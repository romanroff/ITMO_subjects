{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сумма тензоров:\n",
      " tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "Транспонирование тензора:\n",
      " tensor([[1., 3.],\n",
      "        [2., 4.]])\n",
      "Матричное умножение тензоров:\n",
      " tensor([[19., 22.],\n",
      "        [43., 50.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Создание тензоров\n",
    "tensor_a = torch.tensor([[1.0, 2.0], \n",
    "                         [3.0, 4.0]])\n",
    "\n",
    "tensor_b = torch.tensor([[5.0, 6.0], \n",
    "                         [7.0, 8.0]])\n",
    "\n",
    "# Сложение тензоров\n",
    "tensor_sum = tensor_a + tensor_b\n",
    "print(\"Сумма тензоров:\\n\", tensor_sum)\n",
    "\n",
    "# Транспонирование тензора\n",
    "tensor_transpose = tensor_a.T\n",
    "print(\"Транспонирование тензора:\\n\", tensor_transpose)\n",
    "\n",
    "# Матричное умножение тензоров\n",
    "tensor_matmul = torch.matmul(tensor_a, tensor_b)\n",
    "print(\"Матричное умножение тензоров:\\n\", tensor_matmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Градиент y по отношению к x: tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Создаем тензор с возможностью вычисления градиента\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Вычисляем функцию от x\n",
    "y = x ** 2\n",
    "\n",
    "# Вычисляем градиент y по отношению к x\n",
    "y.backward()\n",
    "\n",
    "# Вывод градиента\n",
    "print(\"Градиент y по отношению к x:\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Определение простой CNN для классификации изображений\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 16 * 16, 10)  # CIFAR-10, 10 классов\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 16 * 16 * 16)  # Приведение к вектору\n",
    "        x = self.fc1(x)  # Полносвязный слой\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Создание сверточного слоя с 32 фильтрами и ядром 3x3\n",
    "conv_layer = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Применение Max Pooling с размером окна 2x2\n",
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "# Применение Average Pooling с размером окна 2x2\n",
    "avgpool = nn.AvgPool2d(kernel_size=2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU: tensor([0., 0., 1.])\n",
      "Sigmoid: tensor([0.2689, 0.5000, 0.7311])\n",
      "Tanh: tensor([-0.7616,  0.0000,  0.7616])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Инициализация различных активационных функций\n",
    "relu = nn.ReLU()\n",
    "sigmoid = nn.Sigmoid()\n",
    "tanh = nn.Tanh()\n",
    "\n",
    "# Применение активационной функции\n",
    "x = torch.tensor([-1.0, 0.0, 1.0])  # Пример входных данных\n",
    "print(\"ReLU:\", relu(x))\n",
    "print(\"Sigmoid:\", sigmoid(x))\n",
    "print(\"Tanh:\", tanh(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Определение пайплайна для аугментации изображений\u001b[39;00m\n\u001b[0;32m      4\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      5\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mRandomHorizontalFlip(),   \u001b[38;5;66;03m# Случайное горизонтальное отражение\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mRandomRotation(\u001b[38;5;241m10\u001b[39m),       \u001b[38;5;66;03m# Случайное вращение на 10 градусов\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor()                \u001b[38;5;66;03m# Конвертация в тензор\u001b[39;00m\n\u001b[0;32m      8\u001b[0m ])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Определение пайплайна для аугментации изображений\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),   # Случайное горизонтальное отражение\n",
    "    transforms.RandomRotation(10),       # Случайное вращение на 10 градусов\n",
    "    transforms.ToTensor()                # Конвертация в тензор\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Использование оптимизатора Adam с начальным learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Пример изменения batch size для DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Изменение гиперпараметров в зависимости от этапа обучения\n",
    "optimizer.param_groups[0]['lr'] = 0.0005  # Снижение learning rate в процессе обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Создание слоя Batch Normalization для сверточного слоя\n",
    "bn = nn.BatchNorm2d(16)  # Для слоя с 16 каналами\n",
    "\n",
    "# Пример использования Batch Normalization в слое CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))  # Применение Batch Norm после свертки\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Пример использования Dropout с вероятностью 0.5\n",
    "dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "# Встроим Dropout в полносвязную нейронную сеть\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Применение Dropout\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Пример использования learning rate в оптимизаторе SGD\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Применение scheduler для динамического изменения learning rate\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Понижение lr на каждом 5 шаге\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "# Оптимизатор с базовым learning rate\n",
    "optimizer = SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# CyclicLR scheduler с минимальным и максимальным lr\n",
    "scheduler = CyclicLR(optimizer, base_lr=0.001, max_lr=0.01, step_size_up=5, mode='triangular')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Использование Adam с адаптивным learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Пример обновления learning rate вручную\n",
    "for epoch in range(epochs):\n",
    "    if epoch % 10 == 0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= 0.9  # Понижение lr каждые 10 эпох\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Установка batch size при загрузке данных\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Обход по данным с использованием batch size\n",
    "for images, labels in train_loader:\n",
    "    # Процесс обучения модели\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Оценка точности на тестовом наборе данных\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Пример истинных и предсказанных значений\n",
    "y_true = [0, 1, 1, 0, 1, 1]\n",
    "y_pred = [0, 1, 0, 0, 1, 1]\n",
    "\n",
    "# Расчет Precision\n",
    "precision = precision_score(y_true, y_pred)\n",
    "print(\"Precision:\", precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Пример истинных и предсказанных значений\n",
    "y_true = [0, 1, 1, 0, 1, 1]\n",
    "y_pred = [0, 1, 0, 0, 1, 1]\n",
    "\n",
    "# Расчет Recall\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Пример истинных и предсказанных значений\n",
    "y_true = [0, 1, 1, 0, 1, 1]\n",
    "y_pred = [0, 1, 0, 0, 1, 1]\n",
    "\n",
    "# Расчет F1-score\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Пример истинных меток и предсказанных вероятностей\n",
    "y_true = [0, 1, 1, 0, 1, 1]\n",
    "y_pred_prob = [0.1, 0.9, 0.8, 0.3, 0.6, 0.75]\n",
    "\n",
    "# Расчет ROC-AUC\n",
    "roc_auc = roc_auc_score(y_true, y_pred_prob)\n",
    "print(\"ROC-AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
