{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теория:**\n",
    "\n",
    "Базовый алгоритм совместной фильтрации.\n",
    "\n",
    "$$\\hat{r}_{ui} = \\frac{ \\sum\\limits_{v \\in N^k_i(u)} \\text{sim}(u, v) \\cdot r_{vi}} {\\sum\\limits_{v \\in N^k_i(u)} \\text{sim}(u, v)}$$\n",
    "или\n",
    "$$\\hat{r}_{ui} = \\frac{ \\sum\\limits_{j \\in N^k_u(i)} \\text{sim}(i, j) \\cdot r_{uj}} {\\sum\\limits_{j \\in N^k_u(i)} \\text{sim}(i, j)}$$\n",
    "\n",
    "Однако, в работе нужно использовать базовый алгоритм совместной фильтрации, учитывающий средние оценки каждого пользователя.\n",
    "\n",
    "$$\n",
    "\\hat{r}_{ui} = \\mu_u + \\frac{ \\sum\\limits_{v \\in N^k_i(u)} \\text{sim}(u, v) \\cdot (r_{vi} - \\mu_v)} {\\sum\\limits_{v \\in N^k_i(u)} \\text{sim}(u, v)}\n",
    "$$\n",
    "или\n",
    "$$\n",
    "\\hat{r}_{ui} = \\mu_i + \\frac{ \\sum\\limits_{j \\in N^k_u(i)} \\text{sim}(i, j) \\cdot (r_{uj} - \\mu_j)} {\\sum\\limits_{j \\in N^k_u(i)} \\text{sim}(i, j)}\n",
    "$$\n",
    "\n",
    "\n",
    "Но в итоге можно задать `use_mean_adjustment = (False/True)` для выбора алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'ModeResult'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 260\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28mprint\u001b[39m(results_df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 260\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 251\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    230\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# User-based CF\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# results['user_based'] = user_based_cf(train, test)\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# Voting-based CF\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoting_based\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mvoting_based_cf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Создаем DataFrame с результатами\u001b[39;00m\n\u001b[0;32m    254\u001b[0m results_df \u001b[38;5;241m=\u001b[39m create_results_dataframe(results)\n",
      "Cell \u001b[1;32mIn[10], line 210\u001b[0m, in \u001b[0;36mvoting_based_cf\u001b[1;34m(train, test, n_neighbors)\u001b[0m\n\u001b[0;32m    207\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_rating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: predict_rating(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Вычисляем RMSE\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted_rating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rmse\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:497\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    494\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    495\u001b[0m         )\n\u001b[1;32m--> 497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    501\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:104\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m    102\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    103\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 104\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    107\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\pandas\\core\\series.py:1031\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1031\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1033\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# 1. Загрузка и разделение данных\n",
    "def load_and_split_data(file_path, test_size=0.3, random_state=42):\n",
    "    df = pd.read_csv(file_path)\n",
    "    train, test = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    return train, test\n",
    "\n",
    "# 2. User-based коллаборативная фильтрация\n",
    "def user_based_cf(train, test, use_mean_adjustment=False):\n",
    "    # Создаем матрицу пользователь-фильм\n",
    "    user_item_matrix = train.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "    \n",
    "    # Вычисляем косинусное сходство между пользователями\n",
    "    user_similarity = cosine_similarity(user_item_matrix)\n",
    "    \n",
    "    # Вычисляем средний рейтинг для каждого пользователя (если нужно)\n",
    "    user_means = user_item_matrix.mean(axis=1) if use_mean_adjustment else None\n",
    "    \n",
    "    # Функция для предсказания рейтинга\n",
    "    def predict_rating(user_id, item_id):\n",
    "        # Если юзер или фильм отсутствуют в базе, то выдаем среднее значение\n",
    "        if user_id not in user_item_matrix.index or item_id not in user_item_matrix.columns:\n",
    "            return user_item_matrix.mean().mean()\n",
    "        \n",
    "        user_ratings = user_item_matrix.loc[user_id]\n",
    "        similar_users = user_similarity[user_item_matrix.index.get_loc(user_id)]\n",
    "        \n",
    "        # Находим топ-10 похожих пользователей\n",
    "        top_similar_users = np.argsort(similar_users)[-40:-1]\n",
    "        \n",
    "        # Вычисляем взвешенный рейтинг\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        for similar_user in top_similar_users:\n",
    "            if user_item_matrix.iloc[similar_user][item_id] > 0:\n",
    "                # Если выбран алгоритм с учетом средних оценок\n",
    "                if use_mean_adjustment:\n",
    "                    adjusted_rating = user_item_matrix.iloc[similar_user][item_id] - user_means.iloc[similar_user]\n",
    "                    numerator += similar_users[similar_user] * adjusted_rating\n",
    "                else:\n",
    "                    numerator += similar_users[similar_user] * user_item_matrix.iloc[similar_user][item_id]\n",
    "                \n",
    "                denominator += similar_users[similar_user]\n",
    "        \n",
    "        if denominator == 0:\n",
    "            return user_ratings.mean()\n",
    "        \n",
    "        # Если выбран алгоритм с учетом средних оценок\n",
    "        if use_mean_adjustment:\n",
    "            return user_means.loc[user_id] + numerator / denominator\n",
    "        else:\n",
    "            return numerator / denominator\n",
    "    \n",
    "    # Предсказываем рейтинги для тестового набора\n",
    "    test['predicted_rating'] = test.apply(lambda row: predict_rating(row['userId'], row['movieId']), axis=1)\n",
    "    \n",
    "    # Вычисляем RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(test['rating'], test['predicted_rating']))\n",
    "    return rmse\n",
    "\n",
    "# 3. Item-based коллаборативная фильтрация\n",
    "def item_based_cf(train, test, use_mean_adjustment=False):\n",
    "    # Создаем матрицу фильм-пользователь\n",
    "    item_user_matrix = train.pivot(index='movieId', columns='userId', values='rating').fillna(0)\n",
    "    \n",
    "    # Вычисляем косинусное сходство между фильмами\n",
    "    item_similarity = cosine_similarity(item_user_matrix)\n",
    "    \n",
    "    # Вычисляем средний рейтинг для каждого фильма (если нужно)\n",
    "    item_means = item_user_matrix.mean(axis=1) if use_mean_adjustment else None\n",
    "    \n",
    "    # Функция для предсказания рейтинга\n",
    "    def predict_rating(user_id, item_id):\n",
    "        if item_id not in item_user_matrix.index or user_id not in item_user_matrix.columns:\n",
    "            return item_user_matrix.mean().mean()\n",
    "        \n",
    "        item_ratings = item_user_matrix.loc[item_id]\n",
    "        similar_items = item_similarity[item_user_matrix.index.get_loc(item_id)]\n",
    "        \n",
    "        # Находим топ-10 похожих фильмов\n",
    "        top_similar_items = np.argsort(similar_items)[-40:-1]\n",
    "        \n",
    "        # Вычисляем взвешенный рейтинг\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        for similar_item in top_similar_items:\n",
    "            if item_user_matrix.iloc[similar_item][user_id] > 0:\n",
    "                if use_mean_adjustment:\n",
    "                    # Коррекция рейтинга на среднее значение\n",
    "                    adjusted_rating = item_user_matrix.iloc[similar_item][user_id] - item_means.iloc[similar_item]\n",
    "                    numerator += similar_items[similar_item] * adjusted_rating\n",
    "                else:\n",
    "                    numerator += similar_items[similar_item] * item_user_matrix.iloc[similar_item][user_id]\n",
    "                denominator += similar_items[similar_item]\n",
    "        \n",
    "        if denominator == 0:\n",
    "            return item_ratings.mean()\n",
    "        \n",
    "        if use_mean_adjustment:\n",
    "            # Предсказание с корректировкой на среднее значение фильма\n",
    "            return item_means.loc[item_id] + numerator / denominator\n",
    "        else:\n",
    "            return numerator / denominator\n",
    "    \n",
    "    # Предсказываем рейтинги для тестового набора\n",
    "    test['predicted_rating'] = test.apply(lambda row: predict_rating(row['userId'], row['movieId']), axis=1)\n",
    "    \n",
    "    # Вычисляем RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(test['rating'], test['predicted_rating']))\n",
    "    return rmse\n",
    "\n",
    "# 4. Рекомендательная система на основе кластеризации и расчета средней оценки кластера\n",
    "def cluster_based_cf(train, test, n_clusters=40):\n",
    "    # Создаем матрицу пользователь-фильм\n",
    "    user_item_matrix = train.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "    \n",
    "    # Применяем K-means кластеризацию\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    user_clusters = kmeans.fit_predict(user_item_matrix)\n",
    "    \n",
    "    # Функция для предсказания рейтинга\n",
    "    def predict_rating(user_id, item_id):\n",
    "        if user_id not in user_item_matrix.index or item_id not in user_item_matrix.columns:\n",
    "            return user_item_matrix.mean().mean()\n",
    "        \n",
    "        user_cluster = user_clusters[user_item_matrix.index.get_loc(user_id)]\n",
    "        cluster_users = user_item_matrix.index[user_clusters == user_cluster]\n",
    "        cluster_ratings = user_item_matrix.loc[cluster_users, item_id]\n",
    "        \n",
    "        if cluster_ratings.empty:\n",
    "            return user_item_matrix.mean().mean()\n",
    "        return cluster_ratings.mean()\n",
    "    \n",
    "    # Предсказываем рейтинги для тестового набора\n",
    "    test['predicted_rating'] = test.apply(lambda row: predict_rating(row['userId'], row['movieId']), axis=1)\n",
    "    \n",
    "    # Вычисляем RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(test['rating'], test['predicted_rating']))\n",
    "    return rmse\n",
    "\n",
    "# 5. Рекомендательная система на основе кластеризации и учета z-оценки\n",
    "def cluster_based_cf_z_score(train, test, n_clusters=40):\n",
    "    # Создаем матрицу пользователь-фильм\n",
    "    user_item_matrix = train.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "    \n",
    "    # Нормализуем оценки с помощью z-score\n",
    "    user_means = user_item_matrix.mean(axis=1)\n",
    "    user_stds = user_item_matrix.std(axis=1)\n",
    "    user_item_matrix_normalized = user_item_matrix.sub(user_means, axis=0).div(user_stds, axis=0)\n",
    "    \n",
    "    # Применяем K-means кластеризацию\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    user_clusters = kmeans.fit_predict(user_item_matrix_normalized)\n",
    "    \n",
    "    # Функция для предсказания рейтинга\n",
    "    def predict_rating(user_id, item_id):\n",
    "        if user_id not in user_item_matrix.index or item_id not in user_item_matrix.columns:\n",
    "            return user_item_matrix.mean().mean()\n",
    "        \n",
    "        user_cluster = user_clusters[user_item_matrix.index.get_loc(user_id)]\n",
    "        cluster_users = user_item_matrix.index[user_clusters == user_cluster]\n",
    "        cluster_ratings_normalized = user_item_matrix_normalized.loc[cluster_users, item_id]\n",
    "        \n",
    "        if cluster_ratings_normalized.empty:\n",
    "            return user_means[user_id]\n",
    "        \n",
    "        predicted_z_score = cluster_ratings_normalized.mean()\n",
    "        return user_means[user_id] + (predicted_z_score * user_stds[user_id])\n",
    "    \n",
    "    # Предсказываем рейтинги для тестового набора\n",
    "    test['predicted_rating'] = test.apply(lambda row: predict_rating(row['userId'], row['movieId']), axis=1)\n",
    "    \n",
    "    # Вычисляем RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(test['rating'], test['predicted_rating']))\n",
    "    return rmse\n",
    "\n",
    "# 6. Рекомендательная система на основе голосования\n",
    "def voting_based_cf(train, test, n_neighbors=40):\n",
    "    # Создаем матрицу пользователь-фильм\n",
    "    user_item_matrix = train.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "    \n",
    "    # Вычисляем косинусное сходство между пользователями\n",
    "    user_similarity = cosine_similarity(user_item_matrix)\n",
    "    \n",
    "    # Функция для предсказания рейтинга\n",
    "    def predict_rating(user_id, item_id):\n",
    "        if user_id not in user_item_matrix.index or item_id not in user_item_matrix.columns:\n",
    "            return user_item_matrix.mean().mean()\n",
    "        \n",
    "        user_ratings = user_item_matrix.loc[user_id]\n",
    "        similar_users = user_similarity[user_item_matrix.index.get_loc(user_id)]\n",
    "        \n",
    "        # Находим топ-N похожих пользователей\n",
    "        top_similar_users = np.argsort(similar_users)[-n_neighbors-1:-1]\n",
    "        \n",
    "        # Собираем голоса\n",
    "        votes = user_item_matrix.iloc[top_similar_users][item_id].values\n",
    "        votes = votes[votes > 0]\n",
    "        \n",
    "        if len(votes) == 0:\n",
    "            return user_ratings.mean()\n",
    "        \n",
    "        # Возвращаем наиболее популярную оценку\n",
    "        return np.bincount(votes.astype(int)).argmax()\n",
    "    \n",
    "    # Предсказываем рейтинги для тестового набора\n",
    "    test['predicted_rating'] = test.apply(lambda row: predict_rating(row['userId'], row['movieId']), axis=1)\n",
    "    \n",
    "    # Вычисляем RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(test['rating'], test['predicted_rating']))\n",
    "    return rmse\n",
    "\n",
    "# Оформление результа\n",
    "def create_results_dataframe(results):\n",
    "    \"\"\"\n",
    "    Создает pandas DataFrame из словаря результатов.\n",
    "    \n",
    "    :param results: Словарь с названиями методов в качестве ключей и RMSE в качестве значений\n",
    "    :return: pandas DataFrame с результатами\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(list(results.items()), columns=['Метод', 'RMSE'])\n",
    "    df.set_index('Метод', inplace=True)\n",
    "    return df\n",
    "\n",
    "# Основная функция\n",
    "def main():\n",
    "    # Загрузка и разделение данных\n",
    "    train, test = load_and_split_data('data/ml-latest-small/ratings.csv')\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    # User-based CF\n",
    "    results['user_based'] = user_based_cf(train, test)\n",
    "\n",
    "    # User-based CF with Mean\n",
    "    results['user_based_mean'] = user_based_cf(train, test, use_mean_adjustment=True)\n",
    "    \n",
    "    # Item-based CF\n",
    "    results['item_based'] = item_based_cf(train, test)\n",
    "\n",
    "    # Item-based CF with Mean\n",
    "    results['item_based_mean'] = item_based_cf(train, test, use_mean_adjustment=True)\n",
    "    \n",
    "    # Cluster-based CF\n",
    "    results['cluster_based'] = cluster_based_cf(train, test)\n",
    "    \n",
    "    # Cluster-based CF with z-score\n",
    "    results['cluster_based_z_score'] = cluster_based_cf_z_score(train, test)\n",
    "    \n",
    "    # Voting-based CF\n",
    "    results['voting_based'] = voting_based_cf(train, test)\n",
    "    \n",
    "    # Создаем DataFrame с результатами\n",
    "    results_df = create_results_dataframe(results)\n",
    "    \n",
    "    # Выводим результаты\n",
    "    print(results_df.sort_values('RMSE'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                     RMSE\n",
    "Метод                    \n",
    "SVD-based CF     0.880165\n",
    "Voting-based CF  0.881114\n",
    "User-based CF    0.907214\n",
    "Item-based CF    0.910994\n",
    "KNN-Z CF         0.916671\n",
    "NMF-based CF     0.970052\n",
    "voting_based           1.530395"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итог 1:**\n",
    "Голосование показало себя лучше всего.\n",
    "\n",
    "*Нужно посмотреть данные и понять почему `user_based` лучше, чем `item_based`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9072\n",
      "RMSE: 0.9110\n",
      "RMSE: 0.8802\n",
      "RMSE: 0.9701\n",
      "RMSE: 0.9167\n",
      "RMSE: 0.8811\n",
      "                     RMSE\n",
      "Метод                    \n",
      "SVD-based CF     0.880165\n",
      "Voting-based CF  0.881114\n",
      "User-based CF    0.907214\n",
      "Item-based CF    0.910994\n",
      "KNN-Z CF         0.916671\n",
      "NMF-based CF     0.970052\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, SVD, KNNBasic, KNNWithMeans, KNNWithZScore, NMF\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.accuracy import rmse\n",
    "from collections import defaultdict\n",
    "\n",
    "# 1. Загрузка и разделение данных\n",
    "def load_and_split_data(file_path, test_size=0.3, random_state=42):\n",
    "    \n",
    "    # Загрузка данных\n",
    "    df = pd.read_csv(file_path)\n",
    "    reader = Reader(rating_scale=(0.5, 5))\n",
    "    data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
    "    \n",
    "    # Разделение данных\n",
    "    trainset, testset = train_test_split(data, test_size=test_size, random_state=random_state)\n",
    "    return trainset, testset\n",
    "\n",
    "# 2. User-based коллаборативная фильтрация\n",
    "def user_based_cf(trainset, testset):\n",
    "    sim_options = {'name': 'cosine', 'user_based': True}\n",
    "    algo = KNNWithMeans(sim_options=sim_options, verbose=False)\n",
    "    algo.fit(trainset) \n",
    "    predictions = algo.test(testset)\n",
    "    return rmse(predictions)\n",
    "\n",
    "# 3. Item-based коллаборативная фильтрация\n",
    "def item_based_cf(trainset, testset):\n",
    "    sim_options = {'name': 'cosine', 'user_based': False}\n",
    "    algo = KNNWithMeans(sim_options=sim_options, verbose=False)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    return rmse(predictions)\n",
    "\n",
    "# 4. Рекомендательная система на основе SVD (аналог кластеризации)\n",
    "def svd_based_cf(trainset, testset):\n",
    "    algo = SVD(n_factors=100, random_state=42)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    return rmse(predictions)\n",
    "\n",
    "# 5.1 Рекомендательная система на основе NMF (аналог кластеризации с учетом z-оценки)\n",
    "def nmf_based_cf(trainset, testset):\n",
    "    algo = NMF(n_factors=50, random_state=42)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    return rmse(predictions)\n",
    "\n",
    "# 5.2 Рекомендательная система на основе кластеризации с учетом z-оценки\n",
    "def knnz_based_cf(trainset, testset):\n",
    "    sim_options = {'name': 'cosine', 'user_based': False}\n",
    "    algo = KNNWithZScore(sim_options=sim_options, verbose=False)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    return rmse(predictions)\n",
    "\n",
    "# 6. Рекомендательная система на основе голосования (усредненное предсказание)\n",
    "def voting_based_cf(trainset, testset):\n",
    "    # Используем несколько алгоритмов для голосования\n",
    "    algos = [\n",
    "        KNNWithMeans(sim_options={'name': 'cosine', 'user_based': True}, verbose=False),\n",
    "        KNNWithMeans(sim_options={'name': 'cosine', 'user_based': False}, verbose=False),\n",
    "        SVD(n_factors=100, random_state=42),\n",
    "        NMF(n_factors=50, random_state=42)\n",
    "    ]\n",
    "    \n",
    "    # Обучаем все алгоритмы\n",
    "    for algo in algos:\n",
    "        algo.fit(trainset)\n",
    "    \n",
    "    # Предсказываем рейтинги и усредняем их\n",
    "    predictions = defaultdict(list)\n",
    "    for algo in algos:\n",
    "        for prediction in algo.test(testset):\n",
    "            uid, iid, _, est, _ = prediction\n",
    "            predictions[(uid, iid)].append(est)\n",
    "    \n",
    "    # Усредняем предсказания\n",
    "    final_predictions = []\n",
    "    for (uid, iid), preds in predictions.items():\n",
    "        true_r = next((true_r for (u, i, true_r) in testset if u == uid and i == iid), None)\n",
    "        if true_r is not None:\n",
    "            final_predictions.append((uid, iid, true_r, np.mean(preds), {'n_votes': len(preds)}))\n",
    "    \n",
    "    return rmse(final_predictions)\n",
    "\n",
    "# Оформление результа\n",
    "def create_results_dataframe(results):\n",
    "    \"\"\"\n",
    "    Создает pandas DataFrame из словаря результатов.\n",
    "    \n",
    "    :param results: Словарь с названиями методов в качестве ключей и RMSE в качестве значений\n",
    "    :return: pandas DataFrame с результатами\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(list(results.items()), columns=['Метод', 'RMSE'])\n",
    "    df.set_index('Метод', inplace=True)\n",
    "    return df\n",
    "\n",
    "# Основная функция\n",
    "def main():\n",
    "    # Загрузка и разделение данных\n",
    "    trainset, testset = load_and_split_data('data/ml-latest-small/ratings.csv')\n",
    "    \n",
    "    # Словарь для хранения результатов\n",
    "    results = {}\n",
    "    \n",
    "    # User-based CF\n",
    "    results['User-based CF'] = user_based_cf(trainset, testset)\n",
    "    \n",
    "    # Item-based CF\n",
    "    results['Item-based CF'] = item_based_cf(trainset, testset)\n",
    "    \n",
    "    # SVD-based CF (аналог кластеризации)\n",
    "    results['SVD-based CF'] = svd_based_cf(trainset, testset)\n",
    "    \n",
    "    # NMF-based CF (аналог кластеризации с учетом z-оценки)\n",
    "    results['NMF-based CF'] = nmf_based_cf(trainset, testset)\n",
    "\n",
    "    #KNN-Z CF\n",
    "    results['KNN-Z CF'] = knnz_based_cf(trainset, testset)\n",
    "    \n",
    "    # Voting-based CF\n",
    "    results['Voting-based CF'] = voting_based_cf(trainset, testset)\n",
    "    \n",
    "    # Создаем DataFrame с результатами\n",
    "    results_df = create_results_dataframe(results)\n",
    "    \n",
    "    # Выводим результаты\n",
    "    print(results_df.sort_values('RMSE'))\n",
    "    \n",
    "    # results_df.to_csv('recommender_systems_results.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
