{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция ошибки (с регуляризацией)\n",
    "\n",
    "Основная функция ошибки для одного элемента матрицы взаимодействий $ A_{ij} $:\n",
    "$$\n",
    "E_{ij} = (A_{ij} - U_i^T V_j)^2 + \\lambda (||U_i||^2 + ||V_j||^2)\n",
    "$$\n",
    "Здесь:\n",
    "- $ A_{ij} $ — фактическое взаимодействие (например, рейтинг).\n",
    "- $ U_i $ и $ V_j $ — вектора скрытых факторов для пользователя $ i $ и товара $ j $, соответственно.\n",
    "- $ U_i^T V_j $ — предсказанное взаимодействие.\n",
    "- $ \\lambda $ — коэффициент регуляризации для предотвращения переобучения.\n",
    "\n",
    "### Вычисление градиента для каждого параметра\n",
    "\n",
    "1. **Градиент по $ U_i $**\n",
    "\n",
    "   Нам нужно минимизировать функцию ошибки $ E_{ij} $, изменяя $ U_i $. Для этого вычисляется частная производная ошибки по каждому элементу вектора $ U_i $:\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial E_{ij}}{\\partial U_i} = -2 (A_{ij} - U_i^T V_j) V_j + 2 \\lambda U_i\n",
    "   $$\n",
    "   - $ -2 (A_{ij} - U_i^T V_j) V_j $ — это градиент без регуляризации, который корректирует вектор $ U_i $ на основе ошибки предсказания.\n",
    "   - $ 2 \\lambda U_i $ — регуляризация, которая уменьшает значения элементов $ U_i $, чтобы избежать переобучения.\n",
    "\n",
    "   Итоговое обновление $ U_i $ с использованием градиентного спуска:\n",
    "   $$\n",
    "   U_i \\gets U_i + \\alpha \\left( (A_{ij} - U_i^T V_j) V_j - \\lambda U_i \\right)\n",
    "   $$\n",
    "   Здесь $ \\alpha $ — скорость обучения (learning rate).\n",
    "\n",
    "   **Аналогично, градиент по $ V_j $:**\n",
    "   $$\n",
    "   V_j \\gets V_j + \\alpha \\left( (A_{ij} - U_i^T V_j) U_i - \\lambda V_j \\right)\n",
    "   $$\n",
    "\n",
    "2. **Градиенты по $b_u$, $b_i$**:\n",
    "   \n",
    "     $$\n",
    "     b_u[i] \\leftarrow b_u[i] + \\alpha \\left( e_{ij} - \\lambda b_u[i] \\right)\n",
    "     $$\n",
    "\n",
    "     $$\n",
    "     b_i[j] \\leftarrow b_i[j] + \\alpha \\left( e_{ij} - \\lambda b_i[j] \\right)\n",
    "     $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('data/ml-latest-small/ratings.csv')\n",
    "n_users = df['userId'].nunique()\n",
    "n_items = df['movieId'].nunique()\n",
    "\n",
    "# Создание индексов для пользователей и фильмов\n",
    "user_ids = df['userId'].astype('category').cat.codes.values\n",
    "item_ids = df['movieId'].astype('category').cat.codes.values\n",
    "\n",
    "df['user_idx'] = user_ids\n",
    "df['item_idx'] = item_ids\n",
    "\n",
    "# Разделение данных на тренировочные и тестовые наборы\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Матрица рейтингов\n",
    "def create_matrix(df, n_users, n_items):\n",
    "    matrix = np.zeros((n_users, n_items))\n",
    "    for row in df.itertuples():\n",
    "        matrix[row.user_idx, row.item_idx] = row.rating\n",
    "    return matrix\n",
    "\n",
    "R_train = create_matrix(train_df, n_users, n_items)\n",
    "R_test = create_matrix(test_df, n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для расчета RMSE\n",
    "def calculate_rmse(R_test, model):\n",
    "    xs, ys = R_test.nonzero()\n",
    "    predicted = []\n",
    "    actual = []\n",
    "    progress_bar = tqdm(total=len(xs), desc=\"Calculating RMSE\")\n",
    "    for x, y in zip(xs, ys):\n",
    "        predicted.append(model.predict(x, y))\n",
    "        actual.append(R_test[x, y])\n",
    "        progress_bar.update(1)\n",
    "    progress_bar.close()\n",
    "    return np.sqrt(np.mean((np.array(predicted) - np.array(actual)) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    def __init__(self, R, K=20, alpha=0.002, beta=0.02, iterations=100):\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha  # Скорость обучения\n",
    "        self.beta = beta  # Регуляризация\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R > 0])\n",
    "\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        progress_bar = tqdm(total=self.iterations, desc=\"Training Progress\")\n",
    "        for iteration in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            progress_bar.set_postfix({'RMSE': f\"{rmse:.4f}\"})\n",
    "            progress_bar.update(1)\n",
    "        progress_bar.close()\n",
    "\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.predict(i, j)\n",
    "            error = r - prediction\n",
    "\n",
    "            # Обновление биасов\n",
    "            self.b_u[i] += self.alpha * (error - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (error - self.beta * self.b_i[j])\n",
    "\n",
    "            # Обновление скрытых факторов\n",
    "            self.P[i, :] += self.alpha * (error * self.Q[j, :] - self.beta * self.P[i, :])\n",
    "            self.Q[j, :] += self.alpha * (error * self.P[i, :] - self.beta * self.Q[j, :])\n",
    "\n",
    "    def predict(self, i, j):\n",
    "        return self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = []\n",
    "        actual = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            predicted.append(self.predict(x, y))\n",
    "            actual.append(self.R[x, y])\n",
    "        return np.sqrt(np.mean((np.array(predicted) - np.array(actual)) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDPlusPlus:\n",
    "    def __init__(self, R, K=20, alpha=0.002, beta=0.02, iterations=100):\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K  # Количество скрытых факторов\n",
    "        self.alpha = alpha  # Скорость обучения\n",
    "        self.beta = beta  # Регуляризация\n",
    "        self.iterations = iterations\n",
    "\n",
    "        # Инициализация параметров\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))  # Пользовательские факторы\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))  # Товарные факторы\n",
    "        self.y = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))  # Латентные векторы для товаров\n",
    "\n",
    "        self.b_u = np.zeros(self.num_users)  # Биасы пользователей\n",
    "        self.b_i = np.zeros(self.num_items)  # Биасы товаров\n",
    "        self.b = np.mean(self.R[self.R > 0])  # Глобальный биас\n",
    "\n",
    "        # Предварительное сохранение индексов непустых оценок\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        # Предварительное вычисление множества N_u для каждого пользователя\n",
    "        self.N_u = {i: [j for j in range(self.num_items) if self.R[i, j] > 0] for i in range(self.num_users)}\n",
    "\n",
    "    def train(self):\n",
    "        progress_bar = tqdm(total=self.iterations, desc=\"Training SVD++\")\n",
    "        for iteration in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            progress_bar.set_postfix({'RMSE': f\"{rmse:.4f}\"})\n",
    "            progress_bar.update(1)\n",
    "        progress_bar.close()\n",
    "\n",
    "    def sgd(self):\n",
    "        y_update = np.zeros((self.num_items, self.K))  # Для обновления латентных векторов y_j\n",
    "        \n",
    "        for i, j, r in self.samples:\n",
    "            # Имплицитный фидбек для пользователя i\n",
    "            N_u = self.N_u[i]\n",
    "            if len(N_u) > 0:\n",
    "                implicit_feedback = np.sum(self.y[N_u], axis=0) / np.sqrt(len(N_u))\n",
    "            else:\n",
    "                implicit_feedback = np.zeros(self.K)\n",
    "\n",
    "            # Предсказание\n",
    "            prediction = self.b + self.b_u[i] + self.b_i[j] + np.dot(self.P[i, :] + implicit_feedback, self.Q[j, :].T)\n",
    "            error = r - prediction\n",
    "\n",
    "            # Обновление биасов\n",
    "            self.b_u[i] += self.alpha * (error - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (error - self.beta * self.b_i[j])\n",
    "\n",
    "            # Обновление факторов\n",
    "            self.P[i, :] += self.alpha * (error * self.Q[j, :] - self.beta * self.P[i, :])\n",
    "            self.Q[j, :] += self.alpha * (error * (self.P[i, :] + implicit_feedback) - self.beta * self.Q[j, :])\n",
    "\n",
    "            # Обновление латентных факторов y для каждого товара в N_u\n",
    "            if len(N_u) > 0:\n",
    "                y_update[N_u] += self.alpha * (error / np.sqrt(len(N_u)) * self.Q[j, :] - self.beta * self.y[N_u])\n",
    "\n",
    "        # Обновление латентных векторов y для всех товаров после прохода по данным\n",
    "        self.y += y_update\n",
    "\n",
    "    def predict(self, i, j):\n",
    "        N_u = self.N_u[i]\n",
    "        if len(N_u) > 0:\n",
    "            implicit_feedback = np.sum(self.y[N_u], axis=0) / np.sqrt(len(N_u))\n",
    "        else:\n",
    "            implicit_feedback = np.zeros(self.K)\n",
    "        return self.b + self.b_u[i] + self.b_i[j] + np.dot(self.P[i, :] + implicit_feedback, self.Q[j, :].T)\n",
    "\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = []\n",
    "        actual = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            predicted.append(self.predict(x, y))\n",
    "            actual.append(self.R[x, y])\n",
    "        return np.sqrt(np.mean((np.array(predicted) - np.array(actual)) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 25/25 [00:34<00:00,  1.37s/it, RMSE=0.7840]\n",
      "Calculating RMSE: 100%|██████████| 30251/30251 [00:00<00:00, 205788.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.8828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training SVD++: 100%|██████████| 25/25 [07:16<00:00, 17.47s/it, RMSE=0.8174]\n",
      "Calculating RMSE: 100%|██████████| 30251/30251 [00:02<00:00, 14202.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "K=5\n",
    "iterations=25\n",
    "alpha=0.005\n",
    "beta=0.01\n",
    "\n",
    "# Запуск моделей\n",
    "svd = SVD(R_train, K=K, iterations=iterations, alpha=alpha, beta=beta)\n",
    "svd.train()\n",
    "rmse_test = calculate_rmse(R_test, svd)\n",
    "print(f\"Test RMSE: {rmse_test:.4f}\")\n",
    "\n",
    "svdpp = SVDPlusPlus(R_train, K=K, iterations=iterations, alpha=alpha, beta=beta)\n",
    "svdpp.train()\n",
    "rmse_test = calculate_rmse(R_test, svdpp)\n",
    "print(f\"Test RMSE: {rmse_test:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
