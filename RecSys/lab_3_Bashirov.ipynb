{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рестораны:\n",
    "1. `chefmozaccepts.csv` (1314 строк): информация об оплате.\n",
    "2. `chefmozcuisine.csv` (916 строк): типы кухни.\n",
    "3. `chefmozhours4.csv` (2339 строк): часы работы.\n",
    "4. `chefmozparking.csv` (702 строки): информация о парковке.\n",
    "5. `geoplaces2.csv` (130 строк): геолокация и дополнительная информация.\n",
    "\n",
    "Пользователи:\n",
    "1. `usercuisine.csv` (330 строк): предпочтения кухни пользователей.\n",
    "2. `userpayment.csv` (177 строк): способы оплаты.\n",
    "3. `userprofile.csv` (138 строк): профили пользователей (например, курение, уровень дохода, активность).\n",
    "\n",
    "Рейтинги:\n",
    "1. `rating_final.csv` (1161 строк): оценки ресторанов пользователями по нескольким параметрам (еда, сервис)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка файлов\n",
    "accepts = pd.read_csv('data/restaurant/chefmozaccepts.csv')\n",
    "cuisine = pd.read_csv('data/restaurant/chefmozcuisine.csv')\n",
    "hours = pd.read_csv('data/restaurant/chefmozhours4.csv')\n",
    "parking = pd.read_csv('data/restaurant/chefmozparking.csv')\n",
    "geoplaces = gpd.read_file('data/restaurant/geoplaces2.csv')\n",
    "\n",
    "user_cuisine = pd.read_csv('data/restaurant/usercuisine.csv')\n",
    "user_payment = pd.read_csv('data/restaurant/userpayment.csv')\n",
    "user_profile = pd.read_csv('data/restaurant/userprofile.csv')\n",
    "\n",
    "rating = pd.read_csv('data/restaurant/rating_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = rating['userID'].nunique()\n",
    "n_items = rating['placeID'].nunique()\n",
    "\n",
    "# Создание индексов для пользователей и фильмов\n",
    "user_ids = rating['userID'].astype('category').cat.codes.values\n",
    "item_ids = rating['placeID'].astype('category').cat.codes.values\n",
    "\n",
    "rating['user_idx'] = user_ids\n",
    "rating['item_idx'] = item_ids\n",
    "\n",
    "# Разделение данных на тренировочные и тестовые наборы\n",
    "train_df, test_df = train_test_split(rating, test_size=0.3, random_state=42)\n",
    "\n",
    "# Матрица рейтингов\n",
    "def create_matrix(df, n_users, n_items):\n",
    "    matrix = np.zeros((n_users, n_items))\n",
    "    for row in df.itertuples():\n",
    "        matrix[row.user_idx, row.item_idx] = row.rating\n",
    "    return matrix\n",
    "\n",
    "R_train = create_matrix(train_df, n_users, n_items)\n",
    "R_test = create_matrix(test_df, n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    def __init__(self, R, K=20, alpha=0.002, beta=0.02, iterations=100):\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha  # Скорость обучения\n",
    "        self.beta = beta  # Регуляризация\n",
    "        self.iterations = iterations\n",
    "        self.rmse_values = []  # Список для хранения значений RMSE\n",
    "        self.map_values = []  # Список для хранения значений MAP\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R > 0])\n",
    "\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        progress_bar = tqdm(total=self.iterations, desc=\"Training SVD\")\n",
    "        for iteration in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            self.rmse_values.append(rmse)  # Сохраняем значение RMSE\n",
    "            progress_bar.set_postfix({'RMSE': f\"{rmse:.4f}\"})\n",
    "            progress_bar.update(1)\n",
    "        progress_bar.close()\n",
    "\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.predict(i, j)\n",
    "            error = r - prediction\n",
    "\n",
    "            # Обновление биасов\n",
    "            self.b_u[i] += self.alpha * (error - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (error - self.beta * self.b_i[j])\n",
    "\n",
    "            # Обновление скрытых факторов\n",
    "            self.P[i, :] += self.alpha * (error * self.Q[j, :] - self.beta * self.P[i, :])\n",
    "            self.Q[j, :] += self.alpha * (error * self.P[i, :] - self.beta * self.Q[j, :])\n",
    "\n",
    "\n",
    "    def predict(self, i, j):\n",
    "        return self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "\n",
    "\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = []\n",
    "        actual = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            predicted.append(self.predict(x, y))\n",
    "            actual.append(self.R[x, y])\n",
    "        return np.sqrt(np.mean((np.array(predicted) - np.array(actual)) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.02\u001b[39m\n\u001b[0;32m      6\u001b[0m svd \u001b[38;5;241m=\u001b[39m SVD(R_train, K\u001b[38;5;241m=\u001b[39mK, iterations\u001b[38;5;241m=\u001b[39miterations, alpha\u001b[38;5;241m=\u001b[39malpha, beta\u001b[38;5;241m=\u001b[39mbeta)\n\u001b[1;32m----> 7\u001b[0m \u001b[43msvd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 32\u001b[0m, in \u001b[0;36mSVD.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msgd()\n\u001b[1;32m---> 32\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrmse_values\u001b[38;5;241m.\u001b[39mappend(rmse)  \u001b[38;5;66;03m# Сохраняем значение RMSE\u001b[39;00m\n\u001b[0;32m     34\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m})\n",
      "Cell \u001b[1;32mIn[4], line 57\u001b[0m, in \u001b[0;36mSVD.rmse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrmse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 57\u001b[0m     xs, ys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     59\u001b[0m     actual \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training SVD:   6%|▋         | 637/10000 [00:20<02:11, 71.04it/s, RMSE=0.0369]"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "iterations = 10000\n",
    "alpha = 0.02\n",
    "beta = 0.02\n",
    "\n",
    "svd = SVD(R_train, K=K, iterations=iterations, alpha=alpha, beta=beta)\n",
    "svd.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведение всех placeID к строковому типу\n",
    "accepts['placeID'] = accepts['placeID'].astype(str)\n",
    "cuisine['placeID'] = cuisine['placeID'].astype(str)\n",
    "hours['placeID'] = hours['placeID'].astype(str)\n",
    "parking['placeID'] = parking['placeID'].astype(str)\n",
    "geoplaces['placeID'] = geoplaces['placeID'].astype(str)\n",
    "rating['placeID'] = rating['placeID'].astype(str)\n",
    "\n",
    "# Объединение таблиц по placeID\n",
    "restaurants = accepts.merge(cuisine, on='placeID', how='left') \\\n",
    "                     .merge(hours, on='placeID', how='left') \\\n",
    "                     .merge(parking, on='placeID', how='left') \\\n",
    "                     .merge(geoplaces, on='placeID', how='left')\n",
    "\n",
    "# Объединение информации о пользователях\n",
    "users = user_cuisine.merge(user_payment, on='userID', how='left') \\\n",
    "                   .merge(user_profile, on='userID', how='left')\n",
    "\n",
    "data = rating.merge(users, on='userID', how='left') \\\n",
    "             .merge(restaurants, on='placeID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример: Фильтрация ресторанов по типу кухни и цене\n",
    "filtered_restaurants = restaurants[(restaurants['Rcuisine'].isin(['Italian', 'Japanese', 'Mexican'])) &\n",
    "                                   (restaurants['price'].isin(['medium', 'high']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Подготовка данных для Surprise\n",
    "reader = Reader(rating_scale=(0, 2))\n",
    "surprise_data = Dataset.load_from_df(train[['userID', 'placeID', 'rating']], reader)\n",
    "trainset = surprise_data.build_full_trainset()\n",
    "\n",
    "# Обучение модели\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "test_filtered = test[test['placeID'].isin(filtered_restaurants['placeID'])]\n",
    "predictions = algo.test(test_filtered[['userID', 'placeID', 'rating']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@50: 1.0\n"
     ]
    }
   ],
   "source": [
    "def map_at_k(predictions, k=50):\n",
    "    # Группируем предсказания по userID\n",
    "    from collections import defaultdict\n",
    "    user_pred = defaultdict(list)\n",
    "    for pred in predictions:\n",
    "        user_pred[pred.uid].append((pred.iid, pred.est))\n",
    "    \n",
    "    average_precisions = []\n",
    "    for user, items in user_pred.items():\n",
    "        # Сортируем по оценке\n",
    "        items_sorted = sorted(items, key=lambda x: x[1], reverse=True)[:k]\n",
    "        # Истинные релеванты\n",
    "        true_items = test_filtered[test_filtered['userID'] == user]['placeID'].tolist()\n",
    "        hits = 0\n",
    "        sum_precisions = 0\n",
    "        for i, (item, _) in enumerate(items_sorted, 1):\n",
    "            if item in true_items:\n",
    "                hits += 1\n",
    "                sum_precisions += hits / i\n",
    "        if hits > 0:\n",
    "            average_precisions.append(sum_precisions / hits)\n",
    "        else:\n",
    "            average_precisions.append(0)\n",
    "    \n",
    "    return sum(average_precisions) / len(average_precisions)\n",
    "\n",
    "map50 = map_at_k(predictions, k=50)\n",
    "print(f'MAP@50: {map50}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
