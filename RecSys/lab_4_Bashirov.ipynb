{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import time\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import cornac\n",
    "import surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method                         | RMSE | MAP@K | NDCG@K | Novelty | Diversity |\n",
    "|--------------------------------|------|-------|--------|---------|-----------|\n",
    "| User-based                     | 0.98 | NaN   | 0.89   | -5.41   | 0.78      |\n",
    "| Item-based                     | 0.00 | NaN   | 0.00   | 0.00    | 0.00      |\n",
    "| Clustering                     | 0.00 | 0.00  | 0.00   | 0.00    | 0.00      |\n",
    "| Clustering + Z-score           | 0.00 | 0.00  | 0.00   | 0.00    | 0.00      |\n",
    "| KNNregression (classification) | 0.00 | 0.00  | 0.00   | 0.00    | 0.00      |\n",
    "| MF                             | 0.00 | 0.00  | 0.00   | 0.00    | 0.00      |\n",
    "| Surprise_MF                    | 0.00 | 0.00  | 0.00   | 0.00    | 0.00      |\n",
    "| Cornac_NN                      | 0.00 | 0.00  | 0.00   | 0.00    | 0.00      |\n",
    "\n",
    "User- Item based решения не имеют (имеют 1.00) MAP@K, так как предсказание идет только для конкретных фильмов из test. Иначе предсказание всей матрицы занимает несколько часов из-за поэлементного вычисления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для метрик\n",
    "def calculate_rmse(df):\n",
    "    return np.sqrt(mean_squared_error(df['rating'], df['predicted_rating']))\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual: #and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def calculate_mapk(df, k=10):\n",
    "    user_group = df.groupby('userId')\n",
    "    apk_scores = []\n",
    "    for user, group in user_group:\n",
    "        actual = group['movieId'].values\n",
    "        predicted = group.sort_values(by='predicted_rating', ascending=False)['movieId'].values\n",
    "        apk_scores.append(apk(actual, predicted, k))\n",
    "    return np.mean(apk_scores)\n",
    "\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.0\n",
    "\n",
    "def ndcg_at_k(actual, predicted, k=10):\n",
    "    predicted = predicted[:k]\n",
    "    ideal = sorted(actual, reverse=True)[:k]\n",
    "    return dcg_at_k(predicted, k) / dcg_at_k(ideal, k)\n",
    "\n",
    "def calculate_ndcgk(df, k=10):\n",
    "    user_group = df.groupby('userId')\n",
    "    ndcg_scores = []\n",
    "    for user, group in user_group:\n",
    "        actual = group['rating'].values\n",
    "        predicted = group.sort_values(by='predicted_rating', ascending=False)['rating'].values\n",
    "        ndcg_scores.append(ndcg_at_k(actual, predicted, k))\n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "def calculate_novelty(df, item_popularity, k=10):\n",
    "    count_users = len((df['userId'].unique()))\n",
    "    user_group = df.groupby('userId')\n",
    "    novelty_scores = []\n",
    "    for user, group in user_group:\n",
    "        recommended_items = group.sort_values(by='predicted_rating', ascending=False)['movieId'].values[:k]\n",
    "        novelty = np.mean([np.log2(1 / item_popularity[item]) for item in recommended_items if item in item_popularity])\n",
    "        novelty_scores.append(novelty)\n",
    "    return np.mean(novelty_scores)\n",
    "\n",
    "def calculate_diversity(df, item_similarity_matrix, k=10, matrix_columns=None):\n",
    "    user_group = df.groupby('userId')\n",
    "    diversity_scores = []\n",
    "    \n",
    "    for user, group in user_group:\n",
    "        recommended_items = group.sort_values(by='predicted_rating', ascending=False)['movieId'].values[:k]\n",
    "        total_pairs = 0\n",
    "        diversity = 0\n",
    "        for i in range(len(recommended_items)):\n",
    "            for j in range(i + 1, len(recommended_items)):\n",
    "                # Получаем индексы фильмов в матрице\n",
    "                if recommended_items[i] in matrix_columns and recommended_items[j] in matrix_columns:\n",
    "                    idx_i = matrix_columns.get_loc(recommended_items[i])\n",
    "                    idx_j = matrix_columns.get_loc(recommended_items[j])\n",
    "                    total_pairs += 1\n",
    "                    diversity += (1 - item_similarity_matrix[idx_i, idx_j])\n",
    "        \n",
    "        if total_pairs > 0:\n",
    "            diversity_scores.append(diversity / total_pairs)\n",
    "    \n",
    "    return np.mean(diversity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cf_matrix(train, cf_type='user'):\n",
    "\n",
    "    \"\"\"\n",
    "    Создает матрицу для коллаборативной фильтрации.\n",
    "    \n",
    "    Параметры:\n",
    "    - train: DataFrame с обучающими данными.\n",
    "    - cf_type: 'user' для пользователь-фильм матрицы или 'item' для фильм-пользователь матрицы.\n",
    "    \n",
    "    Возвращает:\n",
    "    - Матрица для коллаборативной фильтрации.\n",
    "    \"\"\"\n",
    "    if cf_type == 'user':\n",
    "        # Матрица пользователь-фильм\n",
    "        return train.pivot(index='userId', columns='movieId', values='rating')\n",
    "    elif cf_type == 'item':\n",
    "        # Матрица фильм-пользователь\n",
    "        return train.pivot(index='movieId', columns='userId', values='rating')\n",
    "    else:\n",
    "        raise ValueError(\"cf_type должен быть 'user' или 'item'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_data(file_path, test_size=0.3, random_state=42):\n",
    "    df = pd.read_csv(file_path)\n",
    "    train, test = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    return train, test, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-3. User-based and Item-based коллаборативная фильтрация с/без z-score\n",
    "def collaborative_filtering(train, test, cf_type='user', use_mean_adjustment=False, use_z_score=False, N=None):\n",
    "    # Используем отдельную функцию для создания матрицы\n",
    "    matrix = create_cf_matrix(train, cf_type=cf_type)\n",
    "    \n",
    "    # Вычисляем косинусное сходство\n",
    "    similarity = cosine_similarity(matrix.fillna(0))\n",
    "    \n",
    "    # Вычисляем средние и стандартные отклонения для Z-score (если нужно)\n",
    "    means = matrix.mean(axis=1)\n",
    "    stds = matrix.fillna(0).std(axis=1) if use_z_score else None\n",
    "\n",
    "    # Если включен Z-score, нормализуем рейтинги\n",
    "    if use_z_score:\n",
    "        matrix_normalized = matrix.sub(means, axis=0).div(stds, axis=0).fillna(0)\n",
    "    \n",
    "    # Функция для предсказания рейтинга\n",
    "    def predict_rating(user_id, item_id):\n",
    "        if cf_type == 'user':\n",
    "            # Если тип фильтрации пользователь-фильм\n",
    "            user_index, item_index = user_id, item_id\n",
    "        else:\n",
    "            # Если тип фильтрации фильм-пользователь\n",
    "            user_index, item_index = item_id, user_id\n",
    "        \n",
    "        # Если пользователь или элемент отсутствует в базе\n",
    "        if user_index not in matrix.index or item_index not in matrix.columns:\n",
    "            return matrix.mean().mean()\n",
    "        \n",
    "        # Рейтинги текущего пользователя или фильма\n",
    "        ratings = matrix.loc[user_index]\n",
    "        # Сходства с другими пользователями или фильмами\n",
    "        similarities = similarity[matrix.index.get_loc(user_index)]\n",
    "        \n",
    "        # Сортируем по схожести и выбираем топ-N (если задано)\n",
    "        sorted_similarities = np.argsort(similarities)[::-1]\n",
    "        top_similar = sorted_similarities[:N] if N else sorted_similarities\n",
    "        \n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        for similar in top_similar:\n",
    "            # Проверяем, есть ли рейтинг для указанного элемента (пользователя или фильма)\n",
    "            if matrix.iloc[similar][item_index] > 0:\n",
    "                if use_z_score:\n",
    "                    # Коррекция на Z-score\n",
    "                    adjusted_rating = matrix_normalized.iloc[similar][item_index]\n",
    "                    numerator += similarities[similar] * adjusted_rating\n",
    "                elif use_mean_adjustment:\n",
    "                    # Коррекция на среднюю оценку\n",
    "                    adjusted_rating = matrix.iloc[similar][item_index] - means.iloc[similar]\n",
    "                    numerator += similarities[similar] * adjusted_rating\n",
    "                else:\n",
    "                    numerator += similarities[similar] * matrix.iloc[similar][item_index]\n",
    "                \n",
    "                # Знаменатель: \\text{denominator} += \\text{sim}(u, v)\n",
    "                denominator += abs(similarities[similar])\n",
    "        \n",
    "        # Если нет похожих пользователей/фильмов, предсказываем средний рейтинг пользователя\n",
    "        if denominator == 0:\n",
    "            return ratings.mean()\n",
    "        \n",
    "        if use_z_score:\n",
    "            # Предсказание через Z-score\n",
    "            predicted_z_score = numerator / denominator\n",
    "            return means.loc[user_index] + predicted_z_score * stds.loc[user_index]\n",
    "        elif use_mean_adjustment:\n",
    "            # Предсказание с коррекцией на среднее значение\n",
    "            return means.loc[user_index] + numerator / denominator\n",
    "        else:\n",
    "            # Предсказание без коррекции на среднее значение\n",
    "            return numerator / denominator\n",
    "\n",
    "    # Предсказываем рейтинги только для тех, которых не было в train\n",
    "    test['predicted_rating'] = test.apply(\n",
    "        lambda row: predict_rating(row['userId'], row['movieId']), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Вычисляем метрики на отфильтрованных данных\n",
    "    rmse = calculate_rmse(test)\n",
    "    mapk = calculate_mapk(test, k=10)\n",
    "    ndcgk = calculate_ndcgk(test, k=10)\n",
    "    \n",
    "    item_popularity = train['movieId'].value_counts().to_dict()\n",
    "    item_similarity_matrix = 1 - pairwise_distances(matrix.T.fillna(0), metric='cosine')\n",
    "    novelty = calculate_novelty(test, item_popularity, k=10)\n",
    "    diversity = calculate_diversity(test, item_similarity_matrix, k=10, matrix_columns=matrix.columns)\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAP@K': mapk,\n",
    "        'NDCG@K': ndcgk,\n",
    "        'Novelty': novelty,\n",
    "        'Diversity': diversity\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': 0.9765590439849144, 'MAP@K': 1.0, 'NDCG@K': 0.8862164437146262, 'Novelty': -5.407149403543376, 'Diversity': 0.7842086565702061}\n"
     ]
    }
   ],
   "source": [
    "train, test, df = load_and_split_data('data/ml-latest-small/ratings.csv', test_size=0.3)\n",
    "\n",
    "user = collaborative_filtering(train, test, cf_type='user', use_mean_adjustment=False, use_z_score=False, N=None)\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = collaborative_filtering(train, test, cf_type='item', use_mean_adjustment=False, use_z_score=False, N=None)\n",
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-5. Рекомендательная система на основе кластеризации и расчета средней оценки кластера\n",
    "def cluster_based_cf(train, test, n_clusters=40, use_z_score=False, cf_type='user'):\n",
    "    \"\"\"\n",
    "    Кластерная коллаборативная фильтрация.\n",
    "    \n",
    "    Параметры:\n",
    "    - train: DataFrame с обучающими данными.\n",
    "    - test: DataFrame с тестовыми данными.\n",
    "    - n_clusters: количество кластеров для K-means.\n",
    "    - use_z_score: флаг для использования Z-score нормализации.\n",
    "    - cf_type: 'user' для пользователь-фильм матрицы или 'item' для фильм-пользователь матрицы.\n",
    "    \n",
    "    Возвращает:\n",
    "    - RMSE для предсказанных значений.\n",
    "    \"\"\"\n",
    "    # Создаем матрицу с помощью create_cf_matrix\n",
    "    matrix = create_cf_matrix(train, cf_type=cf_type)\n",
    "    \n",
    "    if use_z_score:\n",
    "        # Нормализуем оценки с помощью z-score\n",
    "        means = matrix.mean(axis=1)\n",
    "        stds = matrix.fillna(0).std(axis=1)\n",
    "        matrix_normalized = matrix.sub(means, axis=0).div(stds, axis=0)\n",
    "        matrix_for_clustering = matrix_normalized.fillna(0)\n",
    "    else:\n",
    "        # Используем обычную матрицу для кластеризации\n",
    "        matrix_for_clustering = matrix.fillna(0)\n",
    "    \n",
    "    # Применяем K-means кластеризацию\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(matrix_for_clustering)\n",
    "    \n",
    "    # Функция для предсказания рейтинга\n",
    "    def predict_rating(user_id, item_id):\n",
    "        if cf_type == 'user':\n",
    "            user_index, item_index = user_id, item_id\n",
    "        else:\n",
    "            user_index, item_index = item_id, user_id\n",
    "        \n",
    "        # Проверка, если пользователя или элемента нет в матрице\n",
    "        if user_index not in matrix.index or item_index not in matrix.columns:\n",
    "            return matrix.mean().mean()\n",
    "        \n",
    "        # Определяем кластер пользователя или фильма\n",
    "        cluster = clusters[matrix.index.get_loc(user_index)]\n",
    "        cluster_items = matrix.index[clusters == cluster]\n",
    "        \n",
    "        if use_z_score:\n",
    "            # Получаем нормализованные рейтинги для кластера\n",
    "            cluster_ratings_normalized = matrix_normalized.loc[cluster_items, item_index]\n",
    "            \n",
    "            # Проверяем, пусты ли нормализованные рейтинги\n",
    "            if cluster_ratings_normalized.empty or cluster_ratings_normalized.isna().all():\n",
    "                return matrix.mean().mean()  # Если нет рейтингов, вернуть среднее по всей матрице\n",
    "            \n",
    "            predicted_z_score = cluster_ratings_normalized.mean()\n",
    "            # Преобразуем предсказание обратно в исходные единицы\n",
    "            return means[user_index] + (predicted_z_score * stds[user_index])\n",
    "        else:\n",
    "            # Получаем обычные рейтинги для кластера\n",
    "            cluster_ratings = matrix.loc[cluster_items, item_index]\n",
    "            \n",
    "            # Проверка на наличие не NaN значений\n",
    "            if cluster_ratings.empty or cluster_ratings.isna().all():\n",
    "                return matrix.mean().mean()  # Если нет доступных значений, вернуть среднее по всей матрице\n",
    "            \n",
    "            # Возвращаем среднее значение по кластеру\n",
    "            return cluster_ratings.mean()\n",
    "    \n",
    "    # Предсказываем рейтинги для тестового набора\n",
    "    test['predicted_rating'] = test.apply(lambda row: predict_rating(row['userId'], row['movieId']), axis=1)\n",
    "    \n",
    "    # Вычисляем RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(test['rating'], test['predicted_rating']))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
