{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import time\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import cornac\n",
    "import surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method                         | RMSE | MAP@K | NDCG@K | Novelty | Diversity |\n",
    "|--------------------------------|------|-------|--------|---------|-----------|\n",
    "| User-based                     | 1.05 | 1.00  | 0.87   | 3.84    | 0.79      |\n",
    "| Item-based                     | 1.01 | 1.00  | 0.88   | 3.87    | 0.92      |\n",
    "| Clustering                     | 1.04 | 1.00  | 0.87   | 3.95    | 0.80      |\n",
    "| Clustering + Z-score           | 1.02 | 1.00  | 0.88   | 3.82    | 0.79      |\n",
    "| KNNregression (classification) | 0.00 | 0.00  | 0.00   | 0.00    | 0.00      |\n",
    "| MF                             | 0.00 | 0.00  | 0.00   | 0.00    | 0.00      |\n",
    "| Surprise_MF                    | 0.00 | 0.00  | 0.00   | 0.00    | 0.00      |\n",
    "| Cornac_NN                      | 0.00 | 0.00  | 0.00   | 0.00    | 0.00      |\n",
    "\n",
    "User- Item based решения не имеют (имеют 1.00) MAP@K, так как предсказание идет только для конкретных фильмов из test. Иначе предсказание всей матрицы занимает несколько часов из-за поэлементного вычисления\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для метрик\n",
    "def calculate_rmse(df):\n",
    "    return np.sqrt(mean_squared_error(df.dropna()['rating'], df.dropna()['predicted_rating']))\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual: #and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    return score / min(len(actual), k) if len(actual) > 0 else 0.0\n",
    "\n",
    "def calculate_mapk(df, k=10):\n",
    "    user_group = df.groupby('userId')\n",
    "    apk_scores = []\n",
    "    for user, group in user_group:\n",
    "        actual = group.dropna()['movieId'].values\n",
    "        if len(actual) == 0:\n",
    "            continue\n",
    "        predicted = group.sort_values(by='predicted_rating', ascending=False)['movieId'].values\n",
    "        apk_scores.append(apk(actual, predicted, k))\n",
    "    return np.mean(apk_scores)\n",
    "\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k] # to float\n",
    "    if r.size:\n",
    "        return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.0\n",
    "\n",
    "def ndcg_at_k(actual, predicted, k=10):\n",
    "    predicted = predicted[:k]\n",
    "    ideal = sorted(actual, reverse=True)[:k]\n",
    "    return dcg_at_k(predicted, k) / dcg_at_k(ideal, k)\n",
    "\n",
    "def calculate_ndcgk(df, k=10):\n",
    "    user_group = df.dropna().groupby('userId') # разделить пользователей\n",
    "    ndcg_scores = []\n",
    "    for user, group in user_group:\n",
    "        actual = group['rating'].values # реальный рейтинг\n",
    "        predicted = group.sort_values(by='predicted_rating', ascending=False)['rating'].values # рейтинг, как решила модель\n",
    "        ndcg_scores.append(ndcg_at_k(actual, predicted, k))\n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "def calculate_novelty(df, item_popularity, k=10):\n",
    "    user_group = df.groupby('userId')\n",
    "    novelty_scores = []\n",
    "    for user, group in user_group:\n",
    "        recommended_items = group.sort_values(by='predicted_rating', ascending=False)['movieId'].values[:k]\n",
    "        novelty = np.mean([np.log2(len(df['userId'].unique()) / item_popularity[item]) for item in recommended_items if item in item_popularity])\n",
    "        if not np.isnan(novelty):\n",
    "            novelty_scores.append(novelty)\n",
    "    print(rf'$log_2$ max: {np.log2(len(df[\"userId\"].unique())):.3}')\n",
    "    return np.mean(novelty_scores) if novelty_scores else 0\n",
    "\n",
    "\n",
    "def calculate_diversity(df, item_similarity_matrix, k=10, matrix_columns=None):\n",
    "    user_group = df.groupby('userId')\n",
    "    diversity_scores = []\n",
    "    \n",
    "    for user, group in user_group:\n",
    "        recommended_items = group.sort_values(by='predicted_rating', ascending=False)['movieId'].values[:k]\n",
    "        total_pairs = 0\n",
    "        diversity = 0\n",
    "        for i in range(len(recommended_items)):\n",
    "            for j in range(i + 1, len(recommended_items)):\n",
    "                # Получаем индексы фильмов в матрице\n",
    "                if recommended_items[i] in matrix_columns and recommended_items[j] in matrix_columns:\n",
    "                    idx_i = matrix_columns.get_loc(recommended_items[i])\n",
    "                    idx_j = matrix_columns.get_loc(recommended_items[j])\n",
    "                    total_pairs += 1\n",
    "                    diversity += (1 - item_similarity_matrix[idx_i, idx_j])\n",
    "        \n",
    "        if total_pairs > 0:\n",
    "            diversity_scores.append(diversity / total_pairs)\n",
    "    \n",
    "    return np.mean(diversity_scores) if diversity_scores else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cf_matrix(train, cf_type='user'):\n",
    "\n",
    "    \"\"\"\n",
    "    Создает матрицу для коллаборативной фильтрации.\n",
    "    \n",
    "    Параметры:\n",
    "    - train: DataFrame с обучающими данными.\n",
    "    - cf_type: 'user' для пользователь-фильм матрицы или 'item' для фильм-пользователь матрицы.\n",
    "    \n",
    "    Возвращает:\n",
    "    - Матрица для коллаборативной фильтрации.\n",
    "    \"\"\"\n",
    "    if cf_type == 'user':\n",
    "        # Матрица пользователь-фильм\n",
    "        return train.pivot(index='userId', columns='movieId', values='rating')\n",
    "    elif cf_type == 'item':\n",
    "        # Матрица фильм-пользователь\n",
    "        return train.pivot(index='movieId', columns='userId', values='rating')\n",
    "    else:\n",
    "        raise ValueError(\"cf_type должен быть 'user' или 'item'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_data(file_path, test_size=0.3, random_state=42):\n",
    "    df = pd.read_csv(file_path)\n",
    "    train, test = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    return train, test, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Основная часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-3. User-based and Item-based коллаборативная фильтрация с/без z-score\n",
    "\n",
    "def collaborative_filtering(train, test, cf_type='user', use_mean_adjustment=False, use_z_score=False, N=50):\n",
    "    matrix = create_cf_matrix(train, cf_type=cf_type)\n",
    "    similarity = cosine_similarity(matrix.fillna(0))\n",
    "    means = matrix.mean(axis=1)\n",
    "    stds = matrix.fillna(0).std(axis=1) if use_z_score else None\n",
    "\n",
    "    if use_z_score:\n",
    "        matrix_normalized = matrix.sub(means, axis=0).div(stds, axis=0).fillna(0)\n",
    "\n",
    "    # Предварительно вычисляем топ-N для всех пользователей\n",
    "    top_similarities = np.argsort(-similarity, axis=1)[:, :N]\n",
    "\n",
    "    def predict_rating(user_id, item_id):\n",
    "        if cf_type == 'user':\n",
    "            user_index, item_index = user_id, item_id\n",
    "        else:\n",
    "            user_index, item_index = item_id, user_id\n",
    "\n",
    "        if user_index not in matrix.index or item_index not in matrix.columns:\n",
    "            return matrix.mean().mean()\n",
    "\n",
    "        ratings = matrix.loc[user_index]\n",
    "        similarities = similarity[matrix.index.get_loc(user_index)]\n",
    "        top_similar = top_similarities[matrix.index.get_loc(user_index)]\n",
    "\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        for similar in top_similar:\n",
    "            if matrix.iloc[similar][item_index] > 0:\n",
    "                if use_z_score:\n",
    "                    adjusted_rating = matrix_normalized.iloc[similar][item_index]\n",
    "                    numerator += similarities[similar] * adjusted_rating\n",
    "                else:\n",
    "                    numerator += similarities[similar] * matrix.iloc[similar][item_index]\n",
    "\n",
    "                denominator += abs(similarities[similar])\n",
    "\n",
    "        if denominator == 0:\n",
    "            return ratings.mean()\n",
    "\n",
    "        if use_z_score:\n",
    "            predicted_z_score = numerator / denominator\n",
    "            return means.loc[user_index] + predicted_z_score * stds.loc[user_index]\n",
    "        else:\n",
    "            return numerator / denominator\n",
    "\n",
    "    test['predicted_rating'] = Parallel(n_jobs=-1)(delayed(predict_rating)(row['userId'], row['movieId']) for _, row in test.iterrows())\n",
    "\n",
    "    # Вычисляем метрики\n",
    "    rmse = calculate_rmse(test)\n",
    "    mapk = calculate_mapk(test, k=10)\n",
    "    ndcgk = calculate_ndcgk(test, k=10)\n",
    "\n",
    "    item_popularity = train['movieId'].value_counts().to_dict()\n",
    "    item_similarity_matrix = 1 - pairwise_distances(matrix.T.fillna(0), metric='cosine')\n",
    "    novelty = calculate_novelty(test, item_popularity, k=10)\n",
    "    diversity = calculate_diversity(test, item_similarity_matrix, k=10, matrix_columns=matrix.columns)\n",
    "\n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAP@K': mapk,\n",
    "        'NDCG@K': ndcgk,\n",
    "        'Novelty': novelty,\n",
    "        'Diversity': diversity\n",
    "    }, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romab\\AppData\\Local\\Temp\\ipykernel_16684\\176393131.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = all_combinations_df.groupby('userId').apply(lambda x: x.sample(n=300, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "train, test, df = load_and_split_data('data/ml-latest-small/ratings.csv', test_size=0.3)\n",
    "\n",
    "users = df['userId'].unique()\n",
    "movies = df['movieId'].unique()\n",
    "all_combinations = pd.MultiIndex.from_product([users, movies], names=['userId', 'movieId'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "sampled_df = all_combinations_df.groupby('userId').apply(lambda x: x.sample(n=300, random_state=42))\n",
    "sampled_df = sampled_df.reset_index(drop=True)\n",
    "expanded_test = pd.merge(sampled_df, test, on=['userId', 'movieId'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user, result = collaborative_filtering(train, expanded_test, cf_type='user', use_mean_adjustment=False, use_z_score=False, N=20)\n",
    "pd.DataFrame(user, index=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$log_2$ max: 9.25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAP@K</th>\n",
       "      <th>NDCG@K</th>\n",
       "      <th>Novelty</th>\n",
       "      <th>Diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.005489</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883193</td>\n",
       "      <td>3.866595</td>\n",
       "      <td>0.915602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE  MAP@K    NDCG@K   Novelty  Diversity\n",
       "1  1.005489    1.0  0.883193  3.866595   0.915602"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = collaborative_filtering(train, expanded_test, cf_type='item', use_mean_adjustment=False, use_z_score=False, N=20)\n",
    "pd.DataFrame(item, index=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-5. Рекомендательная система на основе кластеризации и расчета средней оценки кластера\n",
    "def cluster_based_cf(train, test, n_clusters=40, use_z_score=False, cf_type='user'):\n",
    "    \"\"\"\n",
    "    Кластерная коллаборативная фильтрация.\n",
    "    \n",
    "    Параметры:\n",
    "    - train: DataFrame с обучающими данными.\n",
    "    - test: DataFrame с тестовыми данными.\n",
    "    - n_clusters: количество кластеров для K-means.\n",
    "    - use_z_score: флаг для использования Z-score нормализации.\n",
    "    - cf_type: 'user' для пользователь-фильм матрицы или 'item' для фильм-пользователь матрицы.\n",
    "    \n",
    "    Возвращает:\n",
    "    - RMSE для предсказанных значений.\n",
    "    \"\"\"\n",
    "    # Создаем матрицу с помощью create_cf_matrix\n",
    "    matrix = create_cf_matrix(train, cf_type=cf_type)\n",
    "    \n",
    "    if use_z_score:\n",
    "        # Нормализуем оценки с помощью z-score\n",
    "        means = matrix.mean(axis=1)\n",
    "        stds = matrix.fillna(0).std(axis=1)\n",
    "        matrix_normalized = matrix.sub(means, axis=0).div(stds, axis=0)\n",
    "        matrix_for_clustering = matrix_normalized.fillna(0)\n",
    "    else:\n",
    "        # Используем обычную матрицу для кластеризации\n",
    "        matrix_for_clustering = matrix.fillna(0)\n",
    "    \n",
    "    # Применяем K-means кластеризацию\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(matrix_for_clustering)\n",
    "    \n",
    "    # Функция для предсказания рейтинга\n",
    "    def predict_rating(user_id, item_id):\n",
    "        if cf_type == 'user':\n",
    "            user_index, item_index = user_id, item_id\n",
    "        else:\n",
    "            user_index, item_index = item_id, user_id\n",
    "        \n",
    "        # Проверка, если пользователя или элемента нет в матрице\n",
    "        if user_index not in matrix.index or item_index not in matrix.columns:\n",
    "            return matrix.mean().mean()\n",
    "        \n",
    "        # Определяем кластер пользователя или фильма\n",
    "        cluster = clusters[matrix.index.get_loc(user_index)]\n",
    "        cluster_items = matrix.index[clusters == cluster]\n",
    "        \n",
    "        if use_z_score:\n",
    "            # Получаем нормализованные рейтинги для кластера\n",
    "            cluster_ratings_normalized = matrix_normalized.loc[cluster_items, item_index]\n",
    "            \n",
    "            # Проверяем, пусты ли нормализованные рейтинги\n",
    "            if cluster_ratings_normalized.empty or cluster_ratings_normalized.isna().all():\n",
    "                return matrix.mean().mean()  # Если нет рейтингов, вернуть среднее по всей матрице\n",
    "            \n",
    "            predicted_z_score = cluster_ratings_normalized.mean()\n",
    "            # Преобразуем предсказание обратно в исходные единицы\n",
    "            return means[user_index] + (predicted_z_score * stds[user_index])\n",
    "        else:\n",
    "            # Получаем обычные рейтинги для кластера\n",
    "            cluster_ratings = matrix.loc[cluster_items, item_index]\n",
    "            \n",
    "            # Проверка на наличие не NaN значений\n",
    "            if cluster_ratings.empty or cluster_ratings.isna().all():\n",
    "                return matrix.mean().mean()  # Если нет доступных значений, вернуть среднее по всей матрице\n",
    "            \n",
    "            # Возвращаем среднее значение по кластеру\n",
    "            return cluster_ratings.mean()\n",
    "    \n",
    "    # Предсказываем рейтинги для тестового набора\n",
    "    test['predicted_rating'] = test.apply(lambda row: predict_rating(row['userId'], row['movieId']), axis=1)\n",
    "    \n",
    "    # Вычисляем метрики\n",
    "    rmse = calculate_rmse(test)\n",
    "    mapk = calculate_mapk(test, k=10)\n",
    "    ndcgk = calculate_ndcgk(test, k=10)\n",
    "\n",
    "    item_popularity = train['movieId'].value_counts().to_dict()\n",
    "    item_similarity_matrix = 1 - pairwise_distances(matrix.T.fillna(0), metric='cosine')\n",
    "    novelty = calculate_novelty(test, item_popularity, k=10)\n",
    "    diversity = calculate_diversity(test, item_similarity_matrix, k=10, matrix_columns=matrix.columns)\n",
    "\n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAP@K': mapk,\n",
    "        'NDCG@K': ndcgk,\n",
    "        'Novelty': novelty,\n",
    "        'Diversity': diversity\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$log_2$ max: 9.25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAP@K</th>\n",
       "      <th>NDCG@K</th>\n",
       "      <th>Novelty</th>\n",
       "      <th>Diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.04326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865875</td>\n",
       "      <td>3.945203</td>\n",
       "      <td>0.798151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RMSE  MAP@K    NDCG@K   Novelty  Diversity\n",
       "1  1.04326    1.0  0.865875  3.945203   0.798151"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering = cluster_based_cf(train, test, n_clusters=40, use_z_score=False, cf_type='user')\n",
    "pd.DataFrame(clustering, index=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$log_2$ max: 9.25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAP@K</th>\n",
       "      <th>NDCG@K</th>\n",
       "      <th>Novelty</th>\n",
       "      <th>Diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.02404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.87568</td>\n",
       "      <td>3.821923</td>\n",
       "      <td>0.79185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RMSE  MAP@K   NDCG@K   Novelty  Diversity\n",
       "1  1.02404    1.0  0.87568  3.821923    0.79185"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering = cluster_based_cf(train, test, n_clusters=40, use_z_score=True, cf_type='user')\n",
    "pd.DataFrame(clustering, index=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Рекомендательная система на основе голосования\n",
    "def voting_based_cf(train, test, cf_type='user', n_neighbors=40, use_knn=False):\n",
    "    \"\"\"\n",
    "    Коллаборативная фильтрация с голосованием на основе сходства и KNN.\n",
    "\n",
    "    Параметры:\n",
    "    - train: DataFrame с обучающими данными.\n",
    "    - test: DataFrame с тестовыми данными.\n",
    "    - cf_type: 'user' для пользователь-фильм матрицы или 'item' для фильм-пользователь матрицы.\n",
    "    - n_neighbors: количество соседей для KNN или топ-N для голосования.\n",
    "    - use_knn: флаг для использования KNN вместо простого выбора топ-N похожих пользователей/фильмов.\n",
    "\n",
    "    Возвращает:\n",
    "    - RMSE для предсказанных значений.\n",
    "    \"\"\"\n",
    "    # Создаем матрицу для коллаборативной фильтрации\n",
    "    matrix = create_cf_matrix(train, cf_type=cf_type)\n",
    "    \n",
    "    # Если используем KNN\n",
    "    if use_knn:\n",
    "        knn = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine').fit(matrix.fillna(0))\n",
    "    \n",
    "    # Вычисляем косинусное сходство, если не используем KNN\n",
    "    similarity = cosine_similarity(matrix.fillna(0)) if not use_knn else None\n",
    "\n",
    "    # Функция для предсказания рейтинга\n",
    "    def predict_rating(user_id, item_id):\n",
    "        if cf_type == 'user':\n",
    "            user_index, item_index = user_id, item_id\n",
    "        else:\n",
    "            user_index, item_index = item_id, user_id\n",
    "\n",
    "        # Если пользователя или элемента нет в матрице\n",
    "        if user_index not in matrix.index or item_index not in matrix.columns:\n",
    "            return matrix.mean().mean()\n",
    "\n",
    "        # Если используем KNN\n",
    "        if use_knn:\n",
    "            # Найти ближайших соседей для пользователя\n",
    "            distances, neighbors = knn.kneighbors([matrix.fillna(0).loc[user_index]], n_neighbors=n_neighbors)\n",
    "            neighbors = neighbors.flatten()  # Индексы соседей\n",
    "        else:\n",
    "            # Вычисляем схожесть и выбираем топ-N похожих пользователей/фильмов\n",
    "            similarities = similarity[matrix.index.get_loc(user_index)]\n",
    "            neighbors = np.argsort(similarities)[-n_neighbors-1:-1]  # Топ-N соседей\n",
    "\n",
    "        # Собираем рейтинги соседей для указанного элемента\n",
    "        neighbor_ratings = matrix.iloc[neighbors][item_index].values\n",
    "        valid_ratings = neighbor_ratings[neighbor_ratings > 0]\n",
    "\n",
    "        # Если нет валидных рейтингов, возвращаем средний рейтинг пользователя\n",
    "        if len(valid_ratings) == 0:\n",
    "            return matrix.loc[user_index].mean()\n",
    "\n",
    "        # Возвращаем среднее значение рейтингов соседей\n",
    "        return valid_ratings.mean()\n",
    "\n",
    "    # Предсказываем рейтинги для тестового набора\n",
    "    test['predicted_rating'] = test.apply(lambda row: predict_rating(row['userId'], row['movieId']), axis=1)\n",
    "    \n",
    "    # Вычисляем метрики\n",
    "    rmse = calculate_rmse(test)\n",
    "    mapk = calculate_mapk(test, k=10)\n",
    "    ndcgk = calculate_ndcgk(test, k=10)\n",
    "\n",
    "    item_popularity = train['movieId'].value_counts().to_dict()\n",
    "    item_similarity_matrix = 1 - pairwise_distances(matrix.T.fillna(0), metric='cosine')\n",
    "    novelty = calculate_novelty(test, item_popularity, k=10)\n",
    "    diversity = calculate_diversity(test, item_similarity_matrix, k=10, matrix_columns=matrix.columns)\n",
    "\n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAP@K': mapk,\n",
    "        'NDCG@K': ndcgk,\n",
    "        'Novelty': novelty,\n",
    "        'Diversity': diversity\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m knn \u001b[38;5;241m=\u001b[39m \u001b[43mvoting_based_cf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcf_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_knn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(knn, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[28], line 59\u001b[0m, in \u001b[0;36mvoting_based_cf\u001b[1;34m(train, test, cf_type, n_neighbors, use_knn)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m valid_ratings\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Предсказываем рейтинги для тестового набора\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_rating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_rating\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muserId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovieId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Вычисляем метрики\u001b[39;00m\n\u001b[0;32m     62\u001b[0m rmse \u001b[38;5;241m=\u001b[39m calculate_rmse(test)\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[28], line 59\u001b[0m, in \u001b[0;36mvoting_based_cf.<locals>.<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m valid_ratings\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Предсказываем рейтинги для тестового набора\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_rating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mpredict_rating\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muserId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovieId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Вычисляем метрики\u001b[39;00m\n\u001b[0;32m     62\u001b[0m rmse \u001b[38;5;241m=\u001b[39m calculate_rmse(test)\n",
      "Cell \u001b[1;32mIn[28], line 40\u001b[0m, in \u001b[0;36mvoting_based_cf.<locals>.predict_rating\u001b[1;34m(user_id, item_id)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Если используем KNN\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_knn:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Найти ближайших соседей для пользователя\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     distances, neighbors \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     neighbors \u001b[38;5;241m=\u001b[39m neighbors\u001b[38;5;241m.\u001b[39mflatten()  \u001b[38;5;66;03m# Индексы соседей\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Вычисляем схожесть и выбираем топ-N похожих пользователей/фильмов\u001b[39;00m\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\neighbors\\_base.py:886\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    883\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 886\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2172\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2171\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 2172\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   2173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   2174\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2175\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   2176\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   2177\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   2178\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2375\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2372\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2373\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1893\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1890\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1893\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1895\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1896\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1130\u001b[0m, in \u001b[0;36mcosine_distances\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine distance between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m \n\u001b[0;32m   1097\u001b[0m \u001b[38;5;124;03mCosine distance is defined as 1.0 minus the cosine similarity.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;124;03m       [0.42..., 0.18...]])\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;66;03m# 1.0 - cosine_similarity(X, Y) without copy\u001b[39;00m\n\u001b[1;32m-> 1130\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m S \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1132\u001b[0m S \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1685\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1683\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m X_normalized\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1685\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1687\u001b[0m K \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X_normalized, Y_normalized\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39mdense_output)\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1965\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1963\u001b[0m     norms \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39msum(xp\u001b[38;5;241m.\u001b[39mabs(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1964\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m norm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1965\u001b[0m     norms \u001b[38;5;241m=\u001b[39m \u001b[43mrow_norms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m norm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1967\u001b[0m     norms \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmax(xp\u001b[38;5;241m.\u001b[39mabs(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\sklearn\\utils\\extmath.py:84\u001b[0m, in \u001b[0;36mrow_norms\u001b[1;34m(X, squared)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m     83\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(X)\n\u001b[1;32m---> 84\u001b[0m     norms \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mij,ij->i\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     norms \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39masarray(norms)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32me:\\ИТМО\\python\\git\\ITMO_subjects\\.venv\\lib\\site-packages\\numpy\\core\\einsumfunc.py:1371\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m specified_out:\n\u001b[0;32m   1370\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m-> 1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m c_einsum(\u001b[38;5;241m*\u001b[39moperands, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;66;03m# repeat default values here\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m valid_einsum_kwargs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcasting\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "knn = voting_based_cf(train, test, cf_type='user', n_neighbors=40, use_knn=True)\n",
    "pd.DataFrame(knn, index=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
