{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "with h5py.File('data/raw_data/PEMS-BAY/PEMS-BAY.h5', 'r') as file:\n",
    "\n",
    "    axis0 = file['speed']['axis0'][:]               # Идентификаторы датчиков\n",
    "    block0_items = file['speed']['block0_items'][:] # Идентификаторы датчиков\n",
    "    axis1 = file['speed']['axis1'][:]               # Метки времени\n",
    "    timestamps = pd.to_datetime(axis1)              # Преобразование меток времени в формат datetime\n",
    "    speed_data = file['speed']['block0_values'][:]  # Данные замеров скорости\n",
    "\n",
    "pems_bay = pd.DataFrame(speed_data, index=timestamps, columns=axis0)\n",
    "\n",
    "# Открытие .pkl файла\n",
    "with open('data/raw_data/PEMS-BAY/adj_PEMS-BAY.pkl', 'rb') as file:\n",
    "    data = pickle.load(file, encoding='bytes')\n",
    "    \n",
    "node_ids = [x.decode('utf-8') for x in data[0]]                     # Получаем список id узлов из data[0]\n",
    "adj_matrix = data[2]                                                # Получаем матрицу смежности из data[2]\n",
    "adj_df = pd.DataFrame(adj_matrix, index=node_ids, columns=node_ids) # Создание DataFrame с использованием id узлов как индексов и названий колонок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методология\n",
    "\n",
    "#### 1. **Преобразование Фурье**\n",
    "   - **Проблема Time-Shift**: В статье утверждается, что проблема Time-Shift (сдвига во времени) затрудняет моделирование пространственной зависимости в данных о трафике. Для решения этой проблемы предлагается использовать преобразование Фурье, которое переводит данные о трафике в частотную область.\n",
    "   - **Математическое обоснование**: \n",
    "     - Пусть $ f(t) $ — данные о трафике, захваченные сенсорами на определенном перекрестке. Если трафик задерживается на время $ t_0 $, то данные $ f(t-t_0) $ будут захвачены на следующем перекрестке.\n",
    "     - Согласно определению преобразования Фурье:\n",
    "       $$\n",
    "       F(\\omega) = \\int_{-\\infty}^{\\infty} f(t) e^{-j\\omega t} dt\n",
    "       $$\n",
    "       $$\n",
    "       F_{t_0}(\\omega) = \\int_{-\\infty}^{\\infty} f(t-t_0) e^{-j\\omega t} dt\n",
    "       $$\n",
    "     - После преобразований доказывается, что $ F_{t_0}(\\omega) = F(\\omega) \\cdot e^{-j\\omega t_0} $, что означает, что данные в частотной области представлены в одной фазовой размерности, что упрощает изучение пространственных зависимостей между сенсорами.\n",
    "\n",
    "#### 2. **DFDGCN (Dynamic Frequency Domain Graph Convolutional Network)**\n",
    "   - **Модуль частотной области**: Основная идея DFDGCN заключается в обновлении динамической матрицы смежности $ A_D $ на основе данных о трафике, наблюдаемых в текущем окне наблюдения.\n",
    "   - **Шаги модуля**:\n",
    "     1. **Преобразование Фурье**: Данные о трафике $ X_t $ в каждом окне наблюдения переводятся в частотную область с помощью быстрого преобразования Фурье (FFT):\n",
    "        $$\n",
    "        F_t = FFT(X_t)\n",
    "        $$\n",
    "     2. **Встраивание идентичности и времени**: Для уменьшения влияния шума в данных о трафике вводятся встраивания идентичности сенсоров $ E_t $ и временные встраивания $ T^{W}_t $ (день недели) и $ T^{D}_t $ (час дня):\n",
    "        $$\n",
    "        DE_t = W_{F,t} \\cdot F_t || E_t || W_{T,t} \\cdot (T^{W}_t || T^{D}_t)\n",
    "        $$\n",
    "     3. **Одномерная свертка**: Применяется одномерная сверточная слой с ядром $ 1 \\times 1 $ для дополнительного встраивания, чтобы изучить связи между измерениями $ DE_t $.\n",
    "     4. **Полносвязный слой и матричное умножение**: Применяется полносвязный слой для изучения $ DE_t $, затем результат умножается на транспонированную матрицу $ DE_t $. После активационной функции и $ Softmax $ получается финальная матрица смежности:\n",
    "        $$\n",
    "        A^{t}_D = Softmax(ReLU(DE_t W_{adj} DE^{T}_t))\n",
    "        $$\n",
    "     5. **Граф сверточный слой**: Динамический частотный граф комбинируется с предопределенными графами $ P $ (из DCRNN) и самоадаптивными графами $ A_{adt} $ (из GWNet) для создания графового сверточного слоя:\n",
    "        $$\n",
    "        Z_t = \\sum_{k=0}^{K} (P^{k} X_t W_{k,1} + A^{k}_{adt} X_t W_{k,2} + A^{t}_D X_t W_{k,3})\n",
    "        $$\n",
    "     6. **Обработка временной информации**: Для обработки временной информации используется классическая причинная свертка с остаточной сетью, как в GWNet.\n",
    "\n",
    "#### 3. **Эксперименты**\n",
    "   - **Датасеты**: Эксперименты проводятся на четырех реальных датасетах с десятками тысяч временных шагов и сотнями сенсоров. Статистика датасетов представлена в таблице 1.\n",
    "   - **Базовые линии и метрики**: В качестве базовых линий выбраны классические методы, такие как HI, GWNet, DCRNN, AGCRN, STGCN, MTGNN, DGCRN. Метрики оценки включают среднюю абсолютную ошибку (MAE), среднеквадратичную ошибку (RMSE) и среднюю абсолютную процентную ошибку (MAPE).\n",
    "   - **Настройки экспериментов**: Датасеты делятся на обучающую, валидационную и тестовую выборки в соотношении 7:1:2. Предсказываются данные о трафике на 12 временных шагов с использованием исторических данных длиной 12. Размеры встраиваний после преобразования Фурье и идентичности составляют 10, а временные встраивания $ T^{W}_t $ и $ T^{D}_t $ — 12. Размер встраивания после одномерной свертки — 30.\n",
    "   - **Результаты экспериментов**: DFDGCN показывает лучшие результаты по сравнению с базовыми линиями на всех датасетах. Анализ аблационных экспериментов подтверждает эффективность частотного графа в моделировании динамической пространственной зависимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры\n",
    "B = 32  # Размер батча\n",
    "N = 325  # Количество датчиков\n",
    "L = 12  # Длина временного окна\n",
    "fft_emb = 10  # Размерность эмбеддинга частотной области\n",
    "identity_emb = 10  # Размерность эмбеддинга идентичности\n",
    "T_D_size = 12  # Размерность эмбеддингов времени (например, день недели)\n",
    "D_W_size = 12  # Размерность эмбеддингов времени (например, час дня)\n",
    "hidden_emb = 30\n",
    "\n",
    "# Создание случайных данных для history_data (размер: B, L, N, 1)\n",
    "history_data = torch.randn(B, N, L, 1)\n",
    "\n",
    "# Эмбеддинги\n",
    "Ex1 = torch.randn(L//2 + 1, fft_emb)  # Эмбеддинг частотной области, размер: (L//2+1, fft_emb)\n",
    "node1 = torch.randn(N, identity_emb)  # Эмбеддинг идентичности, размер: (N, identity_emb)\n",
    "T_D_emb = torch.randn(B, N, T_D_size)  # Эмбеддинг дня недели, размер: (B, N, T_D_size)\n",
    "D_W_emb = torch.randn(B, N, D_W_size)  # Эмбеддинг часа дня, размер: (B, N, D_W_size)\n",
    "Wd = torch.randn(N, fft_emb + identity_emb + L * 2, hidden_emb)\n",
    "Wxabs = torch.randn(hidden_emb, hidden_emb)\n",
    "\n",
    "# Логгер для записи в текстовый файл\n",
    "def log_tensor_size(tensor, description, log_file='tensor_sizes.txt'):\n",
    "    with open(log_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(f\"{description}: {tensor.shape}\\n\")\n",
    "\n",
    "# Преобразование Фурье по оси L (по временным данным)\n",
    "xn1 = torch.fft.rfft(history_data.squeeze(-1), dim=-1)  # Преобразование Фурье, размер: [B, N, L//2+1]\n",
    "log_tensor_size(xn1, \"После преобразования Фурье xn1\")\n",
    "\n",
    "xn1 = torch.abs(xn1)  # Абсолютное значение\n",
    "log_tensor_size(xn1, \"После применения abs(xn1)\")\n",
    "\n",
    "# Нормализация данных в частотной области\n",
    "xn1 = F.normalize(xn1, p=2.0, dim=1)  # Нормализация по оси N\n",
    "log_tensor_size(xn1, \"После нормализации по оси N\")\n",
    "\n",
    "xn1 = F.normalize(xn1, p=2.0, dim=2)  # Нормализация по оси L//2+1\n",
    "log_tensor_size(xn1, \"После нормализации по оси L//2+1\")\n",
    "\n",
    "# Перемножение с Ex1 (embedding для частотной области)\n",
    "xn1 = torch.matmul(xn1, Ex1)  # Размерность: [B, N, fft_emb]\n",
    "log_tensor_size(xn1, \"После перемножения с Ex1\")\n",
    "\n",
    "# Конкатенация с идентичностью и временными эмбеддингами\n",
    "xn1k = torch.cat([xn1, node1.unsqueeze(0).expand(B, -1, -1)], dim=2)  # Размерность: [B, N, fft_emb + identity_emb]\n",
    "log_tensor_size(xn1k, \"После конкатенации с node1\")\n",
    "\n",
    "x_n1 = torch.cat([xn1k, T_D_emb, D_W_emb], dim=2)  # Размерность: [B, N, fft_emb + identity_emb + T_D_size + D_W_size]\n",
    "log_tensor_size(x_n1, \"После конкатенации с T_D_emb и D_W_emb\")\n",
    "\n",
    "x1 = torch.bmm(x_n1.permute(1,0,2), Wd).permute(1,0,2)\n",
    "log_tensor_size(x1, \"После перемножения с Wd\")\n",
    "\n",
    "# Итоговый размер после конкатенации\n",
    "log_tensor_size(x1, \"Размер после конкатенации всех эмбеддингов\")\n",
    "\n",
    "adp = torch.einsum('bne, ek->bnk', (x1, Wxabs))\n",
    "log_tensor_size(adp, \"Размер после свертки\")\n",
    "\n",
    "adj = torch.bmm(adp, x1.permute(0, 2, 1))\n",
    "log_tensor_size(adj, \"Размер матрицы смежности\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример: pems_bay.index содержит DatetimeIndex\n",
    "# Если pems_bay уже загружен как DataFrame:\n",
    "index = pems_bay.index\n",
    "\n",
    "# 1. Добавляем колонку для индексов дня недели (0 - понедельник, 6 - воскресенье)\n",
    "pems_bay[\"weekday\"] = index.weekday  # День недели от 0 до 6\n",
    "\n",
    "# 2. Добавляем колонку для временного индекса в течение дня\n",
    "# 288 интервалов = 24 часа * 12 (каждые 5 минут)\n",
    "pems_bay[\"time_index\"] = (index.hour * 12) + (index.minute // 5)\n",
    "\n",
    "# 3. Преобразуем данные в тензор\n",
    "# Учитываем: [B, L, N, C], где C = [трафик, день недели, временной индекс]\n",
    "traffic_data = pems_bay.iloc[:12, :-2].values  # Берем первые 12 временных шагов\n",
    "weekday_data = pems_bay[\"weekday\"].iloc[:12].values[:, np.newaxis]  # Колонка weekday\n",
    "time_index_data = pems_bay[\"time_index\"].iloc[:12].values[:, np.newaxis]  # Колонка time_index\n",
    "\n",
    "# Добавляем размерность канала C к данным о трафике\n",
    "traffic_data = torch.tensor(traffic_data).float().unsqueeze(-1)  # [L, N, 1]\n",
    "\n",
    "# Добавляем размерность канала C к weekday_data и time_index_data\n",
    "weekday_data = torch.tensor(weekday_data).float().unsqueeze(-1)  # [L, 1, 1]\n",
    "time_index_data = torch.tensor(time_index_data).float().unsqueeze(-1)  # [L, 1, 1]\n",
    "\n",
    "# Расширяем размерность N для weekday_data и time_index_data, чтобы они соответствовали traffic_data\n",
    "weekday_data = weekday_data.expand(-1, traffic_data.size(1), -1)  # [L, N, 1]\n",
    "time_index_data = time_index_data.expand(-1, traffic_data.size(1), -1)  # [L, N, 1]\n",
    "\n",
    "# Объединяем все данные вдоль оси каналов C\n",
    "combined_data = torch.cat([traffic_data, time_index_data, weekday_data], dim=-1)  # [L, N, 3]\n",
    "\n",
    "# Добавляем размерность батча B (первая размерность)\n",
    "combined_data = combined_data.unsqueeze(0)  # [1, L, N, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.shape = torch.Size([1, 2, 325, 12])\n",
      "in_len = 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 325, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class convt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convt, self).__init__()\n",
    "\n",
    "    def forward(self, x, w):\n",
    "        x = torch.einsum('bne, ek->bnk', (x, w))\n",
    "        return x.contiguous()\n",
    "    \n",
    "class nconv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(nconv, self).__init__()\n",
    "\n",
    "    def forward(self, x, A, dims):\n",
    "        if dims == 2:\n",
    "            x = torch.einsum('ncvl,vw->ncwl', (x, A))\n",
    "        elif dims == 3:\n",
    "            x = torch.einsum('ncvl,nvw->ncwl', (x, A))\n",
    "        else:\n",
    "            raise NotImplementedError('DFDGCN not implemented for A of dimension ' + str(dims))\n",
    "        return x.contiguous()\n",
    "\n",
    "class linear(nn.Module):\n",
    "    \"\"\"Linear layer.\"\"\"\n",
    "\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(linear, self).__init__()\n",
    "        self.mlp = torch.nn.Conv2d(c_in, c_out, kernel_size=(\n",
    "            1, 1), padding=(0, 0), stride=(1, 1), bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class gcn(nn.Module):\n",
    "    \"\"\"Graph convolution network.\"\"\"\n",
    "\n",
    "    def __init__(self, c_in, c_out, dropout, support_len=3, order=2):\n",
    "        super(gcn, self).__init__()\n",
    "        self.nconv = nconv()\n",
    "\n",
    "        self.c_in = c_in\n",
    "        c_in = (order * (support_len + 1) + 1) * self.c_in\n",
    "        self.mlp = linear(c_in, c_out)\n",
    "        self.dropout = dropout\n",
    "        self.order = order\n",
    "\n",
    "    def forward(self, x, support):\n",
    "\n",
    "        out = [x]\n",
    "        for a in support:\n",
    "            x1 = self.nconv(x, a.to(x.device), a.dim())\n",
    "            out.append(x1)\n",
    "\n",
    "            for k in range(2, self.order + 1):\n",
    "                x2 = self.nconv(x1, a.to(x1.device), a.dim())\n",
    "                out.append(x2)\n",
    "                x1 = x2\n",
    "        h = torch.cat(out, dim=1)\n",
    "        h = self.mlp(h)\n",
    "        h = F.dropout(h, self.dropout, training=self.training)\n",
    "        return h\n",
    "\n",
    "def dy_mask_graph(adj, k):\n",
    "    M = []\n",
    "    for i in range(adj.size(0)):\n",
    "        adp = adj[i]\n",
    "        mask = torch.zeros( adj.size(1),adj.size(2)).to(adj.device)\n",
    "        mask = mask.fill_(float(\"0\"))\n",
    "        s1, t1 = (adp + torch.rand_like(adp) * 0.01).topk(k, 1)\n",
    "        mask = mask.scatter_(1, t1, s1.fill_(1))\n",
    "        M.append(mask)\n",
    "    mask = torch.stack(M,dim=0)\n",
    "    adj = adj * mask\n",
    "    return adj\n",
    "\n",
    "def cat(x1,x2):\n",
    "    M = []\n",
    "    for i in range(x1.size(0)):\n",
    "        x = x1[i]\n",
    "        new_x = torch.cat([x,x2],dim=1)\n",
    "        M.append(new_x)\n",
    "    result = torch.stack(M,dim=0)\n",
    "    return result\n",
    "\n",
    "\n",
    "class DFDGCN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_nodes, dropout=0.3, supports=None,\n",
    "                    gcn_bool=True, addaptadj=True, aptinit=None,\n",
    "                    in_dim=2, out_dim=12, residual_channels=32,\n",
    "                    dilation_channels=32, skip_channels=256, end_channels=512,\n",
    "                    kernel_size=2, blocks=4, layers=2, a=1, seq_len=12, affine=True, fft_emb=10, identity_emb=10, hidden_emb=30, subgraph=20):\n",
    "        super(DFDGCN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.blocks = blocks\n",
    "        self.layers = layers\n",
    "        self.gcn_bool = gcn_bool\n",
    "        self.addaptadj = addaptadj\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs = nn.ModuleList()\n",
    "        self.residual_convs = nn.ModuleList()\n",
    "        self.skip_convs = nn.ModuleList()\n",
    "        self.bn = nn.ModuleList()\n",
    "        self.gconv = nn.ModuleList()\n",
    "        self.seq_len = seq_len\n",
    "        self.a = a\n",
    "\n",
    "        self.start_conv = nn.Conv2d(in_channels=in_dim,\n",
    "                                    out_channels=residual_channels,\n",
    "                                    kernel_size=(1, 1))\n",
    "\n",
    "        self.supports = supports\n",
    "        self.emb = fft_emb\n",
    "        self.subgraph_size = subgraph\n",
    "        self.identity_emb = identity_emb\n",
    "        self.hidden_emb = hidden_emb\n",
    "        self.fft_len = round(seq_len//2) + 1\n",
    "        self.Ex1 = nn.Parameter(torch.randn(self.fft_len, self.emb), requires_grad=True)\n",
    "        self.Wd = nn.Parameter(torch.randn(num_nodes,self.emb + self.identity_emb + self.seq_len * 2, self.hidden_emb), requires_grad=True)\n",
    "        self.Wxabs = nn.Parameter(torch.randn(self.hidden_emb, self.hidden_emb), requires_grad=True)\n",
    "\n",
    "        self.mlp = linear(residual_channels * 4,residual_channels)\n",
    "        self.layersnorm = torch.nn.LayerNorm(normalized_shape=[num_nodes,self.hidden_emb], eps=1e-08,elementwise_affine=affine)\n",
    "        self.convt = convt()\n",
    "\n",
    "        self.node1 = nn.Parameter(\n",
    "            torch.randn(num_nodes, self.identity_emb), requires_grad=True)\n",
    "        self.drop = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.T_i_D_emb = nn.Parameter(\n",
    "            torch.empty(288, self.seq_len))\n",
    "        self.D_i_W_emb = nn.Parameter(\n",
    "            torch.empty(7, self.seq_len))\n",
    "\n",
    "        receptive_field = 1\n",
    "        self.reset_parameter()\n",
    "        self.supports_len = 0\n",
    "        if not addaptadj:\n",
    "            self.supports_len -= 1\n",
    "        if supports is not None:\n",
    "            self.supports_len += len(supports)\n",
    "        if gcn_bool and addaptadj:\n",
    "            if aptinit is None:\n",
    "                if supports is None:\n",
    "                    self.supports = []\n",
    "                self.nodevec1 = nn.Parameter(\n",
    "                    torch.randn(num_nodes, self.emb), requires_grad=True)\n",
    "                self.nodevec2 = nn.Parameter(\n",
    "                    torch.randn(self.emb, num_nodes), requires_grad=True)\n",
    "                self.supports_len += 1\n",
    "            else:\n",
    "                if supports is None:\n",
    "                    self.supports = []\n",
    "                m, p, n = torch.svd(aptinit)\n",
    "                initemb1 = torch.mm(m[:, :10], torch.diag(p[:10] ** 0.5))\n",
    "                initemb2 = torch.mm(torch.diag(p[:10] ** 0.5), n[:, :10].t())\n",
    "                self.nodevec1 = nn.Parameter(initemb1, requires_grad=True)\n",
    "                self.nodevec2 = nn.Parameter(initemb2, requires_grad=True)\n",
    "                self.supports_len += 1\n",
    "\n",
    "        for b in range(blocks):\n",
    "            additional_scope = kernel_size - 1\n",
    "            new_dilation = 1\n",
    "            for i in range(layers):\n",
    "                # dilated convolutions\n",
    "                self.filter_convs.append(nn.Conv2d(in_channels=residual_channels,\n",
    "                                                   out_channels=dilation_channels,\n",
    "                                                   kernel_size=(1, kernel_size), dilation=new_dilation))\n",
    "\n",
    "                self.gate_convs.append(nn.Conv2d(in_channels=residual_channels,\n",
    "                                                 out_channels=dilation_channels,\n",
    "                                                 kernel_size=(1, kernel_size), dilation=new_dilation))\n",
    "\n",
    "                # 1x1 convolution for residual connection\n",
    "                self.residual_convs.append(nn.Conv2d(in_channels=dilation_channels,\n",
    "                                                     out_channels=residual_channels,\n",
    "                                                     kernel_size=(1, 1)))\n",
    "\n",
    "                # 1x1 convolution for skip connection\n",
    "                self.skip_convs.append(nn.Conv2d(in_channels=dilation_channels,\n",
    "                                                 out_channels=skip_channels,\n",
    "                                                 kernel_size=(1, 1)))\n",
    "                self.bn.append(nn.BatchNorm2d(residual_channels))\n",
    "                new_dilation *= 2\n",
    "                receptive_field += additional_scope\n",
    "                additional_scope *= 2\n",
    "                if self.gcn_bool:\n",
    "                    self.gconv.append(\n",
    "                        gcn(dilation_channels, residual_channels, dropout, support_len=self.supports_len))\n",
    "        self.end_conv_1 = nn.Conv2d(in_channels=skip_channels,\n",
    "                                    out_channels=end_channels,\n",
    "                                    kernel_size=(1, 1),\n",
    "                                    bias=True)\n",
    "\n",
    "        self.end_conv_2 = nn.Conv2d(in_channels=end_channels,\n",
    "                                    out_channels=out_dim,\n",
    "                                    kernel_size=(1, 1),\n",
    "                                    bias=True)\n",
    "\n",
    "        self.receptive_field = receptive_field\n",
    "\n",
    "    def reset_parameter(self):\n",
    "        nn.init.xavier_uniform_(self.T_i_D_emb)\n",
    "        nn.init.xavier_uniform_(self.D_i_W_emb)\n",
    "\n",
    "\n",
    "    def forward(self, history_data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Feedforward function of DFDGCN; Based on Graph WaveNet\n",
    "\n",
    "        Args:\n",
    "            history_data (torch.Tensor): shape [B, L, N, C]\n",
    "\n",
    "        Graphs:\n",
    "            predefined graphs: two graphs; [2, N, N] : Pre-given graph structure, including in-degree and out-degree graphs\n",
    "\n",
    "            self-adaptive graph: [N, N] : Self-Adaptively constructed graphs with two learnable parameters\n",
    "                torch.mm(self.nodevec1, self.nodevec2)\n",
    "                    nodevec: [N, Emb]\n",
    "\n",
    "            dynamic frequency domain graph: [B, N, N] : Data-driven graphs constructed with frequency domain information from traffic data\n",
    "                traffic_data : [B, N, L]\n",
    "                frequency domain information : [B, N, L/2.round + 1] ------Embedding ------[B, N, Emb2]\n",
    "                Identity embedding : learnable parameter [N, Emb3]\n",
    "                Time embedding : Week and Day : [N, 7] [N, 24(hour) * 12 (60min / 5min due to sampling)] ------Embedding ------ [N, 2 * Emb4]\n",
    "                Concat frequency domain information + Identity embedding + Time embedding ------Embedding , Activating, Normalization and Dropout\n",
    "                Conv1d to get adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: [B, L, N, 1]\n",
    "        \"\"\"\n",
    "        #num_feat = model_args[\"num_feat\"]\n",
    "        input = history_data.transpose(1, 3).contiguous()[:,0:2,:,:]\n",
    "        data = history_data\n",
    "\n",
    "        in_len = input.size(3)\n",
    "        if in_len < self.receptive_field:\n",
    "            x = nn.functional.pad(\n",
    "                input, (self.receptive_field-in_len, 0, 0, 0))\n",
    "        else:\n",
    "            x = input\n",
    "        x = self.start_conv(x)\n",
    "\n",
    "        skip = 0\n",
    "        if self.gcn_bool and self.addaptadj and self.supports is not None:\n",
    "\n",
    "\n",
    "            gwadp = F.softmax(\n",
    "                F.relu(torch.mm(self.nodevec1, self.nodevec2)), dim=1)\n",
    "\n",
    "            new_supports = self.supports + [gwadp] # pretrained graph in DCRNN and self-adaptive graph in GWNet\n",
    "\n",
    "            # Construction of dynamic frequency domain graph\n",
    "            xn1 = input[:, 0, :, -self.seq_len:]\n",
    "\n",
    "            # T_D = self.T_i_D_emb[(data[:, :, :, 1] * 288).type(torch.LongTensor)][:, -1, :, :]\n",
    "            T_D = self.T_i_D_emb[(data[:, :, :, 1]).type(torch.LongTensor)][:, -1, :, :]\n",
    "            D_W = self.D_i_W_emb[(data[:, :, :, 1 + 1]).type(torch.LongTensor)][:, -1, :, :]\n",
    "\n",
    "            xn1 = torch.fft.rfft(xn1, dim=-1)\n",
    "            xn1 = torch.abs(xn1)\n",
    "\n",
    "            xn1 = torch.nn.functional.normalize(xn1, p=2.0, dim=1, eps=1e-12, out=None)\n",
    "            xn1 = torch.nn.functional.normalize(xn1, p=2.0, dim=2, eps=1e-12, out=None) * self.a\n",
    "\n",
    "\n",
    "            xn1 = torch.matmul(xn1, self.Ex1)\n",
    "            xn1k = cat(xn1, self.node1)\n",
    "            x_n1 = torch.cat([xn1k, T_D, D_W], dim=2)\n",
    "            x1 = torch.bmm(x_n1.permute(1,0,2),self.Wd).permute(1,0,2)\n",
    "            x1 = torch.relu(x1)\n",
    "            x1k = self.layersnorm(x1)\n",
    "            x1k = self.drop(x1k)\n",
    "            adp = self.convt(x1k, self.Wxabs)\n",
    "            adj = torch.bmm(adp, x1.permute(0, 2, 1))\n",
    "            adp = torch.relu(adj)\n",
    "            adp = dy_mask_graph(adp, self.subgraph_size)\n",
    "            adp = F.softmax(adp, dim=2)\n",
    "            new_supports = new_supports + [adp]\n",
    "\n",
    "\n",
    "\n",
    "        # WaveNet layers\n",
    "        for i in range(self.blocks * self.layers):\n",
    "\n",
    "            #            |----------------------------------------|     *residual*\n",
    "            #            |                                        |\n",
    "            #            |    |-- conv -- tanh --|                |\n",
    "            # -> dilate -|----|                  * ----|-- 1x1 -- + -->\t*input*\n",
    "            #                 |-- conv -- sigm --|     |\n",
    "            #                                         1x1\n",
    "            #                                          |\n",
    "            # ---------------------------------------> + ------------->\t*skip*\n",
    "\n",
    "\n",
    "            # dilated convolution\n",
    "            residual = x\n",
    "            filter = self.filter_convs[i](residual)\n",
    "            filter = torch.tanh(filter)\n",
    "            gate = self.gate_convs[i](residual)\n",
    "            gate = torch.sigmoid(gate)\n",
    "            x = filter * gate\n",
    "\n",
    "            # parametrized skip connection\n",
    "\n",
    "            s = x\n",
    "\n",
    "            s = self.skip_convs[i](s)\n",
    "            try:\n",
    "                skip = skip[:, :, :,  -s.size(3):]\n",
    "\n",
    "            except:\n",
    "                skip = 0\n",
    "            skip = s + skip\n",
    "\n",
    "            if self.gcn_bool and self.supports is not None:\n",
    "                if self.addaptadj:\n",
    "                    x = self.gconv[i](x, new_supports)\n",
    "\n",
    "                else:\n",
    "                    x = self.gconv[i](x, self.supports)\n",
    "            else:\n",
    "                x = self.residual_convs[i](x)\n",
    "            x = x + residual[:, :, :, -x.size(3):]\n",
    "\n",
    "            x = self.bn[i](x)\n",
    "\n",
    "        x = F.relu(skip)\n",
    "        x = F.relu(self.end_conv_1(x))\n",
    "        x = self.end_conv_2(x)\n",
    "        return x\n",
    "    \n",
    "supports = [torch.tensor(adj_df.to_numpy(), dtype=torch.float32)]\n",
    "model = DFDGCN(num_nodes=adj_df.shape[0], supports=supports)\n",
    "\n",
    "model(combined_data).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
