{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "import folium\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "with h5py.File('data/PEMS-BAY/pems-bay.h5', 'r') as file:\n",
    "\n",
    "    axis0 = file['speed']['axis0'][:]               # Идентификаторы датчиков\n",
    "    block0_items = file['speed']['block0_items'][:] # Идентификаторы датчиков\n",
    "    axis1 = file['speed']['axis1'][:]               # Метки времени\n",
    "    timestamps = pd.to_datetime(axis1)              # Преобразование меток времени в формат datetime\n",
    "    speed_data = file['speed']['block0_values'][:]  # Данные замеров скорости\n",
    "\n",
    "pems_bay = pd.DataFrame(speed_data, index=timestamps, columns=axis0)\n",
    "\n",
    "# Открытие .pkl файла\n",
    "with open('data/PEMS-BAY/adj_mx_bay.pkl', 'rb') as file:\n",
    "    data = pickle.load(file, encoding='bytes')\n",
    "    \n",
    "node_ids = [x.decode('utf-8') for x in data[0]]                     # Получаем список id узлов из data[0]\n",
    "adj_matrix = data[2]                                                # Получаем матрицу смежности из data[2]\n",
    "adj_df = pd.DataFrame(adj_matrix, index=node_ids, columns=node_ids) # Создание DataFrame с использованием id узлов как индексов и названий колонок\n",
    "\n",
    "distances_df = pd.read_csv('data/PEMS-BAY/distances_bay_2017.csv', header=None)\n",
    "locations_df = pd.read_csv('data/PEMS-BAY/graph_sensor_locations_bay.csv', header=None)\n",
    "distances_df.columns = ['from', 'to', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x, y, t\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Create DataLoaders\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTrafficDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     86\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m TrafficDataset(X_val, y_val, seq_len)\n",
      "Cell \u001b[1;32mIn[80], line 70\u001b[0m, in \u001b[0;36mTrafficDataset.__init__\u001b[1;34m(self, X, y, seq_len)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len \u001b[38;5;241m=\u001b[39m seq_len\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_steps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "\n",
    "# Remove self-loops from adjacency matrix\n",
    "adj_df.values[np.arange(325), np.arange(325)] = 0\n",
    "\n",
    "# Normalize adjacency matrix\n",
    "adj = adj_df.values\n",
    "adj = adj + np.eye(325)\n",
    "degrees = np.sum(adj, axis=1)\n",
    "degrees_inv_sqrt = np.diag(1.0 / np.sqrt(degrees))\n",
    "adj_norm = degrees_inv_sqrt @ adj @ degrees_inv_sqrt\n",
    "adj_tensor = torch.FloatTensor(adj_norm)\n",
    "\n",
    "# Normalize traffic data\n",
    "scaler = StandardScaler()\n",
    "pems_bay_scaled = scaler.fit_transform(pems_bay.values)\n",
    "\n",
    "# Convert to tensor\n",
    "X = torch.FloatTensor(pems_bay_scaled).permute(1, 0)  # Shape: [N, T]\n",
    "\n",
    "# Parameters\n",
    "N = 325  # Number of sensors\n",
    "T = X.shape[1]\n",
    "seq_len = 12\n",
    "pre_len = 3\n",
    "num_features = 1\n",
    "emb_dim = 10\n",
    "time_emb_dim = 12\n",
    "hid_dim = 32\n",
    "num_layers = 2\n",
    "batch_size = 32\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, seq_len, pre_len):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data[0]) - seq_len - pre_len + 1):\n",
    "        x = data[:, i:i+seq_len]\n",
    "        y = data[:, i+seq_len:i+seq_len+pre_len]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return torch.stack(xs), torch.stack(ys)\n",
    "\n",
    "# Create sequences\n",
    "X_seq, y_seq = create_sequences(X, seq_len, pre_len)\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "train_size = int(X_seq.size(0) * 0.7)\n",
    "val_size = int(X_seq.size(0) * 0.1)\n",
    "test_size = X_seq.size(0) - train_size - val_size\n",
    "\n",
    "X_train, y_train = X_seq[:train_size], y_seq[:train_size]\n",
    "X_val, y_val = X_seq[train_size:train_size+val_size], y_seq[train_size:train_size+val_size]\n",
    "X_test, y_test = X_seq[train_size+val_size:], y_seq[train_size+val_size:]\n",
    "\n",
    "# Custom Dataset class\n",
    "class TrafficDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, seq_len):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.seq_len = seq_len\n",
    "        self.N, self.T = X.shape\n",
    "        self.time_steps = torch.arange(self.seq_len)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        t = self.time_steps\n",
    "        return x, y, t\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TrafficDataset(X_train, y_train, seq_len)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TrafficDataset(X_val, y_val, seq_len)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = TrafficDataset(X_test, y_test, seq_len)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Fourier Transform\n",
    "class FourierTransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FourierTransform, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        fft = torch.fft.fft(x, dim=1)\n",
    "        magnitude = torch.abs(fft)\n",
    "        phase = torch.angle(fft)\n",
    "        return magnitude, phase\n",
    "\n",
    "# Embedding Layers\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, N, emb_dim, seq_len, time_emb_dim):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.identity_emb = nn.Embedding(N, emb_dim)\n",
    "        self.time_emb = nn.Embedding(seq_len, time_emb_dim)  # Time embedding for each time step\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        identity = self.identity_emb(torch.arange(N, device=x.device))\n",
    "        time = self.time_emb(t)\n",
    "        return identity, time\n",
    "\n",
    "# Dynamic Graph Construction\n",
    "class DynamicGraph(nn.Module):\n",
    "    def __init__(self, N, emb_dim, time_emb_dim):\n",
    "        super(DynamicGraph, self).__init__()\n",
    "        self.fc1 = nn.Linear(emb_dim + time_emb_dim, hid_dim)\n",
    "        self.fc2 = nn.Linear(hid_dim, N)\n",
    "    \n",
    "    def forward(self, x, identity, time):\n",
    "        x = torch.cat([x, identity, time], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        adj = self.fc2(x)\n",
    "        adj = F.softmax(adj, dim=1)\n",
    "        return adj\n",
    "\n",
    "# Graph Convolution Layer\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features, adj):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.adj = adj\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        support = torch.matmul(input, self.weight)\n",
    "        output = torch.matmul(self.adj, support) + self.bias\n",
    "        return output\n",
    "\n",
    "# Temporal Convolution Layer\n",
    "class TemporalConvolution(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(TemporalConvolution, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# DFDGCN Model\n",
    "class DFDGCN(nn.Module):\n",
    "    def __init__(self, N, seq_len, num_features, adj, emb_dim, time_emb_dim, hid_dim, num_layers):\n",
    "        super(DFDGCN, self).__init__()\n",
    "        self.N = N\n",
    "        self.seq_len = seq_len\n",
    "        self.num_features = num_features\n",
    "        self.emb_dim = emb_dim\n",
    "        self.time_emb_dim = time_emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.fft = FourierTransform()\n",
    "        self.embedding = EmbeddingLayer(N, emb_dim, seq_len, time_emb_dim)\n",
    "        self.dynamic_graph = DynamicGraph(N, emb_dim, time_emb_dim)\n",
    "        self.gconv_layers = nn.ModuleList([GraphConvolution(hid_dim, hid_dim, adj) for _ in range(num_layers)])\n",
    "        self.tconv_layers = nn.ModuleList([TemporalConvolution(hid_dim, hid_dim, 3) for _ in range(num_layers)])\n",
    "        self.fc = nn.Linear(hid_dim, num_features)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # x: [N, seq_len, batch_size]\n",
    "        # t: [seq_len]\n",
    "        magnitude, phase = self.fft(x)\n",
    "        identity, time = self.embedding(x, t)\n",
    "        adj_dynamic = self.dynamic_graph(x, identity, time)\n",
    "        \n",
    "        h = torch.cat([magnitude, phase], dim=1)\n",
    "        h = h.unsqueeze(2)  # [N, 2*seq_len, 1]\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            h_g = self.gconv_layers[i](h[:, :, i])\n",
    "            h_t = self.tconv_layers[i](h[:, :, i].unsqueeze(0))\n",
    "            h = h_g + h_t\n",
    "            h = F.relu(h)\n",
    "        \n",
    "        out = self.fc(h)\n",
    "        return out\n",
    "\n",
    "# Training function\n",
    "def train(model, optimizer, criterion, dataloader, adj, num_epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (x, y, t) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            output = model(x, t)\n",
    "            # Compute loss\n",
    "            loss = criterion(output, y)\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f'Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, criterion, dataloader, adj):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, t in dataloader:\n",
    "            output = model(x, t)\n",
    "            loss = criterion(output, y)\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "# Instantiate the model, optimizer, and criterion\n",
    "model = DFDGCN(N, seq_len, num_features, adj_tensor, emb_dim, time_emb_dim, hid_dim, num_layers)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train(model, optimizer, criterion, train_loader, adj_tensor, num_epochs=10)\n",
    "\n",
    "# Evaluate the model on validation set\n",
    "val_loss = evaluate(model, criterion, val_loader, adj_tensor)\n",
    "print(f'Validation Loss: {val_loss}')\n",
    "\n",
    "# Evaluate the model on test set\n",
    "test_loss = evaluate(model, criterion, test_loader, adj_tensor)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_t shape: torch.Size([32, 12, 325])\n",
      "y shape: torch.Size([32, 3, 325])\n",
      "week_idx: tensor([2, 1, 1, 0, 4, 1, 0, 0, 1, 3, 6, 4, 1, 0, 4, 6, 5, 3, 2, 4, 6, 3, 0, 4,\n",
      "        0, 0, 4, 3, 0, 4, 6, 3])\n",
      "day_idx: tensor([ 5, 11, 20, 17, 15, 16, 23, 18, 23, 15, 19,  4,  5, 17, 18, 19,  0, 15,\n",
      "        17,  8,  0, 20,  9,  8, 22, 11,  4,  7,  8, 20, 11, 21])\n",
      "adj shape: torch.Size([32, 325, 325])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class TrafficDataset(Dataset):\n",
    "    def __init__(self, pems_bay, adj_df, seq_len, pre_len):\n",
    "        \"\"\"\n",
    "        Инициализация датасета.\n",
    "        \n",
    "        :param pems_bay: pd.DataFrame, временные ряды трафика (в формате (время, узлы)).\n",
    "        :param adj_df: pd.DataFrame, матрица смежности.\n",
    "        :param seq_len: int, длина окна видимости (временного ряда для обучения).\n",
    "        :param pre_len: int, длина окна предсказания.\n",
    "        \"\"\"\n",
    "        self.pems_bay = pems_bay.values  # Преобразуем DataFrame в numpy array\n",
    "        self.adj_df = torch.tensor(adj_df.values, dtype=torch.float32)  # Сразу преобразуем матрицу смежности в тензор\n",
    "        self.seq_len = seq_len\n",
    "        self.pre_len = pre_len\n",
    "        self.num_nodes = self.pems_bay.shape[1]  # Количество узлов (датчиков)\n",
    "        self.timestamps = pd.to_datetime(pems_bay.index)  # Преобразуем индексы в datetime\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Возвращает количество доступных временных окон.\n",
    "        \"\"\"\n",
    "        return len(self.pems_bay) - self.seq_len - self.pre_len + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Возвращает один батч данных.\n",
    "        \n",
    "        :param idx: int, индекс окна.\n",
    "        :return: dict, словарь с данными для модели.\n",
    "        \"\"\"\n",
    "        # Временной ряд для обучения\n",
    "        x = self.pems_bay[idx:idx + self.seq_len]\n",
    "        # Целевые данные (предсказание)\n",
    "        y = self.pems_bay[idx + self.seq_len:idx + self.seq_len + self.pre_len]\n",
    "        \n",
    "        # Временные метки для конца обучающего окна\n",
    "        timestamp = self.timestamps[idx + self.seq_len - 1]\n",
    "        day_of_week = timestamp.weekday()\n",
    "        hour_of_day = timestamp.hour\n",
    "        \n",
    "        # Преобразуем данные в тензоры\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        \n",
    "        return {\n",
    "            'X_t': x,  # Входные данные (временные ряды)\n",
    "            'y': y,  # Целевые данные (предсказание)\n",
    "            'week_idx': torch.tensor(day_of_week, dtype=torch.long),  # День недели\n",
    "            'day_idx': torch.tensor(hour_of_day, dtype=torch.long),  # Час дня\n",
    "            'adj': self.adj_df  # Матрица смежности\n",
    "        }\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Параметры\n",
    "    seq_len = 12  # Длина окна видимости\n",
    "    pre_len = 3  # Длина окна предсказания\n",
    "    \n",
    "    # Создание датасета\n",
    "    dataset = TrafficDataset(pems_bay, adj_df, seq_len, pre_len)\n",
    "    \n",
    "    # Создание DataLoader\n",
    "    batch_size = 32\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Пример вывода батча\n",
    "    for batch in dataloader:\n",
    "        print(\"X_t shape:\", batch['X_t'].shape)     # [batch_size, seq_len, num_nodes]\n",
    "        print(\"y shape:\", batch['y'].shape)         # [batch_size, pre_len, num_nodes]\n",
    "        print(\"week_idx:\", batch['week_idx'])       # [batch_size]\n",
    "        print(\"day_idx:\", batch['day_idx'])         # [batch_size]\n",
    "        print(\"adj shape:\", batch['adj'].shape)     # [num_nodes, num_nodes]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fft\n",
    "import logging\n",
    "\n",
    "# Настройка логгера\n",
    "def setup_logger(log_file_path, terminal=False, log_level=logging.INFO, console_log_level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Настройка логгера для записи в файл и, при необходимости, в консоль.\n",
    "\n",
    "    Аргументы:\n",
    "        log_file_path (str): Путь к файлу для записи логов.\n",
    "        terminal (bool): Включить ли вывод логов в консоль.\n",
    "        log_level (int): Уровень логирования для файла (по умолчанию INFO).\n",
    "        console_log_level (int): Уровень логирования для консоли (по умолчанию INFO).\n",
    "\n",
    "    Возвращает:\n",
    "        logger: Настроенный объект логгера.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(\"DFDGCN_Logger\")\n",
    "    \n",
    "    # Удаляем все существующие обработчики, чтобы избежать дублирования\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)\n",
    "    \n",
    "    logger.setLevel(log_level)\n",
    "    \n",
    "    # Формат сообщений\n",
    "    formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "    \n",
    "    # Файловый хэндлер\n",
    "    file_handler = logging.FileHandler(log_file_path)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    file_handler.setLevel(log_level)\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    # Консольный хэндлер (если terminal=True)\n",
    "    if terminal:\n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setFormatter(formatter)\n",
    "        console_handler.setLevel(console_log_level)\n",
    "        logger.addHandler(console_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "# Функция для логирования shape тензоров\n",
    "def log_tensor_shape(logger, tensor, tensor_name):\n",
    "    if tensor is not None:\n",
    "        # Форматирование строки для выравнивания torch.Size([]) справа\n",
    "        shape_str = f\"{tensor.shape}\".rjust(30)  # Выравнивание по правому краю\n",
    "        logger.info(f\"{tensor_name:<30} shape: {shape_str}\")\n",
    "    else:\n",
    "        logger.info(f\"{tensor_name} is None\")\n",
    "\n",
    "# Модель DFDGCN\n",
    "class DFDGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim, num_weeks, num_days, K, seq_len, pre_len, logger):\n",
    "        super(DFDGCN, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.K = K\n",
    "        self.seq_len = seq_len\n",
    "        self.pre_len = pre_len  # Добавляем pre_len\n",
    "        self.logger = logger\n",
    "\n",
    "        # Identity Embedding\n",
    "        self.identity_embedding = nn.Embedding(num_nodes, embedding_dim)\n",
    "        \n",
    "        # Time Embeddings\n",
    "        self.week_embedding = nn.Embedding(num_weeks, embedding_dim)\n",
    "        self.day_embedding = nn.Embedding(num_days, embedding_dim)\n",
    "        \n",
    "        # Linear layers for Fourier transformed data and time embeddings\n",
    "        self.W_F = nn.Linear(1, embedding_dim)\n",
    "        self.W_T = nn.Linear(2 * embedding_dim, embedding_dim)\n",
    "        \n",
    "        # 1x1 Convolution\n",
    "        self.conv1x1 = nn.Conv1d(3 * embedding_dim, embedding_dim, kernel_size=1)\n",
    "        \n",
    "        # Adjacency matrix learning\n",
    "        self.W_adj = nn.Parameter(torch.randn(embedding_dim, embedding_dim))\n",
    "        \n",
    "        # Graph convolution weights\n",
    "        self.W_k1 = [nn.Linear(seq_len, embedding_dim) for _ in range(K + 1)]\n",
    "        self.W_k2 = [nn.Linear(seq_len, embedding_dim) for _ in range(K + 1)]\n",
    "        self.W_k3 = [nn.Linear(seq_len, embedding_dim) for _ in range(K + 1)]\n",
    "        \n",
    "        # Output layer to match target dimension\n",
    "        self.output_layer = nn.Linear(embedding_dim, pre_len)  # Изменяем размерность выходного слоя\n",
    "\n",
    "        # Инициализация A_adt как параметра модели\n",
    "        self.A_adt = nn.Parameter(torch.rand(num_nodes, num_nodes))\n",
    "\n",
    "\n",
    "    def apply_fft(self, x):\n",
    "        fft_x = torch.fft.fft(x, dim=-1)\n",
    "        return fft_x.abs()\n",
    "\n",
    "    def compute_DE_t(self, x_t, week_idx, day_idx):\n",
    "        fft_x_t = self.apply_fft(x_t)\n",
    "        fft_x_t = fft_x_t.mean(dim=-1)\n",
    "        log_tensor_shape(self.logger, fft_x_t, \"FFT(X_t).mean\")\n",
    "        \n",
    "        E_t = self.identity_embedding(torch.arange(self.num_nodes, device=x_t.device))\n",
    "        log_tensor_shape(self.logger, E_t, \"Identity Embedding\")\n",
    "        \n",
    "        T_W = self.week_embedding(week_idx)\n",
    "        T_D = self.day_embedding(day_idx)\n",
    "        T = torch.cat((T_W, T_D), dim=-1)\n",
    "        log_tensor_shape(self.logger, T, \"Time Embedding (concat)\")\n",
    "        T = self.W_T(T)\n",
    "        log_tensor_shape(self.logger, T, \"Time Embedding (W_T)\")\n",
    "        \n",
    "        F_t = fft_x_t.unsqueeze(-1)\n",
    "        log_tensor_shape(self.logger, F_t, \"FFT(X_t).unsqueeze\")\n",
    "        F_t = self.W_F(F_t).squeeze(-1)\n",
    "        log_tensor_shape(self.logger, F_t, \"Fourier Embedding (W_F)\")\n",
    "        \n",
    "        # Перестановка F_t для совпадения размеров\n",
    "        F_t = F_t.unsqueeze(1).expand(x_t.size(0), self.num_nodes, self.seq_len, self.embedding_dim)\n",
    "        F_t = F_t.permute(0, 2, 1, 3).reshape(x_t.size(0), self.seq_len, self.num_nodes * self.embedding_dim)\n",
    "        \n",
    "        E_t_expanded = E_t.unsqueeze(0).expand(x_t.size(0), self.num_nodes, self.embedding_dim)\n",
    "        log_tensor_shape(self.logger, E_t_expanded, \"Identity Embedding (expanded)\")\n",
    "        T_expanded = T.unsqueeze(1).expand(x_t.size(0), self.num_nodes, self.embedding_dim)\n",
    "        log_tensor_shape(self.logger, T_expanded, \"Time Embedding (expanded)\")\n",
    "        \n",
    "        # Конкатенация\n",
    "        DE_t = torch.cat((F_t, E_t_expanded, T_expanded), dim=-1)\n",
    "        log_tensor_shape(self.logger, DE_t, \"DE_t (concat)\")\n",
    "        DE_t = torch.relu(DE_t)  # Добавляем активацию\n",
    "        DE_t = torch.nn.functional.normalize(DE_t, p=2, dim=-1)  # Нормализация\n",
    "        DE_t = DE_t.permute(0, 2, 1)\n",
    "        log_tensor_shape(self.logger, DE_t, \"DE_t (permute)\")\n",
    "        DE_t = self.conv1x1(DE_t)\n",
    "        log_tensor_shape(self.logger, DE_t, \"DE_t (conv1x1)\")\n",
    "        DE_t = DE_t.permute(0, 2, 1)\n",
    "        log_tensor_shape(self.logger, DE_t, \"DE_t (final)\")\n",
    "        return DE_t\n",
    "\n",
    "    def compute_A_D(self, DE_t):\n",
    "        A = torch.einsum('bne, ek->bnk', (DE_t, self.W_adj))\n",
    "        A = torch.relu(A)\n",
    "        A = torch.softmax(A, dim=-1)\n",
    "        return A\n",
    "\n",
    "    def graph_convolution(self, X_t, P, A_adt, A_D):\n",
    "        Z_t = 0\n",
    "        for k in range(self.K + 1):\n",
    "            P_k = torch.matrix_power(P, k)\n",
    "            log_tensor_shape(self.logger, P_k, f\"P^{k}\")\n",
    "            A_adt_k = torch.matrix_power(A_adt, k)\n",
    "            log_tensor_shape(self.logger, A_adt_k, f\"A_adt^{k}\")\n",
    "            A_D_k = torch.matrix_power(A_D, k)\n",
    "            log_tensor_shape(self.logger, A_D_k, f\"A_D^{k}\")\n",
    "            \n",
    "            term1 = (P_k @ X_t) @ self.W_k1[k].weight.t()\n",
    "            log_tensor_shape(self.logger, term1, f\"Term1 (P_k @ X_t)\")\n",
    "            term2 = (A_adt_k @ X_t) @ self.W_k2[k].weight.t()\n",
    "            log_tensor_shape(self.logger, term2, f\"Term2 (A_adt_k @ X_t)\")\n",
    "            term3 = (A_D_k @ X_t) @ self.W_k3[k].weight.t()\n",
    "            log_tensor_shape(self.logger, term3, f\"Term3 (A_D_k @ X_t)\")\n",
    "            Z_t += term1 + term2 + term3\n",
    "        log_tensor_shape(self.logger, Z_t, \"Z_t (graph convolution)\")\n",
    "        return Z_t\n",
    "\n",
    "    def forward(self, X_t, week_idx, day_idx, P, A_adt):\n",
    "        log_tensor_shape(self.logger, X_t, \"X_t (input)\")\n",
    "        DE_t = self.compute_DE_t(X_t, week_idx, day_idx)\n",
    "        A_D = self.compute_A_D(DE_t)\n",
    "        Z_t = self.graph_convolution(X_t, P, A_adt, A_D)\n",
    "        Z_t = self.output_layer(Z_t)  # [batch_size, num_nodes, pre_len]\n",
    "        log_tensor_shape(self.logger, Z_t, \"Z_t (output)\")\n",
    "        return Z_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DFDGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim, num_weeks, num_days, K, seq_len, pre_len, logger):\n",
    "        super(DFDGCN, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.K = K\n",
    "        self.seq_len = seq_len\n",
    "        self.pre_len = pre_len\n",
    "        self.logger = logger\n",
    "\n",
    "        # Identity Embedding (Эмбеддинг идентификаторов)\n",
    "        self.identity_embedding = nn.Embedding(num_nodes, embedding_dim)\n",
    "        \n",
    "        # Time Embeddings (Эмбеддинги времени)\n",
    "        self.week_embedding = nn.Embedding(num_weeks, embedding_dim)\n",
    "        self.day_embedding = nn.Embedding(num_days, embedding_dim)\n",
    "        \n",
    "        # Линейные слои для преобразованных данных Фурье и эмбеддингов времени\n",
    "        self.W_F = nn.Linear(seq_len, embedding_dim)\n",
    "        self.W_T = nn.Linear(2 * embedding_dim, embedding_dim)\n",
    "        \n",
    "        # 1x1 Свертка\n",
    "        self.conv1x1 = nn.Conv1d(3 * embedding_dim, embedding_dim, kernel_size=1)\n",
    "        \n",
    "        # Обучаемый параметр для матрицы смежности\n",
    "        self.W_adj = nn.Parameter(torch.randn(embedding_dim, embedding_dim))\n",
    "        \n",
    "        # Веса для графовой свертки\n",
    "        self.W_k1 = nn.ModuleList([nn.Linear(embedding_dim, embedding_dim) for _ in range(K + 1)])\n",
    "        self.W_k2 = nn.ModuleList([nn.Linear(embedding_dim, embedding_dim) for _ in range(K + 1)])\n",
    "        self.W_k3 = nn.ModuleList([nn.Linear(embedding_dim, embedding_dim) for _ in range(K + 1)])\n",
    "        \n",
    "        # Выходной слой для соответствия целевой размерности\n",
    "        self.output_layer = nn.Linear(embedding_dim, pre_len)\n",
    "        \n",
    "        # Предопределенный граф P и самоадаптивный граф A_adt\n",
    "        self.P = nn.Parameter(torch.randn(num_nodes, num_nodes))\n",
    "        self.A_adt = nn.Parameter(torch.randn(num_nodes, num_nodes))\n",
    "\n",
    "    def apply_fft(self, x):\n",
    "        # Применение FFT и вычисление модуля\n",
    "        fft_x = torch.fft.fft(x, dim=-1)\n",
    "        fft_x = fft_x.abs()\n",
    "        return fft_x\n",
    "\n",
    "    def compute_DE_t(self, x_t, week_idx, day_idx):\n",
    "        # Применение FFT и получение модуля\n",
    "        fft_x_t = self.apply_fft(x_t)\n",
    "        fft_x_t = fft_x_t.mean(dim=-1)\n",
    "        \n",
    "        # Identity Embedding (Эмбеддинг идентификаторов)\n",
    "        E_t = self.identity_embedding(torch.arange(self.num_nodes, device=x_t.device))\n",
    "        \n",
    "        # Time Embedding (Эмбеддинг времени)\n",
    "        T_W = self.week_embedding(week_idx)\n",
    "        T_D = self.day_embedding(day_idx)\n",
    "        T = torch.cat((T_W, T_D), dim=-1)\n",
    "        T = self.W_T(T)\n",
    "        \n",
    "        # Обработка данных Фурье\n",
    "        F_t = self.W_F(fft_x_t)\n",
    "        \n",
    "        # Объединение эмбеддингов\n",
    "        DE_t = torch.cat((F_t, E_t, T), dim=-1)\n",
    "        \n",
    "        # 1x1 Свертка\n",
    "        DE_t = DE_t.permute(0, 2, 1)\n",
    "        DE_t = self.conv1x1(DE_t)\n",
    "        DE_t = DE_t.permute(0, 2, 1)\n",
    "        \n",
    "        return DE_t\n",
    "\n",
    "    def compute_A_D(self, DE_t):\n",
    "        # Вычисление матрицы смежности\n",
    "        A_logits = torch.matmul(DE_t, self.W_adj)\n",
    "        A_logits = A_logits.permute(0, 2, 1)\n",
    "        A_D = F.softmax(A_logits, dim=-1)\n",
    "        return A_D\n",
    "\n",
    "    def graph_convolution(self, X_t, P, A_adt, A_D):\n",
    "        Z_t = 0\n",
    "        for k in range(self.K + 1):\n",
    "            P_k = torch.matrix_power(P, k)\n",
    "            A_adt_k = torch.matrix_power(A_adt, k)\n",
    "            A_D_k = torch.matrix_power(A_D, k)\n",
    "            \n",
    "            term1 = P_k @ X_t @ self.W_k1[k].weight.t()\n",
    "            term2 = A_adt_k @ X_t @ self.W_k2[k].weight.t()\n",
    "            term3 = A_D_k @ X_t @ self.W_k3[k].weight.t()\n",
    "            Z_t += term1 + term2 + term3\n",
    "        return Z_t\n",
    "\n",
    "    def forward(self, X_t, week_idx, day_idx):\n",
    "        DE_t = self.compute_DE_t(X_t, week_idx, day_idx)\n",
    "        A_D = self.compute_A_D(DE_t)\n",
    "        Z_t = self.graph_convolution(X_t, self.P, self.A_adt, A_D)\n",
    "        Z_t = self.output_layer(Z_t)\n",
    "        return Z_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные X: torch.Size([32, 10, 12])\n",
      "Индексы дней недели week_idx: torch.Size([32])\n",
      "Индексы часов дня day_idx: torch.Size([32])\n",
      "Предопределенный граф P: torch.Size([10, 10])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x32 and 12x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m model \u001b[38;5;241m=\u001b[39m DFDGCN(num_nodes\u001b[38;5;241m=\u001b[39mnum_nodes, embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_weeks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, num_days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m, K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, seq_len\u001b[38;5;241m=\u001b[39mseq_len, pre_len\u001b[38;5;241m=\u001b[39mpre_len, logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Передача данных в модель\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweek_idx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mday_idx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Вывод результата\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mРезультат предсказания:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[71], line 98\u001b[0m, in \u001b[0;36mDFDGCN.forward\u001b[1;34m(self, X_t, week_idx, day_idx)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_t, week_idx, day_idx):\n\u001b[1;32m---> 98\u001b[0m     DE_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_DE_t\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweek_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     A_D \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_A_D(DE_t)\n\u001b[0;32m    100\u001b[0m     Z_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_convolution(X_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA_adt, A_D)\n",
      "Cell \u001b[1;32mIn[71], line 65\u001b[0m, in \u001b[0;36mDFDGCN.compute_DE_t\u001b[1;34m(self, x_t, week_idx, day_idx)\u001b[0m\n\u001b[0;32m     62\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_T(T)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Обработка данных Фурье\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m F_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_F\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfft_x_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Объединение эмбеддингов\u001b[39;00m\n\u001b[0;32m     68\u001b[0m DE_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((F_t, E_t, T), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x32 and 12x10)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def generate_synthetic_data(num_nodes, seq_len, pre_len, num_samples):\n",
    "    \"\"\"\n",
    "    Генерация синтетических данных для модели DFDGCN.\n",
    "    \n",
    "    :param num_nodes: Количество узлов (датчиков) в графе.\n",
    "    :param seq_len: Длина входной последовательности (количество временных шагов).\n",
    "    :param pre_len: Длина предсказания (количество временных шагов для предсказания).\n",
    "    :param num_samples: Количество сэмплов (батчей) для генерации.\n",
    "    :return: Словарь с данными: X (входные данные), week_idx (индексы дней недели), day_idx (индексы часов дня), P (предопределенный граф).\n",
    "    \"\"\"\n",
    "    # Генерация входных данных X\n",
    "    X = np.random.rand(num_samples, num_nodes, seq_len)  # [batch_size, num_nodes, seq_len]\n",
    "    \n",
    "    # Генерация индексов дней недели и часов дня\n",
    "    week_idx = np.random.randint(0, 7, size=(num_samples,))  # [batch_size]\n",
    "    day_idx = np.random.randint(0, 24, size=(num_samples,))  # [batch_size]\n",
    "    \n",
    "    # Генерация предопределенного графа P\n",
    "    P = np.random.rand(num_nodes, num_nodes)  # [num_nodes, num_nodes]\n",
    "    P = P / np.sum(P, axis=1, keepdims=True)  # Нормализация строк\n",
    "    \n",
    "    # Преобразование данных в тензоры PyTorch\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    week_idx = torch.tensor(week_idx, dtype=torch.long)\n",
    "    day_idx = torch.tensor(day_idx, dtype=torch.long)\n",
    "    P = torch.tensor(P, dtype=torch.float32)\n",
    "    \n",
    "    return {\n",
    "        'X': X,\n",
    "        'week_idx': week_idx,\n",
    "        'day_idx': day_idx,\n",
    "        'P': P\n",
    "    }\n",
    "\n",
    "# Пример использования\n",
    "num_nodes = 10  # Количество узлов (датчиков)\n",
    "seq_len = 12    # Длина входной последовательности\n",
    "pre_len = 6     # Длина предсказания\n",
    "num_samples = 32  # Количество сэмплов (батчей)\n",
    "\n",
    "data = generate_synthetic_data(num_nodes, seq_len, pre_len, num_samples)\n",
    "\n",
    "# Вывод сгенерированных данных\n",
    "print(\"Входные данные X:\", data['X'].shape)\n",
    "print(\"Индексы дней недели week_idx:\", data['week_idx'].shape)\n",
    "print(\"Индексы часов дня day_idx:\", data['day_idx'].shape)\n",
    "print(\"Предопределенный граф P:\", data['P'].shape)\n",
    "\n",
    "# Инициализация модели\n",
    "model = DFDGCN(num_nodes=num_nodes, embedding_dim=10, num_weeks=7, num_days=24, K=2, seq_len=seq_len, pre_len=pre_len, logger=None)\n",
    "\n",
    "# Передача данных в модель\n",
    "output = model(data['X'], data['week_idx'], data['day_idx'])\n",
    "\n",
    "# Вывод результата\n",
    "print(\"Результат предсказания:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры\n",
    "num_nodes = 10\n",
    "seq_len = 12\n",
    "pre_len = 3  # Окно предсказания\n",
    "batch_size = 32\n",
    "embedding_dim = 10\n",
    "num_weeks = 7\n",
    "num_days = 24\n",
    "K = 2\n",
    "\n",
    "# Генерация данных\n",
    "X_t = torch.randn(batch_size, num_nodes, seq_len)\n",
    "y = torch.randn(batch_size, num_nodes, pre_len)  # Целевые данные с размером pre_len\n",
    "week_idx = torch.randint(0, num_weeks, (batch_size,))\n",
    "day_idx = torch.randint(0, num_days, (batch_size,))\n",
    "P = torch.rand(num_nodes, num_nodes)\n",
    "A_adt = torch.rand(num_nodes, num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 32 but got size 10 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 13\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweek_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[0;32m     15\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[66], line 98\u001b[0m, in \u001b[0;36mDFDGCN.forward\u001b[1;34m(self, X_t, week_idx, day_idx)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_t, week_idx, day_idx):\n\u001b[1;32m---> 98\u001b[0m     DE_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_DE_t\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweek_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     A_D \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_A_D(DE_t)\n\u001b[0;32m    100\u001b[0m     Z_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_convolution(X_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA_adt, A_D)\n",
      "Cell \u001b[1;32mIn[66], line 68\u001b[0m, in \u001b[0;36mDFDGCN.compute_DE_t\u001b[1;34m(self, x_t, week_idx, day_idx)\u001b[0m\n\u001b[0;32m     65\u001b[0m F_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_F(fft_x_t)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Объединение эмбеддингов\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m DE_t \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# 1x1 Свертка\u001b[39;00m\n\u001b[0;32m     71\u001b[0m DE_t \u001b[38;5;241m=\u001b[39m DE_t\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 32 but got size 10 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Настройка логгера с выводом в консоль\n",
    "logger = setup_logger(\"dfdgnn_log.txt\", terminal=False, log_level=logging.DEBUG, console_log_level=logging.DEBUG)\n",
    "\n",
    "# Создание модели\n",
    "model = DFDGCN(num_nodes, embedding_dim, num_weeks, num_days, K, seq_len, pre_len, logger)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Обучение\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_t, week_idx, day_idx)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "\n",
    "\n",
    "# Настройка логгера\n",
    "def setup_logger(log_file_path, terminal=False, log_level=logging.INFO, console_log_level=logging.INFO):\n",
    "    logger = logging.getLogger(\"DFDGCN_Logger\")\n",
    "    for handler in logger.handlers[:]:  # Удаляем существующие обработчики, если они есть\n",
    "        logger.removeHandler(handler)\n",
    "    logger.setLevel(log_level)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "    file_handler = logging.FileHandler(log_file_path)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    file_handler.setLevel(log_level)\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    if terminal:\n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setFormatter(formatter)\n",
    "        console_handler.setLevel(console_log_level)\n",
    "        logger.addHandler(console_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "# Логирование размеров тензоров\n",
    "def log_tensor_shape(logger, tensor, tensor_name):\n",
    "    if tensor is not None:\n",
    "        logger.info(f\"{tensor_name:<30} shape: {tensor.shape}\")\n",
    "    else:\n",
    "        logger.info(f\"{tensor_name:<30} is None\")\n",
    "\n",
    "\n",
    "# Основные компоненты модели\n",
    "class FourierTransform(nn.Module):\n",
    "    def __init__(self, seq_len, emb_dim, logger=None):\n",
    "        super(FourierTransform, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.emb_dim = emb_dim\n",
    "        self.embedding = nn.Linear(seq_len // 2 + 1, emb_dim)\n",
    "        self.logger = logger\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.logger:\n",
    "            log_tensor_shape(self.logger, x, \"Input to FourierTransform\")\n",
    "        x = torch.fft.rfft(x, dim=-1)\n",
    "        x = torch.abs(x)\n",
    "        x = F.normalize(x, p=2, dim=-1)\n",
    "        x = self.embedding(x)\n",
    "        if self.logger:\n",
    "            log_tensor_shape(self.logger, x, \"Output of FourierTransform\")\n",
    "        return x\n",
    "\n",
    "\n",
    "class IdentityEmbedding(nn.Module):\n",
    "    def __init__(self, num_nodes, emb_dim, logger=None):\n",
    "        super(IdentityEmbedding, self).__init__()\n",
    "        self.embedding = nn.Parameter(torch.randn(num_nodes, emb_dim))\n",
    "        self.logger = logger\n",
    "\n",
    "    def forward(self):\n",
    "        if self.logger:\n",
    "            log_tensor_shape(self.logger, self.embedding, \"IdentityEmbedding\")\n",
    "        return self.embedding\n",
    "\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, seq_len, time_emb_dim, logger=None):\n",
    "        super(TimeEmbedding, self).__init__()\n",
    "        self.day_embedding = nn.Embedding(7, time_emb_dim)\n",
    "        self.hour_embedding = nn.Embedding(24, time_emb_dim)\n",
    "        self.seq_len = seq_len\n",
    "        self.logger = logger\n",
    "\n",
    "    def forward(self, day_of_week, hour_of_day):\n",
    "        day_emb = self.day_embedding(day_of_week)\n",
    "        hour_emb = self.hour_embedding(hour_of_day)\n",
    "        out = torch.cat([day_emb, hour_emb], dim=-1)\n",
    "        if self.logger:\n",
    "            log_tensor_shape(self.logger, out, \"Output of TimeEmbedding\")\n",
    "        return out\n",
    "\n",
    "\n",
    "class DynamicGraph(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_dim, logger=None):\n",
    "        super(DynamicGraph, self).__init__()\n",
    "        input_dim = 4 * emb_dim  # Учитываем freq_emb, identity_emb, time_emb (два time_emb)\n",
    "        self.fc = nn.Linear(input_dim, hidden_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.logger = logger\n",
    "\n",
    "    def forward(self, freq_emb, identity_emb, time_emb):\n",
    "        # Добавляем batch-измерение в identity_emb\n",
    "        identity_emb = identity_emb.unsqueeze(0).repeat(freq_emb.size(0), 1, 1)\n",
    "        if self.logger:\n",
    "            log_tensor_shape(self.logger, identity_emb, \"IdentityEmbedding with batch\")\n",
    "\n",
    "        # Объединение всех признаков\n",
    "        combined = torch.cat([freq_emb, identity_emb, time_emb], dim=-1)  # [batch_size, num_nodes, 4 * emb_dim]\n",
    "        if self.logger:\n",
    "            log_tensor_shape(self.logger, combined, \"Combined features for DynamicGraph\")\n",
    "\n",
    "        # Применяем полносвязный слой\n",
    "        combined = self.activation(self.fc(combined))  # [batch_size, num_nodes, hidden_dim]\n",
    "\n",
    "        # Генерация матрицы смежности\n",
    "        adj_matrix = torch.bmm(combined, combined.transpose(1, 2))  # [batch_size, num_nodes, num_nodes]\n",
    "        adj_matrix = self.softmax(F.relu(adj_matrix))\n",
    "        if self.logger:\n",
    "            log_tensor_shape(self.logger, adj_matrix, \"Dynamic adjacency matrix\")\n",
    "        return adj_matrix\n",
    "\n",
    "\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, supports_len, logger=None):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.supports_len = supports_len\n",
    "        self.conv_weights = nn.Parameter(torch.randn(supports_len, in_channels, out_channels))\n",
    "        self.logger = logger\n",
    "\n",
    "    def forward(self, x, supports):\n",
    "        out = 0\n",
    "        for i, A in enumerate(supports):\n",
    "            partial_out = torch.einsum('bcn,cnm->bcm', x, A @ self.conv_weights[i])\n",
    "            out += partial_out\n",
    "            if self.logger:\n",
    "                log_tensor_shape(self.logger, partial_out, f\"GraphConv output for support {i}\")\n",
    "        return out\n",
    "\n",
    "\n",
    "class DFDGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, in_dim, out_dim, seq_len, emb_dim, hidden_dim, supports=None, logger=None):\n",
    "        super(DFDGCN, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # Настройка логгера\n",
    "        self.logger = logger\n",
    "\n",
    "        # Подмодули\n",
    "        self.fourier = FourierTransform(seq_len, emb_dim, logger)\n",
    "        self.identity = IdentityEmbedding(num_nodes, emb_dim, logger)\n",
    "        self.time = TimeEmbedding(seq_len, emb_dim, logger)\n",
    "        self.dynamic_graph = DynamicGraph(emb_dim * 3, hidden_dim, logger)\n",
    "        self.graph_conv = GraphConv(in_dim, out_dim, supports_len=1 + (1 if supports is not None else 0), logger=logger)\n",
    "\n",
    "        # Инициализация графов\n",
    "        self.supports = [supports] if supports is not None else []\n",
    "\n",
    "    def forward(self, x, day_of_week, hour_of_day):\n",
    "        if self.logger:\n",
    "            log_tensor_shape(self.logger, x, \"Input to DFDGCN\")\n",
    "        freq_emb = self.fourier(x)\n",
    "        identity_emb = self.identity()\n",
    "        time_emb = self.time(day_of_week, hour_of_day)\n",
    "\n",
    "        dynamic_adj = self.dynamic_graph(freq_emb, identity_emb, time_emb)\n",
    "        all_supports = self.supports + [dynamic_adj]\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "        out = self.graph_conv(x, all_supports)\n",
    "        if self.logger:\n",
    "            log_tensor_shape(self.logger, out, \"Output of DFDGCN\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройка логгера\n",
    "logger = setup_logger(\"dfdgcn_logs.txt\", terminal=True)\n",
    "\n",
    "# Инициализация данных\n",
    "batch_size = 32\n",
    "num_nodes = 100\n",
    "seq_len = 12\n",
    "features = 1\n",
    "\n",
    "time_series = torch.rand(batch_size, num_nodes, seq_len)\n",
    "norm_adj = torch.rand(num_nodes, num_nodes)\n",
    "day_of_week = torch.randint(0, 7, (batch_size, num_nodes))\n",
    "hour_of_day = torch.randint(0, 24, (batch_size, num_nodes))\n",
    "\n",
    "# Инициализация модели\n",
    "model = DFDGCN(num_nodes=num_nodes, in_dim=features, out_dim=3, seq_len=seq_len,\n",
    "               emb_dim=10, hidden_dim=30, supports=norm_adj, logger=logger)\n",
    "\n",
    "# Прямой проход\n",
    "output = model(time_series, day_of_week, hour_of_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "import folium\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "with h5py.File('data/raw_data_without_large_scale_datasets/raw_data/PEMS-BAY/PEMS-BAY.h5', 'r') as file:\n",
    "\n",
    "    axis0 = file['speed']['axis0'][:]               # Идентификаторы датчиков\n",
    "    block0_items = file['speed']['block0_items'][:] # Идентификаторы датчиков\n",
    "    axis1 = file['speed']['axis1'][:]               # Метки времени\n",
    "    timestamps = pd.to_datetime(axis1)              # Преобразование меток времени в формат datetime\n",
    "    speed_data = file['speed']['block0_values'][:]  # Данные замеров скорости\n",
    "\n",
    "pems_bay = pd.DataFrame(speed_data, index=timestamps, columns=axis0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Открытие .pkl файла\n",
    "with open('data/raw_data_without_large_scale_datasets/raw_data/PEMS-BAY/adj_PEMS-BAY.pkl', 'rb') as file:\n",
    "    data = pickle.load(file, encoding='bytes')\n",
    "node_ids = [x.decode('utf-8') for x in data[0]]                     # Получаем список id узлов из data[0]\n",
    "adj_matrix = data[2]                                                # Получаем матрицу смежности из data[2]\n",
    "adj_df = pd.DataFrame(adj_matrix, index=node_ids, columns=node_ids) # Создание DataFrame с использованием id узлов как индексов и названий колонок\n",
    "adj_df.columns = [int(i) for i in adj_df.columns]                   # Сопостовление названий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            400001  400017  400030  400040  400045  400052  400057  400059  \\\n",
       " 2017-01-01    71.4    67.8    70.5    67.4    68.8    66.6    66.8    68.0   \n",
       " \n",
       "             400065  400069  ...  409525  409526  409528  409529  413026  \\\n",
       " 2017-01-01    66.8    69.0  ...    68.8    67.9    68.8    68.0    69.2   \n",
       " \n",
       "             413845  413877  413878  414284  414694  \n",
       " 2017-01-01    68.9    70.4    68.8    71.1    68.0  \n",
       " \n",
       " [1 rows x 325 columns],\n",
       "         400001  400017  400030  400040  400045  400052  400057  400059  \\\n",
       " 400001     1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       " \n",
       "         400065  400069  ...  409525  409526  409528  409529  413026  413845  \\\n",
       " 400001     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       " \n",
       "         413877  413878  414284  414694  \n",
       " 400001     0.0     0.0     0.0     0.0  \n",
       " \n",
       " [1 rows x 325 columns])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pems_bay.head(1), adj_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 3. Expected size 7 but got size 12 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 173\u001b[0m\n\u001b[0;32m    170\u001b[0m time_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m7\u001b[39m, (batch_size, seq_len, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# [64, 12, 325]\u001b[39;00m\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\IT\\GitHub\\ITMO_subjects\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[145], line 80\u001b[0m, in \u001b[0;36mDFDGCN.forward\u001b[1;34m(self, X, time_features)\u001b[0m\n\u001b[0;32m     77\u001b[0m F_t_expanded \u001b[38;5;241m=\u001b[39m F_t\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [batch, seq_len, num_nodes, 1]\u001b[39;00m\n\u001b[0;32m     78\u001b[0m log_tensor_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger, F_t_expanded, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsqueeze F_t_expanded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m DE_t \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mF_t_expanded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_t\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, seq_len, num_nodes, 1 + embedding_dim + time_embedding_dim * 2]\u001b[39;00m\n\u001b[0;32m     81\u001b[0m log_tensor_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger, DE_t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConcatenated DE_t\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Step 5: 1D Convolution for feature fusion\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 3. Expected size 7 but got size 12 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.fft import fft\n",
    "\n",
    "class DFDGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, seq_len, pre_len, embedding_dim, time_embedding_dim, adj_matrix, adaptive_adj_matrix, logger):\n",
    "        super(DFDGCN, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.seq_len = seq_len\n",
    "        self.pre_len = pre_len\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.time_embedding_dim = time_embedding_dim\n",
    "        self.logger = logger\n",
    "        \n",
    "        # Identity Embedding\n",
    "        self.identity_embedding = nn.Embedding(num_nodes, embedding_dim)\n",
    "        \n",
    "        # Time Embedding\n",
    "        self.time_embedding_week = nn.Embedding(7, time_embedding_dim)  # Day of week\n",
    "        self.time_embedding_hour = nn.Embedding(24, time_embedding_dim)  # Hour of day\n",
    "        \n",
    "        # 1D Convolution for feature fusion\n",
    "        self.conv1d = nn.Conv1d(embedding_dim + time_embedding_dim * 2 + 1, 30, kernel_size=1)\n",
    "        \n",
    "        # Learnable parameters for adjacency matrix\n",
    "        self.W_adj = nn.Parameter(torch.randn(30, 30))\n",
    "        \n",
    "        # Static graphs\n",
    "        self.P = nn.Parameter(adj_matrix, requires_grad=False)  # Predefined graph\n",
    "        self.A_adt = nn.Parameter(adaptive_adj_matrix, requires_grad=False)  # Adaptive graph\n",
    "        \n",
    "        # Graph Convolution Layers\n",
    "        self.graph_conv = nn.ModuleList([\n",
    "            nn.Conv2d(1, 1, kernel_size=(1, 3)) for _ in range(3)  # One for each graph type\n",
    "        ])\n",
    "        \n",
    "        # Temporal processing (Causal Convolution)\n",
    "        self.temporal_conv = nn.Conv1d(seq_len, pre_len, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Fully connected layer for final prediction\n",
    "        self.fc = nn.Linear(30, pre_len)\n",
    "    \n",
    "    def forward(self, X, time_features):\n",
    "        batch_size, seq_len, num_nodes = X.shape\n",
    "        log_tensor_shape(self.logger, X, \"Input X\")\n",
    "        \n",
    "        # Step 1: Fourier Transform\n",
    "        F_t = torch.fft.rfft(X, dim=1)  # [batch, seq_len, num_nodes]\n",
    "        F_t = torch.abs(F_t)  # [batch, seq_len, num_nodes]\n",
    "        log_tensor_shape(self.logger, F_t, \"Fourier Transform F_t\")\n",
    "        \n",
    "        # Step 2: Identity Embedding\n",
    "        E_t = self.identity_embedding(torch.arange(num_nodes).to(X.device))  # [num_nodes, embedding_dim]\n",
    "        log_tensor_shape(self.logger, E_t, \"torch.arange(num_nodes) E_t\")\n",
    "        E_t = E_t.unsqueeze(0).unsqueeze(0).expand(batch_size, seq_len, -1, -1)  # [batch, seq_len, num_nodes, embedding_dim]\n",
    "        log_tensor_shape(self.logger, E_t, \"Identity Embedding E_t\")\n",
    "        \n",
    "        # Step 3: Time Embedding\n",
    "        day_of_week = time_features[:, :, 0]  # [batch, seq_len]\n",
    "        hour_of_day = time_features[:, :, 1]  # [batch, seq_len]\n",
    "        T_week = self.time_embedding_week(day_of_week)  # [batch, seq_len, time_embedding_dim]\n",
    "        T_hour = self.time_embedding_hour(hour_of_day)  # [batch, seq_len, time_embedding_dim]\n",
    "        log_tensor_shape(self.logger, T_week, \"Embedding T_week\")\n",
    "        log_tensor_shape(self.logger, T_hour, \"Embedding T_hour\")\n",
    "\n",
    "        # Масштабируем временные эмбеддинги на все узлы (нужен размер [batch, seq_len, num_nodes, time_embedding_dim])\n",
    "        T_week = T_week.unsqueeze(-2).expand(-1, -1, self.num_nodes, -1)  # [batch, seq_len, num_nodes, time_embedding_dim]\n",
    "        T_hour = T_hour.unsqueeze(-2).expand(-1, -1, self.num_nodes, -1)  # [batch, seq_len, num_nodes, time_embedding_dim]\n",
    "        log_tensor_shape(self.logger, T_week, \"Embedding expand T_week\")\n",
    "        log_tensor_shape(self.logger, T_hour, \"Embedding expand T_hour\")\n",
    "\n",
    "        T_t = torch.cat([T_week, T_hour], dim=-1)  # [batch, seq_len, num_nodes, time_embedding_dim * 2]\n",
    "        log_tensor_shape(self.logger, T_t, \"Time Embedding T_t\")\n",
    "        \n",
    "        # Step 4: Concatenate all features\n",
    "        F_t_expanded = F_t.unsqueeze(-1)  # [batch, seq_len, num_nodes, 1]\n",
    "        log_tensor_shape(self.logger, F_t_expanded, \"Unsqueeze F_t_expanded\")\n",
    "\n",
    "        DE_t = torch.cat([F_t_expanded, E_t, T_t], dim=-1)  # [batch, seq_len, num_nodes, 1 + embedding_dim + time_embedding_dim * 2]\n",
    "        log_tensor_shape(self.logger, DE_t, \"Concatenated DE_t\")\n",
    "        \n",
    "        # Step 5: 1D Convolution for feature fusion\n",
    "        DE_t = DE_t.permute(0, 3, 1, 2)  # [batch, channels, seq_len, num_nodes]\n",
    "        log_tensor_shape(self.logger, DE_t, \"Permute DE_t\")\n",
    "\n",
    "        # Преобразуем DE_t в 3D тензор для conv1d, объединяя seq_len и num_nodes\n",
    "        DE_t = DE_t.view(batch_size, 35, -1)  # [batch, channels, seq_len * num_nodes]\n",
    "        log_tensor_shape(self.logger, DE_t, \"View DE_t\")\n",
    "\n",
    "        DE_t = self.conv1d(DE_t)  # [batch, 30, seq_len * num_nodes]\n",
    "        log_tensor_shape(self.logger, DE_t, \"1D Convolution DE_t\")\n",
    "        \n",
    "        # Шаг 6: Генерация динамической матрицы смежности\n",
    "        DE_t = DE_t.view(batch_size, 30, seq_len, num_nodes)  # [batch, 30, seq_len, num_nodes]\n",
    "        log_tensor_shape(self.logger, DE_t, \"View DE_t\")\n",
    "\n",
    "        # Уплощение для матричных операций\n",
    "        DE_t_flat = DE_t.permute(0, 2, 3, 1).reshape(batch_size * seq_len, num_nodes, -1)  # [batch * seq_len, num_nodes, 30]\n",
    "\n",
    "        # Генерация динамической матрицы A_t_D\n",
    "        A_t_D = torch.matmul(DE_t_flat, self.W_adj)  # [batch * seq_len, num_nodes, 30]\n",
    "        A_t_D = torch.matmul(A_t_D, DE_t_flat.transpose(-1, -2))  # [batch * seq_len, num_nodes, num_nodes]\n",
    "\n",
    "        # Возвращаем A_t_D в нужный формат\n",
    "        A_t_D = A_t_D.view(batch_size, seq_len, num_nodes, num_nodes)  # [batch, seq_len, num_nodes, num_nodes]\n",
    "        A_t_D = F.relu(A_t_D)\n",
    "        A_t_D = F.softmax(A_t_D, dim=-1)\n",
    "        log_tensor_shape(self.logger, A_t_D, \"Dynamic Adjacency Matrix A_t_D\")\n",
    "        \n",
    "        # Step 7: Combine Graphs\n",
    "        P = self.P.unsqueeze(0).unsqueeze(0).expand(batch_size, seq_len, -1, -1)  # [batch, seq_len, num_nodes, num_nodes]\n",
    "        A_adt = self.A_adt.unsqueeze(0).unsqueeze(0).expand(batch_size, seq_len, -1, -1)  # [batch, seq_len, num_nodes, num_nodes]\n",
    "        log_tensor_shape(self.logger, P, \"Predefined Graph P\")\n",
    "        log_tensor_shape(self.logger, A_adt, \"Adaptive Graph A_adt\")\n",
    "        \n",
    "        # Объединение графов\n",
    "        Z_t = 0\n",
    "        for k in range(3):\n",
    "            if k == 0:\n",
    "                graph = P\n",
    "            elif k == 1:\n",
    "                graph = A_adt\n",
    "            else:\n",
    "                graph = A_t_D  # Теперь размерности согласованы\n",
    "            \n",
    "            DE_t_transposed = DE_t.permute(0, 2, 3, 1)  # [batch, seq_len, num_nodes, 30]\n",
    "            Z_t += torch.matmul(graph, DE_t_transposed)  # [batch, seq_len, num_nodes, 30]\n",
    "        log_tensor_shape(self.logger, Z_t, \"Graph Convolution Z_t\")\n",
    "        \n",
    "        # Step 8: Temporal Processing (Causal Convolution)\n",
    "        # Перестановка осей и преобразование для Conv1d\n",
    "        Z_t = Z_t.permute(0, 2, 1, 3)  # [batch, channels, seq_len, num_nodes]\n",
    "        Z_t = Z_t.reshape(batch_size * num_nodes, seq_len, 30)  # [batch * num_nodes, channels, seq_len]\n",
    "        log_tensor_shape(self.logger, Z_t, \"Reshaped for Temporal Conv Z_t\")\n",
    "\n",
    "        # Применение каузальной свертки\n",
    "        Z_t = self.temporal_conv(Z_t)  # [batch * num_nodes, channels, pre_len]\n",
    "        log_tensor_shape(self.logger, Z_t, \"Temporal Convolution Z_t\")\n",
    "\n",
    "        # Восстановление исходной размерности\n",
    "        # Z_t = Z_t.view(batch_size, num_nodes, -1, self.pre_len).permute(0, 3, 1, 2)  # [batch, pre_len, num_nodes, 30]\n",
    "        Z_t = Z_t.view(batch_size, num_nodes, self.pre_len, -1).permute(0, 2, 1, 3)  # [batch, pre_len, num_nodes, 30]\n",
    "        log_tensor_shape(self.logger, Z_t, \"Restored Z_t\")\n",
    "\n",
    "        # Step 9: Final Prediction\n",
    "        Y_t = self.fc(Z_t)  # Усредняем последние скрытые каналы: [batch, pre_len, num_nodes]\n",
    "        Y_t = Y_t.mean(dim=-1)\n",
    "        log_tensor_shape(self.logger, Y_t, \"Final Prediction Y_t\")\n",
    "        \n",
    "        return Y_t\n",
    "\n",
    "# Example usage\n",
    "num_nodes = 325\n",
    "seq_len = 12\n",
    "pre_len = 3\n",
    "batch_size = 64\n",
    "embedding_dim = 10\n",
    "time_embedding_dim = 12\n",
    "adj_matrix = torch.randn(num_nodes, num_nodes)\n",
    "adaptive_adj_matrix = torch.randn(num_nodes, num_nodes)\n",
    "\n",
    "# Настройка логгера\n",
    "logger = setup_logger(\"dfdgnn_log.txt\", terminal=False)\n",
    "\n",
    "model = DFDGCN(num_nodes, seq_len, pre_len, embedding_dim, time_embedding_dim, adj_matrix, adaptive_adj_matrix, logger)\n",
    "\n",
    "# Input data\n",
    "X = torch.randn(batch_size, seq_len, num_nodes)\n",
    "time_features = torch.randint(0, 7, (batch_size, seq_len, 2))\n",
    "\n",
    "# Forward pass\n",
    "output = model(X, time_features)\n",
    "print(output.shape)  # [64, 12, 325]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методология\n",
    "\n",
    "#### 1. **Преобразование Фурье**\n",
    "   - **Проблема Time-Shift**: В статье утверждается, что проблема Time-Shift (сдвига во времени) затрудняет моделирование пространственной зависимости в данных о трафике. Для решения этой проблемы предлагается использовать преобразование Фурье, которое переводит данные о трафике в частотную область.\n",
    "   - **Математическое обоснование**: \n",
    "     - Пусть $ f(t) $ — данные о трафике, захваченные сенсорами на определенном перекрестке. Если трафик задерживается на время $ t_0 $, то данные $ f(t-t_0) $ будут захвачены на следующем перекрестке.\n",
    "     - Согласно определению преобразования Фурье:\n",
    "       $$\n",
    "       F(\\omega) = \\int_{-\\infty}^{\\infty} f(t) e^{-j\\omega t} dt\n",
    "       $$\n",
    "       $$\n",
    "       F_{t_0}(\\omega) = \\int_{-\\infty}^{\\infty} f(t-t_0) e^{-j\\omega t} dt\n",
    "       $$\n",
    "     - После преобразований доказывается, что $ F_{t_0}(\\omega) = F(\\omega) \\cdot e^{-j\\omega t_0} $, что означает, что данные в частотной области представлены в одной фазовой размерности, что упрощает изучение пространственных зависимостей между сенсорами.\n",
    "\n",
    "#### 2. **DFDGCN (Dynamic Frequency Domain Graph Convolutional Network)**\n",
    "   - **Модуль частотной области**: Основная идея DFDGCN заключается в обновлении динамической матрицы смежности $ A_D $ на основе данных о трафике, наблюдаемых в текущем окне наблюдения.\n",
    "   - **Шаги модуля**:\n",
    "     1. **Преобразование Фурье**: Данные о трафике $ X_t $ в каждом окне наблюдения переводятся в частотную область с помощью быстрого преобразования Фурье (FFT):\n",
    "        $$\n",
    "        F_t = FFT(X_t)\n",
    "        $$\n",
    "     2. **Встраивание идентичности и времени**: Для уменьшения влияния шума в данных о трафике вводятся встраивания идентичности сенсоров $ E_t $ и временные встраивания $ T^{W}_t $ (день недели) и $ T^{D}_t $ (час дня):\n",
    "        $$\n",
    "        DE_t = W_{F,t} \\cdot F_t || E_t || W_{T,t} \\cdot (T^{W}_t || T^{D}_t)\n",
    "        $$\n",
    "     3. **Одномерная свертка**: Применяется одномерная сверточная слой с ядром $ 1 \\times 1 $ для дополнительного встраивания, чтобы изучить связи между измерениями $ DE_t $.\n",
    "     4. **Полносвязный слой и матричное умножение**: Применяется полносвязный слой для изучения $ DE_t $, затем результат умножается на транспонированную матрицу $ DE_t $. После активационной функции и $ Softmax $ получается финальная матрица смежности:\n",
    "        $$\n",
    "        A^{t}_D = Softmax(ReLU(DE_t W_{adj} DE^{T}_t))\n",
    "        $$\n",
    "     5. **Граф сверточный слой**: Динамический частотный граф комбинируется с предопределенными графами $ P $ (из DCRNN) и самоадаптивными графами $ A_{adt} $ (из GWNet) для создания графового сверточного слоя:\n",
    "        $$\n",
    "        Z_t = \\sum_{k=0}^{K} (P^{k} X_t W_{k,1} + A^{k}_{adt} X_t W_{k,2} + A^{t}_D X_t W_{k,3})\n",
    "        $$\n",
    "     6. **Обработка временной информации**: Для обработки временной информации используется классическая причинная свертка с остаточной сетью, как в GWNet.\n",
    "\n",
    "#### 3. **Эксперименты**\n",
    "   - **Датасеты**: Эксперименты проводятся на четырех реальных датасетах с десятками тысяч временных шагов и сотнями сенсоров. Статистика датасетов представлена в таблице 1.\n",
    "   - **Базовые линии и метрики**: В качестве базовых линий выбраны классические методы, такие как HI, GWNet, DCRNN, AGCRN, STGCN, MTGNN, DGCRN. Метрики оценки включают среднюю абсолютную ошибку (MAE), среднеквадратичную ошибку (RMSE) и среднюю абсолютную процентную ошибку (MAPE).\n",
    "   - **Настройки экспериментов**: Датасеты делятся на обучающую, валидационную и тестовую выборки в соотношении 7:1:2. Предсказываются данные о трафике на 12 временных шагов с использованием исторических данных длиной 12. Размеры встраиваний после преобразования Фурье и идентичности составляют 10, а временные встраивания $ T^{W}_t $ и $ T^{D}_t $ — 12. Размер встраивания после одномерной свертки — 30.\n",
    "   - **Результаты экспериментов**: DFDGCN показывает лучшие результаты по сравнению с базовыми линиями на всех датасетах. Анализ аблационных экспериментов подтверждает эффективность частотного графа в моделировании динамической пространственной зависимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходные данные (временная область):\n",
      "torch.Size([32, 12, 2])\n",
      "\n",
      "Данные после преобразования Фурье (частотная область):\n",
      "torch.Size([32, 12, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Параметры\n",
    "batch_size = 32  # Размер батча\n",
    "seq_len = 12     # Длина последовательности (количество временных шагов)\n",
    "num_nodes = 2   # Количество узлов (сенсоров)\n",
    "\n",
    "# Создаем случайные данные в формате [batch, seq_len, num_nodes]\n",
    "traffic_data = torch.randn(batch_size, seq_len, num_nodes)\n",
    "\n",
    "# Применяем преобразование Фурье\n",
    "# В PyTorch преобразование Фурье можно выполнить с помощью torch.fft.fft\n",
    "# Мы применяем его по оси времени (seq_len)\n",
    "traffic_data_fft = torch.fft.fft(traffic_data, dim=1)\n",
    "\n",
    "# Выводим результат\n",
    "print(\"Исходные данные (временная область):\")\n",
    "print(traffic_data.shape)\n",
    "print(\"\\nДанные после преобразования Фурье (частотная область):\")\n",
    "print(traffic_data_fft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[189], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 4. Линейное преобразование частотных данных\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# W_{F,t} \\cdot F_t\u001b[39;00m\n\u001b[0;32m     30\u001b[0m W_F_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(num_nodes, embedding_dim)  \u001b[38;5;66;03m# Обучаемый вес для частотных данных\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m F_t_transformed \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[43mW_F_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, F_t) \u001b[38;5;66;03m# [batch, seq_len, embedding_dim]\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mF_t\u001b[38;5;241m.\u001b[39mshape,\u001b[38;5;250m \u001b[39mW_F_t\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m= }\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# 5. Линейное преобразование временных меток\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# W_{T,t} \\cdot (T^{W}_t || T^{D}_t)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Параметры\n",
    "batch_size = 32  # Размер батча\n",
    "seq_len = 12     # Длина последовательности (количество временных шагов)\n",
    "num_nodes = 20   # Количество узлов (сенсоров)\n",
    "embedding_dim = 10  # Размерность эмбеддингов\n",
    "\n",
    "# Создаем случайные данные в формате [batch, seq_len, num_nodes]\n",
    "traffic_data = torch.randn(batch_size, seq_len, num_nodes)\n",
    "\n",
    "# 1. Преобразование Фурье\n",
    "# F_t = FFT(X_t)\n",
    "F_t = torch.fft.fft(traffic_data, dim=1)\n",
    "F_t = torch.abs(F_t)\n",
    "\n",
    "# 2. Эмбеддинг идентичности сенсоров\n",
    "# E_t: [batch, num_nodes, embedding_dim]\n",
    "idntity_eembedding = torch.randn(batch_size, num_nodes, embedding_dim)\n",
    "\n",
    "# 3. Временные метки (день недели и час дня)\n",
    "# T^{W}_t: [batch, seq_len, 1] (меток дня недели)\n",
    "# T^{D}_t: [batch, seq_len, 1] (меток часа дня)\n",
    "day_of_week = torch.randint(0, 7, (batch_size, seq_len, 1))  # Метки дня недели\n",
    "hour_of_day = torch.randint(0, 288, (batch_size, seq_len, 1))  # Метки часа дня\n",
    "\n",
    "# 4. Линейное преобразование частотных данных\n",
    "# W_{F,t} \\cdot F_t\n",
    "W_F_t = torch.randn(num_nodes, embedding_dim)  # Обучаемый вес для частотных данных\n",
    "F_t_transformed = torch.matmul(W_F_t.permute(0, 2, 1), F_t) # [batch, seq_len, embedding_dim]\n",
    "print(f'{F_t.shape, W_F_t.shape = }')\n",
    "\n",
    "# 5. Линейное преобразование временных меток\n",
    "# W_{T,t} \\cdot (T^{W}_t || T^{D}_t)\n",
    "W_T_t = torch.randn(7 + 288, embedding_dim)  # Обучаемый вес для временных меток\n",
    "\n",
    "# Конкатенация временных меток\n",
    "temporal_labels = torch.cat([day_of_week, hour_of_day], dim=-1)  # [batch, seq_len, 7 + 288]\n",
    "\n",
    "# Линейное преобразование временных меток\n",
    "temporal_embedding = torch.matmul(temporal_labels.float(), W_T_t)  # [batch, seq_len, embedding_dim]\n",
    "\n",
    "# 6. Конкатенация\n",
    "# DE_t = W_{F,t} \\cdot F_t || E_t || W_{T,t} \\cdot (T^{W}_t || T^{D}_t)\n",
    "# Расширяем размерности для конкатенации\n",
    "F_t_transformed_expanded = F_t_transformed.unsqueeze(2)  # [batch, seq_len, 1, embedding_dim]\n",
    "identity_embedding_expanded = identity_embedding.unsqueeze(1).expand(-1, seq_len, -1, -1)  # [batch, seq_len, num_nodes, embedding_dim]\n",
    "temporal_embedding_expanded = temporal_embedding.unsqueeze(2)  # [batch, seq_len, 1, embedding_dim]\n",
    "\n",
    "# Конкатенация\n",
    "DE_t = torch.cat([F_t_transformed_expanded, identity_embedding_expanded, temporal_embedding_expanded], dim=-1)\n",
    "\n",
    "# Выводим результат\n",
    "print(\"Результат конкатенации DE_t:\")\n",
    "print(DE_t.shape)  # Ожидаемый размер: [batch, seq_len, num_nodes, embedding_dim + embedding_dim + embedding_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
