{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Добавляем путь на уровень выше\n",
    "sys.path.append(str(Path(os.getcwd()).resolve().parent))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from utils.feature_engineering import add_features\n",
    "from utils.features import *\n",
    "\n",
    "# Загрузка данных из np.memmap\n",
    "def load_memmap(data_path, shape, dtype='float32', mode='r'):\n",
    "    \"\"\"Загружает данные из файла np.memmap.\"\"\"\n",
    "    return np.memmap(data_path, dtype=dtype, mode=mode, shape=shape)[:2016]\n",
    "\n",
    "# Сохранение данных в np.memmap\n",
    "def save_memmap(data, data_path, dtype='float32'):\n",
    "    \"\"\"Сохраняет данные в файл np.memmap.\"\"\"\n",
    "    # Преобразуем data_path в объект Path\n",
    "    data_path = Path(data_path)\n",
    "    \n",
    "    # Проверяем, существует ли папка\n",
    "    if not data_path.parent.exists():\n",
    "        # Создаем папку, если она не существует\n",
    "        data_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Папка {data_path.parent} создана.\")\n",
    "\n",
    "    # Сохраняем данные в np.memmap\n",
    "    memmap = np.memmap(data_path, dtype=dtype, mode='w+', shape=data.shape)\n",
    "    memmap[:] = data[:]\n",
    "    memmap.flush()\n",
    "    print(f\"Данные сохранены в {data_path}.\")\n",
    "\n",
    "def load_pkl(pickle_file: str) -> object:\n",
    "    \"\"\"\n",
    "    Load data from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        pickle_file (str): Path to the pickle file.\n",
    "\n",
    "    Returns:\n",
    "        object: Loaded object from the pickle file.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            pickle_data = pickle.load(f)\n",
    "    except UnicodeDecodeError:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            pickle_data = pickle.load(f, encoding='latin1')\n",
    "    except Exception as e:\n",
    "        print(f'Unable to load data from {pickle_file}: {e}')\n",
    "        raise\n",
    "    return pickle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('./data/all_data/PEMS-BAY/new2/')\n",
    "data_path = data_dir / 'data.dat'\n",
    "metadata_path = data_dir / 'desc.json'\n",
    "adj_path = data_dir / 'adj_mx.pkl'\n",
    "\n",
    "# Загрузка метаданных\n",
    "with open(metadata_path, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Загрузка данных\n",
    "data_shape = (metadata['num_time_steps'], metadata['num_nodes'], metadata['num_features'])\n",
    "data = load_memmap(data_path, shape=data_shape)\n",
    "\n",
    "try:\n",
    "    _, _, adj_mx_pb = load_pkl(adj_path)\n",
    "except ValueError:\n",
    "    adj_mx_pb = load_pkl(adj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convt, self).__init__()\n",
    "\n",
    "    def forward(self, x, w):\n",
    "        x = torch.einsum('bne, ek->bnk', (x, w))\n",
    "        return x.contiguous()\n",
    "    \n",
    "class nconv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(nconv, self).__init__()\n",
    "\n",
    "    def forward(self, x, A, dims):\n",
    "        if dims == 2:\n",
    "            x = torch.einsum('ncvl,vw->ncwl', (x, A))\n",
    "        elif dims == 3:\n",
    "            x = torch.einsum('ncvl,nvw->ncwl', (x, A))\n",
    "        else:\n",
    "            raise NotImplementedError('DFDGCN not implemented for A of dimension ' + str(dims))\n",
    "        return x.contiguous()\n",
    "\n",
    "class linear(nn.Module):\n",
    "    \"\"\"Linear layer.\"\"\"\n",
    "\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(linear, self).__init__()\n",
    "        self.mlp = torch.nn.Conv2d(c_in, c_out, kernel_size=(\n",
    "            1, 1), padding=(0, 0), stride=(1, 1), bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class gcn(nn.Module):\n",
    "    \"\"\"Graph convolution network.\"\"\"\n",
    "\n",
    "    def __init__(self, c_in, c_out, dropout, support_len=3, order=2):\n",
    "        super(gcn, self).__init__()\n",
    "        self.nconv = nconv()\n",
    "\n",
    "        self.c_in = c_in\n",
    "        c_in = (order * (support_len + 1) + 1) * self.c_in\n",
    "        self.mlp = linear(c_in, c_out)\n",
    "        self.dropout = dropout\n",
    "        self.order = order\n",
    "\n",
    "    def forward(self, x, support):\n",
    "\n",
    "        out = [x]\n",
    "        for a in support:\n",
    "            x1 = self.nconv(x, a.to(x.device), a.dim())\n",
    "            out.append(x1)\n",
    "\n",
    "            for k in range(2, self.order + 1):\n",
    "                x2 = self.nconv(x1, a.to(x1.device), a.dim())\n",
    "                out.append(x2)\n",
    "                x1 = x2\n",
    "        h = torch.cat(out, dim=1)\n",
    "        h = self.mlp(h)\n",
    "        h = F.dropout(h, self.dropout, training=self.training)\n",
    "        return h\n",
    "\n",
    "def dy_mask_graph(adj, k):\n",
    "    M = []\n",
    "    for i in range(adj.size(0)):\n",
    "        adp = adj[i]\n",
    "        mask = torch.zeros( adj.size(1),adj.size(2)).to(adj.device)\n",
    "        mask = mask.fill_(float(\"0\"))\n",
    "        s1, t1 = (adp + torch.rand_like(adp) * 0.01).topk(k, 1)\n",
    "        mask = mask.scatter_(1, t1, s1.fill_(1))\n",
    "        M.append(mask)\n",
    "    mask = torch.stack(M,dim=0)\n",
    "    adj = adj * mask\n",
    "    return adj\n",
    "\n",
    "def cat(x1,x2):\n",
    "    M = []\n",
    "    for i in range(x1.size(0)):\n",
    "        x = x1[i]\n",
    "        new_x = torch.cat([x,x2],dim=1)\n",
    "        M.append(new_x)\n",
    "    result = torch.stack(M,dim=0)\n",
    "    return result\n",
    "\n",
    "\n",
    "class DFDGCN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_nodes, dropout=0.3, supports=None,\n",
    "                    gcn_bool=True, addaptadj=True, aptinit=None,\n",
    "                    in_dim=2, out_dim=12, residual_channels=32,\n",
    "                    dilation_channels=32, skip_channels=256, end_channels=512,\n",
    "                    kernel_size=2, blocks=4, layers=2, a=1, seq_len=12, affine=True, fft_emb=10, identity_emb=10, hidden_emb=30, subgraph=20):\n",
    "        super(DFDGCN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.blocks = blocks\n",
    "        self.layers = layers\n",
    "        self.gcn_bool = gcn_bool\n",
    "        self.addaptadj = addaptadj\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs = nn.ModuleList()\n",
    "        self.residual_convs = nn.ModuleList()\n",
    "        self.skip_convs = nn.ModuleList()\n",
    "        self.bn = nn.ModuleList()\n",
    "        self.gconv = nn.ModuleList()\n",
    "        self.seq_len = seq_len\n",
    "        self.a = a\n",
    "\n",
    "        self.start_conv = nn.Conv2d(in_channels=in_dim,\n",
    "                                    out_channels=residual_channels,\n",
    "                                    kernel_size=(1, 1))\n",
    "\n",
    "        self.supports = supports\n",
    "        self.emb = fft_emb\n",
    "        self.subgraph_size = subgraph\n",
    "        self.identity_emb = identity_emb\n",
    "        self.hidden_emb = hidden_emb\n",
    "        self.fft_len = round(seq_len//2) + 1\n",
    "        self.Ex1 = nn.Parameter(torch.randn(self.fft_len, self.emb), requires_grad=True)\n",
    "        self.Wd = nn.Parameter(torch.randn(num_nodes,self.emb + self.identity_emb + self.seq_len * (in_dim-1), self.hidden_emb), requires_grad=True)\n",
    "        self.Wxabs = nn.Parameter(torch.randn(self.hidden_emb, self.hidden_emb), requires_grad=True)\n",
    "\n",
    "        self.mlp = linear(residual_channels * 4,residual_channels)\n",
    "        self.layersnorm = torch.nn.LayerNorm(normalized_shape=[num_nodes,self.hidden_emb], eps=1e-08,elementwise_affine=affine)\n",
    "        self.convt = convt()\n",
    "\n",
    "        self.node1 = nn.Parameter(\n",
    "            torch.randn(num_nodes, self.identity_emb), requires_grad=True)\n",
    "        self.drop = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.T_i_D_emb = nn.Parameter(\n",
    "            torch.empty(288, self.seq_len))\n",
    "        self.D_i_W_emb = nn.Parameter(\n",
    "            torch.empty(7, self.seq_len))\n",
    "        self.G_emb = nn.Parameter(\n",
    "            torch.empty(num_nodes, self.seq_len))\n",
    "\n",
    "        receptive_field = 1\n",
    "        self.reset_parameter()\n",
    "        self.supports_len = 0\n",
    "        if not addaptadj:\n",
    "            self.supports_len -= 1\n",
    "        if supports is not None:\n",
    "            self.supports_len += len(supports)\n",
    "        if gcn_bool and addaptadj:\n",
    "            if aptinit is None:\n",
    "                if supports is None:\n",
    "                    self.supports = []\n",
    "                self.nodevec1 = nn.Parameter(\n",
    "                    torch.randn(num_nodes, self.emb), requires_grad=True)\n",
    "                self.nodevec2 = nn.Parameter(\n",
    "                    torch.randn(self.emb, num_nodes), requires_grad=True)\n",
    "                self.supports_len += 1\n",
    "            else:\n",
    "                if supports is None:\n",
    "                    self.supports = []\n",
    "                m, p, n = torch.svd(aptinit)\n",
    "                initemb1 = torch.mm(m[:, :10], torch.diag(p[:10] ** 0.5))\n",
    "                initemb2 = torch.mm(torch.diag(p[:10] ** 0.5), n[:, :10].t())\n",
    "                self.nodevec1 = nn.Parameter(initemb1, requires_grad=True)\n",
    "                self.nodevec2 = nn.Parameter(initemb2, requires_grad=True)\n",
    "                self.supports_len += 1\n",
    "\n",
    "        for b in range(blocks):\n",
    "            additional_scope = kernel_size - 1\n",
    "            new_dilation = 1\n",
    "            for i in range(layers):\n",
    "                # dilated convolutions\n",
    "                self.filter_convs.append(nn.Conv2d(in_channels=residual_channels,\n",
    "                                                   out_channels=dilation_channels,\n",
    "                                                   kernel_size=(1, kernel_size), dilation=new_dilation))\n",
    "\n",
    "                self.gate_convs.append(nn.Conv2d(in_channels=residual_channels,\n",
    "                                                 out_channels=dilation_channels,\n",
    "                                                 kernel_size=(1, kernel_size), dilation=new_dilation))\n",
    "\n",
    "                # 1x1 convolution for residual connection\n",
    "                self.residual_convs.append(nn.Conv2d(in_channels=dilation_channels,\n",
    "                                                     out_channels=residual_channels,\n",
    "                                                     kernel_size=(1, 1)))\n",
    "\n",
    "                # 1x1 convolution for skip connection\n",
    "                self.skip_convs.append(nn.Conv2d(in_channels=dilation_channels,\n",
    "                                                 out_channels=skip_channels,\n",
    "                                                 kernel_size=(1, 1)))\n",
    "                self.bn.append(nn.BatchNorm2d(residual_channels))\n",
    "                new_dilation *= 2\n",
    "                receptive_field += additional_scope\n",
    "                additional_scope *= 2\n",
    "                if self.gcn_bool:\n",
    "                    self.gconv.append(\n",
    "                        gcn(dilation_channels, residual_channels, dropout, support_len=self.supports_len))\n",
    "        self.end_conv_1 = nn.Conv2d(in_channels=skip_channels,\n",
    "                                    out_channels=end_channels,\n",
    "                                    kernel_size=(1, 1),\n",
    "                                    bias=True)\n",
    "\n",
    "        self.end_conv_2 = nn.Conv2d(in_channels=end_channels,\n",
    "                                    out_channels=out_dim,\n",
    "                                    kernel_size=(1, 1),\n",
    "                                    bias=True)\n",
    "\n",
    "        self.receptive_field = receptive_field\n",
    "\n",
    "    def reset_parameter(self):\n",
    "        nn.init.xavier_uniform_(self.T_i_D_emb)\n",
    "        nn.init.xavier_uniform_(self.D_i_W_emb)\n",
    "\n",
    "\n",
    "    def forward(self, history_data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Feedforward function of DFDGCN; Based on Graph WaveNet\n",
    "\n",
    "        Args:\n",
    "            history_data (torch.Tensor): shape [B, L, N, C]\n",
    "\n",
    "        Graphs:\n",
    "            predefined graphs: two graphs; [2, N, N] : Pre-given graph structure, including in-degree and out-degree graphs\n",
    "\n",
    "            self-adaptive graph: [N, N] : Self-Adaptively constructed graphs with two learnable parameters\n",
    "                torch.mm(self.nodevec1, self.nodevec2)\n",
    "                    nodevec: [N, Emb]\n",
    "\n",
    "            dynamic frequency domain graph: [B, N, N] : Data-driven graphs constructed with frequency domain information from traffic data\n",
    "                traffic_data : [B, N, L]\n",
    "                frequency domain information : [B, N, L/2.round + 1] ------Embedding ------[B, N, Emb2]\n",
    "                Identity embedding : learnable parameter [N, Emb3]\n",
    "                Time embedding : Week and Day : [N, 7] [N, 24(hour) * 12 (60min / 5min due to sampling)] ------Embedding ------ [N, 2 * Emb4]\n",
    "                Concat frequency domain information + Identity embedding + Time embedding ------Embedding , Activating, Normalization and Dropout\n",
    "                Conv1d to get adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: [B, L, N, 1]\n",
    "        \"\"\"\n",
    "        #num_feat = model_args[\"num_feat\"]\n",
    "        input = history_data.transpose(1, 3).contiguous()[:,:,:,:]\n",
    "        \n",
    "        data = history_data\n",
    "\n",
    "        in_len = input.size(3)\n",
    "        if in_len < self.receptive_field:\n",
    "            x = nn.functional.pad(\n",
    "                input, (self.receptive_field-in_len, 0, 0, 0))\n",
    "        else:\n",
    "            x = input\n",
    "        x = self.start_conv(x)\n",
    "\n",
    "        skip = 0\n",
    "        if self.gcn_bool and self.addaptadj and self.supports is not None:\n",
    "\n",
    "\n",
    "            gwadp = F.softmax(\n",
    "                F.relu(torch.mm(self.nodevec1, self.nodevec2)), dim=1)\n",
    "\n",
    "            new_supports = self.supports + [gwadp] # pretrained graph in DCRNN and self-adaptive graph in GWNet\n",
    "\n",
    "            # Construction of dynamic frequency domain graph\n",
    "            xn1 = input[:, 0, :, -self.seq_len:]\n",
    "\n",
    "            T_D = self.T_i_D_emb[(data[:, :, :, 1] * 288).type(torch.LongTensor)][:, -1, :, :]\n",
    "            D_W = self.D_i_W_emb[(data[:, :, :, 2] * 7).type(torch.LongTensor)][:, -1, :, :]\n",
    "            G_E = self.G_emb[(data[:, :, :, 3]).type(torch.LongTensor)][:, -1, :, :]\n",
    "\n",
    "            xn1 = torch.fft.rfft(xn1, dim=-1)\n",
    "            xn1 = torch.abs(xn1)\n",
    "\n",
    "            xn1 = torch.nn.functional.normalize(xn1, p=2.0, dim=1, eps=1e-12, out=None)\n",
    "            xn1 = torch.nn.functional.normalize(xn1, p=2.0, dim=2, eps=1e-12, out=None) * self.a\n",
    "\n",
    "            xn1 = torch.matmul(xn1, self.Ex1)\n",
    "            xn1k = cat(xn1, self.node1)\n",
    "            x_n1 = torch.cat([xn1k, T_D, D_W,G_E], dim=2)\n",
    "            x1 = torch.bmm(x_n1.permute(1,0,2),self.Wd).permute(1,0,2)\n",
    "            x1 = torch.relu(x1)\n",
    "            x1k = self.layersnorm(x1)\n",
    "            x1k = self.drop(x1k)\n",
    "            adp = self.convt(x1k, self.Wxabs)\n",
    "            adj = torch.bmm(adp, x1.permute(0, 2, 1))\n",
    "            adp = torch.relu(adj)\n",
    "            adp = dy_mask_graph(adp, self.subgraph_size)\n",
    "            adp = F.softmax(adp, dim=2)\n",
    "            new_supports = new_supports + [adp]\n",
    "\n",
    "        # WaveNet layers\n",
    "        for i in range(self.blocks * self.layers):\n",
    "\n",
    "            # dilated convolution\n",
    "            residual = x\n",
    "            filter = self.filter_convs[i](residual)\n",
    "            filter = torch.tanh(filter)\n",
    "            gate = self.gate_convs[i](residual)\n",
    "            gate = torch.sigmoid(gate)\n",
    "            x = filter * gate\n",
    "\n",
    "            # parametrized skip connection\n",
    "            s = x\n",
    "            s = self.skip_convs[i](s)\n",
    "            try:\n",
    "                skip = skip[:, :, :,  -s.size(3):]\n",
    "            except:\n",
    "                skip = 0\n",
    "            skip = s + skip\n",
    "\n",
    "            if self.gcn_bool and self.supports is not None:\n",
    "                if self.addaptadj:\n",
    "                    x = self.gconv[i](x, new_supports)\n",
    "\n",
    "                else:\n",
    "                    x = self.gconv[i](x, self.supports)\n",
    "            else:\n",
    "                x = self.residual_convs[i](x)\n",
    "            x = x + residual[:, :, :, -x.size(3):]\n",
    "\n",
    "            x = self.bn[i](x)\n",
    "\n",
    "        x = F.relu(skip)\n",
    "        x = F.relu(self.end_conv_1(x))\n",
    "        x = self.end_conv_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2016, 325, 4)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[:, :, [0,1,2,6]]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Данные и параметры\n",
    "L, N, C = data.shape  # [2016, 325, C]\n",
    "batch_size = 16\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "seq_len = 12  # Количество временных шагов на вход\n",
    "pred_len = 1  # Количество временных шагов для предсказания\n",
    "\n",
    "# Индексы каналов для нормализации\n",
    "normalize = True\n",
    "channels_to_normalize = [0,3]  # Пример: нормализуем каналы 0 и 3\n",
    "\n",
    "# Проверка корректности разделения данных\n",
    "assert train_ratio + val_ratio + test_ratio == 1.0, \"Сумма долей train, val и test должна быть равна 1.0\"\n",
    "\n",
    "# Разделение данных на train, val и test\n",
    "num_samples = data.shape[0]  # Количество временных шагов (L)\n",
    "train_size = int(num_samples * train_ratio)\n",
    "val_size = int(num_samples * val_ratio)\n",
    "test_size = num_samples - train_size - val_size\n",
    "\n",
    "train_data = data[:train_size, :, :]  # [train_size, N, C]\n",
    "val_data = data[train_size:train_size + val_size, :, :]  # [val_size, N, C]\n",
    "test_data = data[train_size + val_size:, :, :]  # [test_size, N, C]\n",
    "\n",
    "# Убедитесь, что данные имеют разрешение на запись\n",
    "train_data = train_data.copy()\n",
    "val_data = val_data.copy()\n",
    "test_data = test_data.copy()\n",
    "\n",
    "# Нормализация данных\n",
    "if normalize:\n",
    "    assert all(0 <= ch < C for ch in channels_to_normalize), \"Индексы каналов выходят за пределы допустимого диапазона\"\n",
    "    channel_max = train_data[:, :, channels_to_normalize].max(axis=(0, 1), keepdims=True)  # Форма [1, 1, len(channels_to_normalize)]\n",
    "    channel_max[channel_max == 0] = 1.0\n",
    "    train_data[:, :, channels_to_normalize] = train_data[:, :, channels_to_normalize] / channel_max\n",
    "    val_data[:, :, channels_to_normalize] = val_data[:, :, channels_to_normalize] / channel_max\n",
    "    test_data[:, :, channels_to_normalize] = test_data[:, :, channels_to_normalize] / channel_max\n",
    "\n",
    "\n",
    "# Создание кастомного Dataset\n",
    "class TrafficDataset(Dataset):\n",
    "    def __init__(self, data, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.data = data  # Форма [L, N, C]\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "    def __len__(self):\n",
    "        # Количество возможных последовательностей\n",
    "        return self.data.shape[0] - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Извлекаем последовательность входных данных\n",
    "        x = self.data[idx:idx + self.seq_len, :, :]  # Форма [seq_len, N, C]\n",
    "        # Извлекаем целевую последовательность\n",
    "        y = self.data[idx + self.seq_len:idx + self.seq_len + self.pred_len, :, 0]  # Форма [pred_len, N, C]\n",
    "        return x, y\n",
    "\n",
    "# Создание DataLoader\n",
    "train_dataset = TrafficDataset(train_data, seq_len, pred_len)\n",
    "val_dataset = TrafficDataset(val_data, seq_len, pred_len)\n",
    "test_dataset = TrafficDataset(test_data, seq_len, pred_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Определение устройства\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else 'cpu'  # Устанавливаем CPU вместо CUDA\n",
    "print(device)\n",
    "\n",
    "# Обновление модели, данных и вычислений\n",
    "supports = [torch.tensor(adj_mx_pb, dtype=torch.float32)]\n",
    "model = DFDGCN(num_nodes=N, supports=supports, in_dim=C, out_dim=pred_len).to(device)  # Модель на CPU\n",
    "criterion = nn.MSELoss()  # Функция потерь\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "# Инициализация TensorBoard\n",
    "writer = SummaryWriter(log_dir=f\"runs/traffic_prediction/clustering_coefficient\")\n",
    "\n",
    "def compute_metrics(output, target):\n",
    "    \"\"\"Вычисление метрик MAE, RMSE, MAPE.\"\"\"\n",
    "    abs_error = torch.abs(output - target).sum().item()\n",
    "    mae = abs_error / len(target)\n",
    "    rmse = ((output - target) ** 2).sum().item() / len(target)\n",
    "    rmse = rmse ** 0.5\n",
    "    mape = (abs_error / torch.abs(target).sum().item()) if torch.abs(target).sum().item() != 0 else 0\n",
    "    return mae, rmse, mape\n",
    "\n",
    "def train_val_test_model(model, train_loader, val_loader, test_loader, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # === Тренировка ===\n",
    "        model.train()\n",
    "        train_loss, train_mae, train_rmse, train_mape = 0.0, 0.0, 0.0, 0.0\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Training\", leave=False)\n",
    "\n",
    "        for x, y in train_loader_tqdm:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x).squeeze(-1)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "\n",
    "            mae, rmse, mape = compute_metrics(output, y)\n",
    "            train_mae += mae\n",
    "            train_rmse += rmse\n",
    "            train_mape += mape\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_mae /= len(train_loader)\n",
    "        train_rmse /= len(train_loader)\n",
    "        train_mape /= len(train_loader)\n",
    "\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch + 1)\n",
    "        writer.add_scalar(\"MAE/Train\", train_mae, epoch + 1)\n",
    "        writer.add_scalar(\"RMSE/Train\", train_rmse, epoch + 1)\n",
    "        writer.add_scalar(\"MAPE/Train\", train_mape, epoch + 1)\n",
    "\n",
    "        # === Валидация ===\n",
    "        model.eval()\n",
    "        val_loss, val_mae, val_rmse, val_mape = 0.0, 0.0, 0.0, 0.0\n",
    "        val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Validation\", leave=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader_tqdm:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = model(x).squeeze(-1)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item() * x.size(0)\n",
    "\n",
    "                mae, rmse, mape = compute_metrics(output, y)\n",
    "                val_mae += mae\n",
    "                val_rmse += rmse\n",
    "                val_mape += mape\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_mae /= len(val_loader)\n",
    "        val_rmse /= len(val_loader)\n",
    "        val_mape /= len(val_loader)\n",
    "\n",
    "        writer.add_scalar(\"Loss/Validation\", val_loss, epoch + 1)\n",
    "        writer.add_scalar(\"MAE/Validation\", val_mae, epoch + 1)\n",
    "        writer.add_scalar(\"RMSE/Validation\", val_rmse, epoch + 1)\n",
    "        writer.add_scalar(\"MAPE/Validation\", val_mape, epoch + 1)\n",
    "\n",
    "        # === Тестирование ===\n",
    "        test_loss, test_mae, test_rmse, test_mape = 0.0, 0.0, 0.0, 0.0\n",
    "        test_loader_tqdm = tqdm(test_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Testing\", leave=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader_tqdm:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = model(x).squeeze(-1)\n",
    "                loss = criterion(output, y)\n",
    "                test_loss += loss.item() * x.size(0)\n",
    "\n",
    "                mae, rmse, mape = compute_metrics(output, y)\n",
    "                test_mae += mae\n",
    "                test_rmse += rmse\n",
    "                test_mape += mape\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_mae /= len(test_loader)\n",
    "        test_rmse /= len(test_loader)\n",
    "        test_mape /= len(test_loader)\n",
    "\n",
    "        writer.add_scalar(\"Loss/Test\", test_loss, epoch + 1)\n",
    "        writer.add_scalar(\"MAE/Test\", test_mae, epoch + 1)\n",
    "        writer.add_scalar(\"RMSE/Test\", test_rmse, epoch + 1)\n",
    "        writer.add_scalar(\"MAPE/Test\", test_mape, epoch + 1)\n",
    "\n",
    "        # Сохранение лучшей модели\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    }
   ],
   "source": [
    "train_val_test_model(model, train_loader, val_loader, test_loader, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
