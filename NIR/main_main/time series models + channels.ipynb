{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import math\n",
    "import numpy.linalg as la\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Загрузка данных\n",
    "with h5py.File('../data/raw_data/METR-LA/METR-LA.h5', 'r') as file:\n",
    "    axis0 = file['df']['axis0'][:]              # Идентификаторы датчиков\n",
    "    axis1 = file['df']['axis1'][:]              # Метки времени\n",
    "    timestamps = pd.to_datetime(axis1)          # Преобразование меток времени в формат datetime\n",
    "    df_data = file['df']['block0_values'][:]    # Данные замеров скорости\n",
    "\n",
    "axis0 = [x.decode('utf-8') for x in axis0]\n",
    "metr_la = pd.DataFrame(df_data, index=timestamps, columns=axis0)\n",
    "metr_la = metr_la.iloc[:2016, :2]\n",
    "\n",
    "# Загрузка матрицы смежности\n",
    "with open('../data/raw_data/METR-LA/adj_METR-LA.pkl', 'rb') as file:\n",
    "    data = pickle.load(file, encoding='bytes')\n",
    "\n",
    "node_ids = [x.decode('utf-8') for x in data[0]]  # Получаем список id узлов из data[0]\n",
    "adj_matrix = data[2]  # Получаем матрицу смежности из data[2]\n",
    "metr_la_adj = pd.DataFrame(adj_matrix, index=node_ids, columns=node_ids)  # Создание DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Проверка доступности GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainX shape: torch.Size([1597, 12, 2, 3])\n",
      "TrainY shape: torch.Size([1597, 3, 2, 3])\n",
      "TestX shape: torch.Size([389, 12, 2, 3])\n",
      "TestY shape: torch.Size([389, 3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Нормализация данных\n",
    "def normalize_data(trainX, testX):\n",
    "    scaler = MinMaxScaler()\n",
    "    trainX_shape = trainX.shape\n",
    "    testX_shape = testX.shape\n",
    "    trainX = scaler.fit_transform(trainX.reshape(-1, trainX_shape[-1])).reshape(trainX_shape)\n",
    "    testX = scaler.transform(testX.reshape(-1, testX_shape[-1])).reshape(testX_shape)\n",
    "    return trainX, testX, scaler\n",
    "\n",
    "# Функция для добавления дополнительных фичей\n",
    "def add_features(data, **kwargs):\n",
    "    \"\"\"\n",
    "    Добавляет фичи в данные, поддерживая канал измерений.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): Исходные данные, shape: [time, nodes, channels] или [time, nodes].\n",
    "        **kwargs: Словарь функций {feature_name: function}, где функция применяется по времени для каждого узла.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Обновленные данные с дополнительными фичами, shape: [time, nodes, channels+N].\n",
    "    \"\"\"\n",
    "    # Если данных нет размерности каналов, добавляем её\n",
    "    if len(data.shape) == 2:  # [time, nodes]\n",
    "        data = data[..., np.newaxis]  # Преобразуем в [time, nodes, 1]\n",
    "    \n",
    "    # Преобразуем данные в DataFrame для удобства добавления фичей\n",
    "    time, nodes, channels = data.shape\n",
    "    df = pd.DataFrame(data.reshape(time, -1))\n",
    "\n",
    "    # Добавляем фичи\n",
    "    new_features = []\n",
    "    for feature_name, func in kwargs.items():\n",
    "        feature = df.apply(func, axis=0).fillna(0).values  # Заполняем NaN значениями 0\n",
    "        new_features.append(feature[..., np.newaxis])  # Добавляем размерность каналов\n",
    "    \n",
    "    # Объединяем оригинальные данные и новые фичи\n",
    "    new_features = np.concatenate(new_features, axis=-1)  # [time, nodes, N]\n",
    "    data = np.concatenate([data, new_features], axis=-1)  # [time, nodes, channels + N]\n",
    "    return data\n",
    "\n",
    "# Предобработка данных\n",
    "def preprocess_data_multichannel(data, time_len, rate, seq_len, pre_len):\n",
    "    \"\"\"\n",
    "    Преобразует данные в формат [batch, seq_len, nodes, channels].\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): Исходные данные, shape: [time, nodes, channels].\n",
    "        time_len (int): Общее количество временных точек.\n",
    "        rate (float): Доля обучающей выборки.\n",
    "        seq_len (int): Длина входной последовательности.\n",
    "        pre_len (int): Длина предсказания.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (trainX, trainY, testX, testY)\n",
    "    \"\"\"\n",
    "    train_size = int(time_len * rate)\n",
    "    train_data = data[:train_size]\n",
    "    test_data = data[train_size:time_len]\n",
    "\n",
    "    trainX, trainY, testX, testY = [], [], [], []\n",
    "    for i in range(len(train_data) - seq_len - pre_len):\n",
    "        a = train_data[i: i + seq_len + pre_len]\n",
    "        trainX.append(a[0: seq_len])  # Shape: [seq_len, nodes, channels]\n",
    "        trainY.append(a[seq_len: seq_len + pre_len])  # Shape: [pre_len, nodes, channels]\n",
    "    for i in range(len(test_data) - seq_len - pre_len):\n",
    "        b = test_data[i: i + seq_len + pre_len]\n",
    "        testX.append(b[0: seq_len])\n",
    "        testY.append(b[seq_len: seq_len + pre_len])\n",
    "    \n",
    "    return np.array(trainX), np.array(trainY), np.array(testX), np.array(testY)\n",
    "\n",
    "# Пример использования\n",
    "time_len = len(metr_la)\n",
    "rate = 0.8\n",
    "seq_len = 12\n",
    "pre_len = 3\n",
    "\n",
    "# Добавление mean и std\n",
    "metr_la_array = metr_la.values  # Исходные данные [time, nodes]\n",
    "metr_la_extended = add_features(\n",
    "    metr_la_array,\n",
    "    mean=lambda x: pd.Series(x).rolling(window=5, min_periods=1).mean().values,\n",
    "    std=lambda x: pd.Series(x).rolling(window=5, min_periods=1).std().values\n",
    ")\n",
    "\n",
    "# Преобразование в массив [time, nodes, channels]\n",
    "trainX, trainY, testX, testY = preprocess_data_multichannel(metr_la_extended, time_len, rate, seq_len, pre_len)\n",
    "\n",
    "# Нормализация данных\n",
    "trainX_norm, testX_norm, scaler_X = normalize_data(trainX, testX)\n",
    "trainY_norm, testY_norm, scaler_Y = normalize_data(trainY, testY)\n",
    "\n",
    "# Преобразование в тензоры PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainX_norm = torch.tensor(trainX_norm, dtype=torch.float32).to(device)\n",
    "trainY_norm = torch.tensor(trainY_norm, dtype=torch.float32).to(device)\n",
    "testX_norm = torch.tensor(testX_norm, dtype=torch.float32).to(device)\n",
    "testY_norm = torch.tensor(testY_norm, dtype=torch.float32).to(device)\n",
    "\n",
    "# Вывод размерности данных\n",
    "print(f\"TrainX shape: {trainX_norm.shape}\")  # [batch, seq_len, nodes, channels]\n",
    "print(f\"TrainY shape: {trainY_norm.shape}\")  # [batch, pre_len, nodes, channels]\n",
    "print(f\"TestX shape: {testX_norm.shape}\")    # [batch, seq_len, nodes, channels]\n",
    "print(f\"TestY shape: {testY_norm.shape}\")    # [batch, pre_len, nodes, channels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, pre_len=3):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.pre_len = pre_len\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, seq_len, nodes, channels]\n",
    "        batch, seq_len, nodes, channels = x.size()\n",
    "        x = x.view(batch * nodes, seq_len, channels)  # Merge batch and nodes dimensions for LSTM\n",
    "        \n",
    "        h_lstm, _ = self.lstm(x)  # h_lstm shape: [batch * nodes, seq_len, hidden_size]\n",
    "        h_lstm = h_lstm[:, -self.pre_len:, :]  # Take last `pre_len` steps\n",
    "        \n",
    "        out = self.fc(h_lstm)  # shape: [batch * nodes, pre_len, output_size]\n",
    "        out = out.view(batch, nodes, self.pre_len, -1).permute(0, 2, 1, 3)  # [batch, pre_len, nodes, output_size]\n",
    "        return out  # Final shape: [batch, pre_len, nodes, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainX, trainY, testX, testY, scaler_Y, epochs=50, lr=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(trainX)  # outputs shape: [batch, pre_len, output_size]\n",
    "        loss = criterion(outputs, trainY)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Оценка модели\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions_norm = model(testX).cpu().numpy()  # predictions shape: [batch, pre_len, output_size]\n",
    "\n",
    "    # Восстановление данных\n",
    "    predictions = scaler_Y.inverse_transform(predictions_norm.reshape(-1, predictions_norm.shape[-1]))\n",
    "    predictions = predictions.reshape(predictions_norm.shape)  # Восстановление исходной формы\n",
    "    actuals = scaler_Y.inverse_transform(testY.cpu().numpy().reshape(-1, testY.shape[-1]))\n",
    "    actuals = actuals.reshape(testY.shape)  # Восстановление исходной формы\n",
    "\n",
    "    # Метрики\n",
    "    rmse = np.sqrt(mean_squared_error(actuals.reshape(-1), predictions.reshape(-1)))\n",
    "    mae = mean_absolute_error(actuals.reshape(-1), predictions.reshape(-1))\n",
    "    r2 = r2_score(actuals.reshape(-1), predictions.reshape(-1))\n",
    "    var = np.var(actuals - predictions)\n",
    "    return rmse, mae, r2, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LSTM with params: {'epochs': 100, 'hidden_size': 32, 'lr': 0.002, 'num_layers': 4}\n",
      "Epoch [100/100], Loss: 0.0215\n",
      "Testing LSTM with params: {'epochs': 100, 'hidden_size': 64, 'lr': 0.002, 'num_layers': 4}\n",
      "Epoch [100/100], Loss: 0.0211\n",
      "Testing LSTM with params: {'epochs': 100, 'hidden_size': 128, 'lr': 0.002, 'num_layers': 4}\n",
      "Epoch [100/100], Loss: 0.0215\n",
      "Testing LSTM with params: {'epochs': 300, 'hidden_size': 32, 'lr': 0.002, 'num_layers': 4}\n",
      "Epoch [100/300], Loss: 0.0213\n",
      "Epoch [200/300], Loss: 0.0196\n",
      "Epoch [300/300], Loss: 0.0178\n",
      "Testing LSTM with params: {'epochs': 300, 'hidden_size': 64, 'lr': 0.002, 'num_layers': 4}\n",
      "Epoch [100/300], Loss: 0.0214\n",
      "Epoch [200/300], Loss: 0.0187\n",
      "Epoch [300/300], Loss: 0.0173\n",
      "Testing LSTM with params: {'epochs': 300, 'hidden_size': 128, 'lr': 0.002, 'num_layers': 4}\n",
      "Epoch [100/300], Loss: 0.0209\n",
      "Epoch [200/300], Loss: 0.0178\n",
      "Epoch [300/300], Loss: 0.0170\n",
      "Best params for LSTM: {'epochs': 300, 'hidden_size': 64, 'lr': 0.002, 'num_layers': 4}\n",
      "Best RMSE for LSTM: 12.535747528076172\n",
      "All results:\n",
      "params                                                                rmse      mae        r2      var\n",
      "-----------------------------------------------------------------  -------  -------  --------  -------\n",
      "{'epochs': 100, 'hidden_size': 32, 'lr': 0.002, 'num_layers': 4}   13.3345  6.55594  0.778689  176.236\n",
      "{'epochs': 100, 'hidden_size': 64, 'lr': 0.002, 'num_layers': 4}   13.2078  6.54176  0.782872  173.294\n",
      "{'epochs': 100, 'hidden_size': 128, 'lr': 0.002, 'num_layers': 4}  13.3469  6.51105  0.778275  176.294\n",
      "{'epochs': 300, 'hidden_size': 32, 'lr': 0.002, 'num_layers': 4}   12.5394  6.14694  0.804293  156.904\n",
      "{'epochs': 300, 'hidden_size': 64, 'lr': 0.002, 'num_layers': 4}   12.5357  6.27005  0.804407  157.138\n",
      "{'epochs': 300, 'hidden_size': 128, 'lr': 0.002, 'num_layers': 4}  12.6466  6.39376  0.800931  159.937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Определение сетки параметров для LSTM\n",
    "param_grid = {\n",
    "    \"hidden_size\": [32, 64, 128],\n",
    "    \"num_layers\": [4],\n",
    "    \"lr\": [0.002],\n",
    "    \"epochs\": [100, 300]\n",
    "}\n",
    "\n",
    "# Функция для Grid Search\n",
    "def grid_search_lstm(model_class, param_grid, trainX, trainY, testX, testY, scaler_Y):\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_params = None\n",
    "    results = []\n",
    "\n",
    "    # Перебор всех комбинаций параметров\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        print(f\"Testing LSTM with params: {params}\")\n",
    "\n",
    "        # Создание модели LSTM\n",
    "        model = model_class(\n",
    "            input_size=trainX.shape[3],  # Размерность входных фичей (channels)\n",
    "            hidden_size=params[\"hidden_size\"],\n",
    "            output_size=trainY.shape[3],  # Размерность выходных фичей (channels)\n",
    "            num_layers=params[\"num_layers\"],\n",
    "            pre_len=trainY.shape[1]\n",
    "        )\n",
    "\n",
    "        # Обучение модели\n",
    "        rmse, mae, r2, var = train_model(\n",
    "            model, trainX, trainY, testX, testY, scaler_Y,\n",
    "            epochs=params[\"epochs\"], lr=params[\"lr\"]\n",
    "        )\n",
    "\n",
    "        # Сохранение результатов\n",
    "        results.append({\n",
    "            \"params\": params,\n",
    "            \"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "            \"r2\": r2,\n",
    "            \"var\": var\n",
    "        })\n",
    "\n",
    "        # Обновление лучших параметров\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_params = params\n",
    "\n",
    "    return best_params, best_rmse, results\n",
    "\n",
    "# Выполнение Grid Search для LSTM\n",
    "best_params, best_rmse, results = grid_search_lstm(\n",
    "    LSTMModel, param_grid, trainX_norm, trainY_norm, testX_norm, testY_norm, scaler_Y\n",
    ")\n",
    "\n",
    "# Вывод лучших параметров и результатов\n",
    "print(f\"Best params for LSTM: {best_params}\")\n",
    "print(f\"Best RMSE for LSTM: {best_rmse}\")\n",
    "print(\"All results:\")\n",
    "print(tabulate(results, headers=\"keys\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
