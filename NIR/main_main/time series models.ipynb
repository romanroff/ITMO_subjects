{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import math\n",
    "import numpy.linalg as la\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Загрузка данных\n",
    "with h5py.File('../data/raw_data/METR-LA/METR-LA.h5', 'r') as file:\n",
    "    axis0 = file['df']['axis0'][:]              # Идентификаторы датчиков\n",
    "    axis1 = file['df']['axis1'][:]              # Метки времени\n",
    "    timestamps = pd.to_datetime(axis1)          # Преобразование меток времени в формат datetime\n",
    "    df_data = file['df']['block0_values'][:]    # Данные замеров скорости\n",
    "\n",
    "axis0 = [x.decode('utf-8') for x in axis0]\n",
    "metr_la = pd.DataFrame(df_data, index=timestamps, columns=axis0)\n",
    "metr_la = metr_la.iloc[:2016, :2]\n",
    "\n",
    "# Загрузка матрицы смежности\n",
    "with open('../data/raw_data/METR-LA/adj_METR-LA.pkl', 'rb') as file:\n",
    "    data = pickle.load(file, encoding='bytes')\n",
    "\n",
    "node_ids = [x.decode('utf-8') for x in data[0]]  # Получаем список id узлов из data[0]\n",
    "adj_matrix = data[2]  # Получаем матрицу смежности из data[2]\n",
    "metr_la_adj = pd.DataFrame(adj_matrix, index=node_ids, columns=node_ids)  # Создание DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Проверка доступности GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка данных (ваша функция)\n",
    "def preprocess_data(data, time_len, rate, seq_len, pre_len):\n",
    "    data = np.array(data)\n",
    "    train_size = int(time_len * rate)\n",
    "    train_data = data[:train_size]\n",
    "    test_data = data[train_size:time_len]\n",
    "\n",
    "    trainX, trainY, testX, testY = [], [], [], []\n",
    "    for i in range(len(train_data) - seq_len - pre_len):\n",
    "        a = train_data[i: i + seq_len + pre_len]\n",
    "        trainX.append(a[0: seq_len])\n",
    "        trainY.append(a[seq_len: seq_len + pre_len])\n",
    "    for i in range(len(test_data) - seq_len - pre_len):\n",
    "        b = test_data[i: i + seq_len + pre_len]\n",
    "        testX.append(b[0: seq_len])\n",
    "        testY.append(b[seq_len: seq_len + pre_len])\n",
    "    return np.array(trainX), np.array(trainY), np.array(testX), np.array(testY)\n",
    "\n",
    "# Параметры\n",
    "time_len = len(metr_la)\n",
    "rate = 0.8\n",
    "seq_len = 12\n",
    "pre_len = 3\n",
    "\n",
    "# Предобработка\n",
    "trainX, trainY, testX, testY = preprocess_data(metr_la.values, time_len, rate, seq_len, pre_len)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Нормализация данных\n",
    "def normalize_data(trainX, testX):\n",
    "    scaler = MinMaxScaler()\n",
    "    # Обучение scaler на тренировочных данных и преобразование всех данных\n",
    "    trainX_shape = trainX.shape\n",
    "    testX_shape = testX.shape\n",
    "    trainX = scaler.fit_transform(trainX.reshape(-1, trainX_shape[-1])).reshape(trainX_shape)\n",
    "    testX = scaler.transform(testX.reshape(-1, testX_shape[-1])).reshape(testX_shape)\n",
    "    return trainX, testX, scaler\n",
    "\n",
    "# Нормализация trainX и testX\n",
    "trainX_norm, testX_norm, scaler_X = normalize_data(trainX, testX)\n",
    "trainY_norm, testY_norm, scaler_Y = normalize_data(trainY, testY)\n",
    "\n",
    "# Преобразование в тензоры PyTorch\n",
    "trainX_norm = torch.tensor(trainX_norm, dtype=torch.float32).to(device)\n",
    "trainY_norm = torch.tensor(trainY_norm, dtype=torch.float32).to(device)\n",
    "testX_norm = torch.tensor(testX_norm, dtype=torch.float32).to(device)\n",
    "testY_norm = torch.tensor(testY_norm, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, pre_len=3):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.pre_len = pre_len\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_lstm, _ = self.lstm(x)  # h_lstm shape: [batch, seq_len, hidden_size]\n",
    "        # Используем последние pre_len скрытые состояния\n",
    "        h_lstm = h_lstm[:, -self.pre_len:, :]  # shape: [batch, pre_len, hidden_size]\n",
    "        out = self.fc(h_lstm)  # shape: [batch, pre_len, output_size]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, pre_len=3):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.pre_len = pre_len\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_gru, _ = self.gru(x)  # h_gru shape: [batch, seq_len, hidden_size]\n",
    "        # Используем последние pre_len скрытые состояния\n",
    "        h_gru = h_gru[:, -self.pre_len:, :]  # shape: [batch, pre_len, hidden_size]\n",
    "        out = self.fc(h_gru)  # shape: [batch, pre_len, output_size]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout=0.2, pre_len=3):\n",
    "        super(TCNModel, self).__init__()\n",
    "        self.pre_len = pre_len\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.Conv1d(input_size, num_channels, kernel_size, padding=(kernel_size - 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(num_channels, num_channels, kernel_size, padding=(kernel_size - 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.fc = nn.Linear(num_channels, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (batch, seq_len, input_size) -> (batch, input_size, seq_len)\n",
    "        out = self.tcn(x)  # shape: [batch, num_channels, seq_len + kernel_size - 1]\n",
    "        # Используем последние pre_len временных шагов\n",
    "        out = out[:, :, -self.pre_len:]  # shape: [batch, num_channels, pre_len]\n",
    "        out = out.permute(0, 2, 1)  # shape: [batch, pre_len, num_channels]\n",
    "        out = self.fc(out)  # shape: [batch, pre_len, output_size]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainX, trainY, testX, testY, scaler_Y, epochs=50, lr=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(trainX)  # outputs shape: [batch, pre_len, output_size]\n",
    "        loss = criterion(outputs, trainY)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'{model}\\nEpoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Оценка модели\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions_norm = model(testX).cpu().numpy()  # predictions shape: [batch, pre_len, output_size]\n",
    "\n",
    "    # Восстановление данных\n",
    "    predictions = scaler_Y.inverse_transform(predictions_norm.reshape(-1, predictions_norm.shape[-1]))\n",
    "    predictions = predictions.reshape(predictions_norm.shape)  # Восстановление исходной формы\n",
    "    actuals = scaler_Y.inverse_transform(testY.cpu().numpy().reshape(-1, testY.shape[-1]))\n",
    "    actuals = actuals.reshape(testY.shape)  # Восстановление исходной формы\n",
    "\n",
    "    # Метрики\n",
    "    rmse = np.sqrt(mean_squared_error(actuals.reshape(-1), predictions.reshape(-1)))\n",
    "    mae = mean_absolute_error(actuals.reshape(-1), predictions.reshape(-1))\n",
    "    r2 = r2_score(actuals.reshape(-1), predictions.reshape(-1))\n",
    "    var = np.var(actuals - predictions)\n",
    "    return rmse, mae, r2, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры моделей\n",
    "input_size = trainX_norm.shape[2]  # Количество узлов (features)\n",
    "output_size = trainY_norm.shape[2]  # Количество узлов (features)\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "num_channels = 64\n",
    "kernel_size = 3\n",
    "pre_len = trainY_norm.shape[1]  # Длина предсказания (pre_len)\n",
    "\n",
    "# Создание моделей\n",
    "lstm_model = LSTMModel(input_size, hidden_size, output_size, num_layers, pre_len)\n",
    "gru_model = GRUModel(input_size, hidden_size, output_size, num_layers, pre_len)\n",
    "tcn_model = TCNModel(input_size, output_size, num_channels, kernel_size, pre_len=pre_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение и оценка\n",
    "results = []\n",
    "for name, model in [(\"LSTM\", lstm_model), (\"GRU\", gru_model), (\"TCN\", tcn_model)]:\n",
    "    rmse, mae, r2, var = train_model(model, trainX_norm, trainY_norm, testX_norm, testY_norm, scaler_Y, epochs=1000)\n",
    "    results.append([name, rmse, mae, r2, var])\n",
    "\n",
    "# Вывод результатов\n",
    "print(tabulate(results, headers=[\"Method\", \"RMSE\", \"MAE\", \"R2\", \"Var\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm): LSTM(2, 128, num_layers=4, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Epoch [100/300], Loss: 0.0255\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(2, 128, num_layers=4, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Epoch [200/300], Loss: 0.0205\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(2, 128, num_layers=4, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Epoch [300/300], Loss: 0.0150\n",
      "GRUModel(\n",
      "  (gru): GRU(2, 128, num_layers=4, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Epoch [100/100], Loss: 0.0188\n",
      "GRUModel(\n",
      "  (gru): GRU(2, 128, num_layers=4, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Epoch [100/300], Loss: 0.0168\n",
      "GRUModel(\n",
      "  (gru): GRU(2, 128, num_layers=4, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Epoch [200/300], Loss: 0.0143\n",
      "GRUModel(\n",
      "  (gru): GRU(2, 128, num_layers=4, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Epoch [300/300], Loss: 0.0136\n",
      "TCNModel(\n",
      "  (tcn): Sequential(\n",
      "    (0): Conv1d(2, 128, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Epoch [100/300], Loss: 0.0218\n",
      "TCNModel(\n",
      "  (tcn): Sequential(\n",
      "    (0): Conv1d(2, 128, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Epoch [200/300], Loss: 0.0193\n",
      "TCNModel(\n",
      "  (tcn): Sequential(\n",
      "    (0): Conv1d(2, 128, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Epoch [300/300], Loss: 0.0178\n",
      "Best params for LSTM: {'epochs': 300, 'hidden_size': 128, 'lr': 0.002, 'num_layers': 4}\n",
      "Best RMSE for LSTM: 16.198286056518555\n",
      "All results:\n",
      "params                                                                rmse      mae          r2      var\n",
      "-----------------------------------------------------------------  -------  -------  ----------  -------\n",
      "{'epochs': 300, 'hidden_size': 128, 'lr': 0.002, 'num_layers': 4}  16.1983  7.53778  -0.0373467  260.045\n",
      "Best params for GRU: {'epochs': 100, 'hidden_size': 128, 'lr': 0.002, 'num_layers': 4}\n",
      "Best RMSE for GRU: 14.57933521270752\n",
      "All results:\n",
      "params                                                                rmse      mae         r2      var\n",
      "-----------------------------------------------------------------  -------  -------  ---------  -------\n",
      "{'epochs': 100, 'hidden_size': 128, 'lr': 0.002, 'num_layers': 4}  14.5793  7.28365  0.159648   210.019\n",
      "{'epochs': 300, 'hidden_size': 128, 'lr': 0.002, 'num_layers': 4}  15.7906  7.22523  0.0142084  248.745\n",
      "Best params for TCN: {'epochs': 300, 'kernel_size': 4, 'lr': 0.002, 'num_channels': 128}\n",
      "Best RMSE for TCN: 14.577077865600586\n",
      "All results:\n",
      "params                                                                  rmse      mae        r2      var\n",
      "-------------------------------------------------------------------  -------  -------  --------  -------\n",
      "{'epochs': 300, 'kernel_size': 4, 'lr': 0.002, 'num_channels': 128}  14.5771  6.10462  0.159908  212.095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Определение сетки параметров для каждой модели\n",
    "param_grid = {\n",
    "    \"LSTM\": {\n",
    "        \"hidden_size\": [128],\n",
    "        \"num_layers\": [4],\n",
    "        \"lr\": [0.002],\n",
    "        \"epochs\": [300]\n",
    "    },\n",
    "    \"GRU\": {\n",
    "        \"hidden_size\": [128],\n",
    "        \"num_layers\": [4],\n",
    "        \"lr\": [0.002],\n",
    "        \"epochs\": [100, 300]\n",
    "    },\n",
    "    \"TCN\": {\n",
    "        \"num_channels\": [128],\n",
    "        \"kernel_size\": [4],\n",
    "        \"lr\": [0.002],\n",
    "        \"epochs\": [300]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Функция для Grid Search\n",
    "def grid_search(model_class, model_name, param_grid, trainX, trainY, testX, testY, scaler_Y):\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_params = None\n",
    "    results = []\n",
    "\n",
    "    # Перебор всех комбинаций параметров\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        # print(f\"Testing {model_name} with params: {params}\")\n",
    "\n",
    "        # Создание модели\n",
    "        if model_name == \"LSTM\":\n",
    "            model = model_class(\n",
    "                input_size=trainX.shape[2],\n",
    "                hidden_size=params[\"hidden_size\"],\n",
    "                output_size=trainY.shape[2],\n",
    "                num_layers=params[\"num_layers\"],\n",
    "                pre_len=trainY.shape[1]\n",
    "            )\n",
    "        elif model_name == \"GRU\":\n",
    "            model = model_class(\n",
    "                input_size=trainX.shape[2],\n",
    "                hidden_size=params[\"hidden_size\"],\n",
    "                output_size=trainY.shape[2],\n",
    "                num_layers=params[\"num_layers\"],\n",
    "                pre_len=trainY.shape[1]\n",
    "            )\n",
    "        elif model_name == \"TCN\":\n",
    "            model = model_class(\n",
    "                input_size=trainX.shape[2],\n",
    "                output_size=trainY.shape[2],\n",
    "                num_channels=params[\"num_channels\"],\n",
    "                kernel_size=params[\"kernel_size\"],\n",
    "                pre_len=trainY.shape[1]\n",
    "            )\n",
    "\n",
    "        # Обучение модели\n",
    "        rmse, mae, r2, var = train_model(\n",
    "            model, trainX, trainY, testX, testY, scaler_Y,\n",
    "            epochs=params[\"epochs\"], lr=params[\"lr\"]\n",
    "        )\n",
    "\n",
    "        # Сохранение результатов\n",
    "        results.append({\n",
    "            \"params\": params,\n",
    "            \"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "            \"r2\": r2,\n",
    "            \"var\": var\n",
    "        })\n",
    "\n",
    "        # Обновление лучших параметров\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_params = params\n",
    "\n",
    "    return best_params, best_rmse, results\n",
    "\n",
    "# Выполнение Grid Search для каждой модели\n",
    "best_results = {}\n",
    "for model_name, model_class in [(\"LSTM\", LSTMModel), (\"GRU\", GRUModel), (\"TCN\", TCNModel)]:\n",
    "    best_params, best_rmse, results = grid_search(\n",
    "        model_class, model_name, param_grid[model_name],\n",
    "        trainX_norm, trainY_norm, testX_norm, testY_norm, scaler_Y\n",
    "    )\n",
    "    best_results[model_name] = {\n",
    "        \"best_params\": best_params,\n",
    "        \"best_rmse\": best_rmse,\n",
    "        \"all_results\": results\n",
    "    }\n",
    "\n",
    "# Вывод лучших параметров и результатов\n",
    "for model_name, result in best_results.items():\n",
    "    print(f\"Best params for {model_name}: {result['best_params']}\")\n",
    "    print(f\"Best RMSE for {model_name}: {result['best_rmse']}\")\n",
    "    print(\"All results:\")\n",
    "    print(tabulate(result[\"all_results\"], headers=\"keys\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
